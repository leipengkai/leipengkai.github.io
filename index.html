<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    
    <title>Femn</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta property="og:type" content="website">
<meta property="og:title" content="Femn">
<meta property="og:url" content="https://www.femn.me/index.html">
<meta property="og:site_name" content="Femn">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Femn">
    

    
        <link rel="alternate" href="/atom.xml" title="Femn" type="application/atom+xml" />
    

    
        <link rel="icon" href="/css/images/favicon.ico" />
    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    


</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Femn</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">Home</a>
                
                    <a class="main-nav-link" href="/archives">Archives</a>
                
                    <a class="main-nav-link" href="/categories">Categories</a>
                
                    <a class="main-nav-link" href="/tags">Tags</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/4822598_105251_2.jpg" />
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">Home</a></td>
                
                    <td><a class="main-nav-link" href="/archives">Archives</a></td>
                
                    <td><a class="main-nav-link" href="/categories">Categories</a></td>
                
                    <td><a class="main-nav-link" href="/tags">Tags</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/4822598_105251_2.jpg" />
            <h2 id="name">leipengkai</h2>
            <h3 id="title">Python Developer</h3>
            <span id="location"><i class="fa fa-map-marker"></i>Shenzhen, China</span>
            <a id="follow" target="_blank" href="https://github.com/leipengkai/">FOLLOW</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                68
                <span>posts</span>
            </div>
            <div class="article-info-block">
                6
                <span>tags</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="http://github.com/leipengkai" target="_blank" title="github" class=tooltip>
                            <i class="fa fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://twitter.com/femnyy" target="_blank" title="twitter" class=tooltip>
                            <i class="fa fa-twitter"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://www.facebook.com/profile.php?id=100012089717648" target="_blank" title="facebook" class=tooltip>
                            <i class="fa fa-facebook"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://www.instagram.com/leipengkai/" target="_blank" title="instagram" class=tooltip>
                            <i class="fa fa-instagram"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="https://plus.google.com/108032606311958999451" target="_blank" title="google_plus" class=tooltip>
                            <i class="fa fa-google_plus"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/atom.xml" target="_blank" title="rss" class=tooltip>
                            <i class="fa fa-rss"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main">
    <article id="post-storm" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/28/storm/">hadoop storm(八)</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/28/storm/">
            <time datetime="2017-09-28T11:41:15.000Z" itemprop="datePublished">2017-09-28</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/大数据/">大数据</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h3 id="storm-分布式实时分析计算系统"><a href="#storm-分布式实时分析计算系统" class="headerlink" title="storm:分布式实时分析计算系统"></a><a href="http://storm.apache.org/" target="_blank" rel="noopener">storm</a>:分布式实时分析计算系统</h3><p>storm概念<br><img src="/2017/09/28/storm/storm.jpg" title="storm基本概念"></p>
<p>Topologies:拓扑,也称为一个任务<br>Spouts:集群i(拓扑)的消息源<br>Bolts:集群(拓扑)节点的处理逻辑单元<br>Configuration:topology配置</p>
<p>tuple:消息元组(在Spouts和Bolts之间传递的数据格式,一种自定义格式的封装)<br>Stream:流,tuple(消息的处理)经过的路径不一样<br>Stream groupings:流的分组策略</p>
<p>Tasks:任务处理单元<br>Executor:工作线程<br>Workers:工作进程</p>
<h4 id="搭建storm集群"><a href="#搭建storm集群" class="headerlink" title="搭建storm集群"></a>搭建storm集群</h4><p>先在cluster1-3中安装zookeeper集群<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 怕有冲突 先将zookeeper目录,在cluster1-3中执行</span></span><br><span class="line">tar -zcvf z.tar.gz zookeeper-3.4.10</span><br><span class="line">rm -rf /root/zookeeper-3.4.10</span><br><span class="line"><span class="comment"># 在cluster1中执行</span></span><br><span class="line">tar -zxvf zookeeper-3.4.10.tar.gz</span><br><span class="line"><span class="built_in">cd</span> zookeeper-3.4.10/conf/</span><br><span class="line">mv zoo_sample.cfg zoo.cfg</span><br><span class="line">vim zoo.cfg </span><br><span class="line">    dataDir=/root/zookeeper-3.4.10/data</span><br><span class="line">    server.1=cluster1:2888:3888</span><br><span class="line">    server.2=cluster2:2888:3888</span><br><span class="line">    server.3=cluster3:2888:3888</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> ../ &amp;&amp; mkdir data &amp;&amp; <span class="built_in">cd</span> data </span><br><span class="line"><span class="built_in">echo</span> 1 &gt; myid</span><br><span class="line"><span class="built_in">cd</span> </span><br><span class="line"><span class="comment"># 将ZK复制到cluster2和3</span></span><br><span class="line">scp -r ./zookeeper-3.4.10 root@cluster2:/root</span><br><span class="line">scp -r ./zookeeper-3.4.10 root@cluster3:/root</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别在cluster2 </span></span><br><span class="line"><span class="built_in">echo</span> 2 &gt; /root/zookeeper-3.4.10/data/myid</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别在cluster3 </span></span><br><span class="line"><span class="built_in">echo</span> 3 &gt; /root/zookeeper-3.4.10/data/myid</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别在cluster1-3运行</span></span><br><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure></p>
<p>复制安装包<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp ./apache-storm-1.1.1.tar.gz root@cluster1:/root/</span><br></pre></td></tr></table></figure></p>
<p>cluster1在运行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-storm-1.1.1.tar.gz</span><br><span class="line">mv apache-storm-1.1.1 storm</span><br><span class="line"><span class="built_in">cd</span> storm/conf </span><br><span class="line">vim storm.yaml</span><br><span class="line">    storm.zookeeper.servers:</span><br><span class="line">        - <span class="string">"cluster1"</span></span><br><span class="line">        - <span class="string">"cluster2"</span></span><br><span class="line">        - <span class="string">"cluster3"</span></span><br><span class="line">    nimbus.seeds: [<span class="string">"cluster1"</span>]</span><br><span class="line">    storm.zookeeper.root: <span class="string">"/root/zookeeper-3.4.10"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> </span><br><span class="line">scp -r storm root@cluster2:/root/</span><br><span class="line">scp -r storm root@cluster3:/root/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置环境变量(cluster1-3)</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"export PATH=\$&#123;PATH&#125;:/root/storm/bin"</span> &gt;&gt; ~/.bashrc</span><br><span class="line">    <span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>在nimbus主机上运行(cluster1)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup storm nimbus 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br><span class="line">nohup storm ui 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>
<p>访问 <a href="http://cluster1:8080/" target="_blank" rel="noopener">http://cluster1:8080/</a></p>
<p>在supervisor主机上运行(cluster2-3),等nimbus跑起来之后 加一个就让HMaster管理<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup storm supervisor 1&gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/28/storm/" data-id="cjgra84vy004905lm0y7zz6gu" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/28/storm/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/28/storm/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <article id="post-hbase" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/28/hbase/">hadoop hbase(七)</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/28/hbase/">
            <time datetime="2017-09-28T11:31:15.000Z" itemprop="datePublished">2017-09-28</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/大数据/">大数据</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>hadoop工具(二):<a href="https://hbase.apache.org/" target="_blank" rel="noopener">hbase</a>也是分布式,可扩展的大数据存储,HBase与HDFS的区别在于它是个数据库,数据库是基于文件系统(HDFS)提供的一种结构化数据的查询管理的一个系统<br>应用场景:<br>对数据进行随机的,实时的进行读写<br>相对于处理复杂的表与表之间的关系,以及关联查询的关系型数据库而言.HBASE是没有表与表的关联,是属于NoSql的范围</p>
<p>HBASE表结构:</p>
<ol>
<li>建表时,不需要限定表中的字段,只需要指定若干个列族</li>
<li>插入数据时,一条数据中可以存储任意多个列(K-V,列名&amp;列值),不在乎是否冗余,只要查询方便</li>
<li>一个Value可以有多个版本,通过版本号来区分(时间戳),要查询某一个具体字段的值,需要指定的坐标:表名–行键–列族(ColumnFamily)–列名(Qualifier)(sql中的字段)–版本</li>
<li>行键是唯一的</li>
</ol>
<p>SQL记录的信息,只能是表中已经定义好的字段,而不能插入没有定义的字段,除非改变整个表结构</p>
<p>HBase是一很大很的表(big table),不可能是单机存储,是分布式管理和存储的<br>只要数据达到一定量之后,若干行就会切分成一个Region,Region会放在Region Server中</p>
<h3 id="安装运行hbase-建立在集群之上"><a href="#安装运行hbase-建立在集群之上" class="headerlink" title="安装运行hbase,建立在集群之上"></a>安装运行hbase,建立在集群之上</h3><p>在cluster3中安装hbase<br>scp ./hbase-1.2.6-bin.tar.gz root@cluster3:/root</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /root </span><br><span class="line">tar -zxvf hbase-1.2.6-bin.tar.gz</span><br><span class="line"><span class="built_in">cd</span> hbase-1.2.6 </span><br><span class="line">rm -rf docs</span><br><span class="line"><span class="built_in">cd</span> conf</span><br><span class="line">vim hbase-env.sh</span><br><span class="line">    <span class="comment"># 告诉HBase使用外部的ZK</span></span><br><span class="line">    <span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br><span class="line"></span><br><span class="line">vim hbase-site.xml</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://ns1/hbase&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;zookeeper1:2181,zookeeper2:2181,zookeeper3:2181&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;  </span><br><span class="line">        &lt;name&gt;hbase.master.info.port&lt;/name&gt;  </span><br><span class="line">        &lt;value&gt;60010&lt;/value&gt;  </span><br><span class="line">    &lt;/property&gt; </span><br><span class="line">    &lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line">vim regionservers</span><br><span class="line">    zookeeper1</span><br><span class="line">    zookeeper2</span><br><span class="line">    zookeeper3</span><br><span class="line"></span><br><span class="line">cp ~/hadoop-2.8.1/etc/hadoop/&#123;core-site.xml,hdfs-site.xml&#125; ./</span><br><span class="line"><span class="built_in">cd</span> </span><br><span class="line">mv hbase-1.2.6 hbase</span><br><span class="line">mv hbase hadoop-2.8.1/</span><br><span class="line">scp -r hadoop-2.8.1/hbase zookeeper1:/root/hadoop-2.8.1</span><br><span class="line">scp -r hadoop-2.8.1/hbase zookeeper2:/root/hadoop-2.8.1</span><br><span class="line">scp -r hadoop-2.8.1/hbase zookeeper3:/root/hadoop-2.8.1</span><br><span class="line">scp -r hadoop-2.8.1/hbase cluster4:/root/hadoop-2.8.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 已经在zookeeper1-3启动 </span></span><br><span class="line">zkServer.sh start </span><br><span class="line">hadoop-daemon.sh start journalnode</span><br><span class="line"><span class="comment"># 在cluster1启动</span></span><br><span class="line">start-dfs.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在本机(cluster3:HMaster)</span></span><br><span class="line"><span class="built_in">cd</span> /root/hadoop-2.8.1/hbase/bin</span><br><span class="line">./start-hbase.sh </span><br><span class="line"></span><br><span class="line"><span class="comment"># 在cluster4中执行</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /root/hadoop-2.8.1/hbase/bin/</span><br><span class="line">./hbase-daemon.sh start master</span><br><span class="line"></span><br><span class="line">./hbase shell</span><br><span class="line">version</span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问http://cluster3:60010/</span></span><br></pre></td></tr></table></figure>
<img src="/2017/09/28/hbase/hbase.jpg" title="HBase基本概念">

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/28/hbase/" data-id="cjgra84qv002505lmo8lc1tas" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/28/hbase/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/28/hbase/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <article id="post-hadoop_cluster" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/27/hadoop_cluster/">hadoop HDFS HA高可用的集群搭建部署(六)</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/27/hadoop_cluster/">
            <time datetime="2017-09-27T11:41:15.000Z" itemprop="datePublished">2017-09-27</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/大数据/">大数据</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>HDFS元数据的可靠性有保证,但hadoop的HA(高可用)不高<br><img src="/2017/09/27/hadoop_cluster/HDFS_HA.jpg" title="HDFS HA实现机制"><br>HDFS HA高可用的集群搭建 </p>
<h4 id="7台机器的集群规划-512M-8G"><a href="#7台机器的集群规划-512M-8G" class="headerlink" title="7台机器的集群规划(512M,8G)"></a>7台机器的集群规划(512M,8G)</h4><p>cluster1 192.168.1.221 jdk,hadoop namenode zkfc<br>cluster2 192.168.1.222 jdk,hadoop namenode zkfc<br>cluster3 192.168.1.223 jdk,hadoop resourcemanager<br>cluster4 192.168.1.224 jdk,hadoop resourcemanager<br>zookeeper1 192.168.1.225 jdk,hadoop,zookeeper zookeeper journalnode datanode nodemanager<br>zookeeper2 192.168.1.226 jdk,hadoop,zookeeper zookeeper journalnode datanode nodemanager<br>zookeeper3 192.168.1.227 jdk,hadoop,zookeeper zookeeper journalnode datanode nodemanager<br><img src="/2017/09/27/hadoop_cluster/cluster_plan.jpg" title="集群规划"></p>
<h4 id="实际操作-之后的所有操作都是root用户"><a href="#实际操作-之后的所有操作都是root用户" class="headerlink" title="实际操作(之后的所有操作都是root用户)"></a>实际操作(之后的所有操作都是root用户)</h4><p>前提</p>
<ol>
<li>修改了<a href="https://www.femn.me/2017/09/20/virtualbox/">网卡设置</a>,网络正常.</li>
<li>在/root目录下有hadoop-2.8.1.tar.gz,jdk8.tar.gz和zookeeper-3.4.10.tar.gz这三个包</li>
</ol>
<p>在一台虚拟机上执行如下脚本(cluster1)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://file.femnyy.com/file/install_hadoop_cluster.sh | sudo sh</span><br></pre></td></tr></table></figure></p>
<p>然后就clone 6台虚拟机,进入开启这6台虚拟机,修改IP,重新启动网络<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-enp0s3</span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-enp0s8</span><br><span class="line">service network restart</span><br><span class="line">ifconfig</span><br></pre></td></tr></table></figure></p>
<p>然后在cluster1中执行SSH免密码登陆,分别对列出的主机执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id cluster1 cluster2 zookeeper1 zookeeper2 zookeeper3</span><br></pre></td></tr></table></figure>
<p>在cluster3中执行如下命令,分别对列出的主机执行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id zookeeper1 zookeeper2 zookeeper3</span><br></pre></td></tr></table></figure></p>
<p>在zookeeper2在执行如下命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> 2 &gt; /root/zookeeper-3.4.10/data/myid</span><br></pre></td></tr></table></figure></p>
<p>在zookeeper3在执行如下命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> 3 &gt; /root/zookeeper-3.4.10/data/myid</span><br></pre></td></tr></table></figure></p>
<h4 id="环境配置好了之后-一定严格按下面步骤进行操作"><a href="#环境配置好了之后-一定严格按下面步骤进行操作" class="headerlink" title="环境配置好了之后,一定严格按下面步骤进行操作"></a>环境配置好了之后,一定严格按下面步骤进行操作</h4><pre><code>启动zookeeper集群(分别在zookeeper1-3上启动zk)
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br><span class="line"><span class="comment"># 查看状态,一个leader(通过选举得到),两个follower</span></span><br><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure>
<pre><code>启动journalnode(分别在zookeeper1-3上执行)
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start journalnode</span><br><span class="line"><span class="comment"># 检验是否有JournalNode进程</span></span><br><span class="line">jps</span><br></pre></td></tr></table></figure>
<pre><code>格式化HDFS(在cluster1上执行)
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br><span class="line"><span class="comment"># 格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件,我是设置成/root/hadoop-2.8.1/tmp,然后将这个tmp目录cp到cluster2下</span></span><br><span class="line">scp -r /root/hadoop-2.8.1/tmp/ root@cluster2:/root/hadoop-2.8.1/</span><br><span class="line"><span class="comment"># 或者在cluster2执行如下命令,效果也是一样的</span></span><br><span class="line"><span class="comment"># hdfs namenode -bootstrapStandby</span></span><br></pre></td></tr></table></figure>
<pre><code>格式化ZKFC(在cluster1上执行即可)
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hdfs zkfc -formatZK</span><br><span class="line"><span class="comment"># 在zookeeper1在执行,查看建立的数据节点</span></span><br><span class="line">zkCli.sh</span><br><span class="line">ls / <span class="comment"># [zookeeper, hadoop-ha]</span></span><br><span class="line">ls /hadoop-ha <span class="comment"># [ns1]</span></span><br><span class="line">get /hadoop-ha/ns1 <span class="comment"># 因为没有运行,数据都是空的</span></span><br></pre></td></tr></table></figure>
<p>如果改了配置文本想重新启动就不需要再启动上面的内容了,<br>比如改了所有虚拟机的hdfs-site.xml文件,只需要在cluster1 stop-dfs.sh 再运行start-dfs.sh就可以了</p>
<p>如是下次重新启动时就启动zk集群和start-dfs.sh和start-yarn.sh,格式化一次就可以了</p>
<pre><code>启动HDFS(在cluster1上执行即可)
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
<pre><code>启动YARN(在cluster3上执行)
</code></pre><p>将Namenode和Resourcemanager分开是因为性能问题<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></p>
<pre><code>启动YARN daemon(在cluster4上执行)
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
<p>访问<br>HDFS: <a href="http://cluster1:50070" target="_blank" rel="noopener">http://cluster1:50070</a><br>HDFS: <a href="http://cluster2:50070" target="_blank" rel="noopener">http://cluster2:50070</a><br>YARN: <a href="http://cluster3:8088" target="_blank" rel="noopener">http://cluster3:8088</a></p>
<p>改进: dfs.datanode.http.address   datanode的HTTP服务器和端口         50075hdfs-site.xml  0.0.0.0:50075   </p>
<h3 id="HDFS-HA-测试"><a href="#HDFS-HA-测试" class="headerlink" title="HDFS HA 测试"></a>HDFS HA 测试</h3><pre><code>测试上传
</code></pre><p>在zookeeper1-3集群中在执行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/hadoop-2.8.1/tmp/dfs/data/current/BP-xx/current/finalized/</span><br></pre></td></tr></table></figure></p>
<p>在cluster1在执行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put /root/hadoop-2.8.1.tar.gz /</span><br><span class="line"><span class="comment"># 执行完成后会在zookeeper1-3中 cd subdir0/subdir0/看到两个block块</span></span><br><span class="line">mkdir 1 &amp;&amp; <span class="built_in">cd</span> 1</span><br><span class="line">hadoop fs -get /hadoop-2.8.1.tar.gz</span><br></pre></td></tr></table></figure></p>
<pre><code>测试namenode切换
</code></pre><p>HDFS: <a href="http://cluster2:50070" target="_blank" rel="noopener">http://cluster2:50070</a><br>HDFS: <a href="http://cluster2:50070" target="_blank" rel="noopener">http://cluster2:50070</a><br>得知哪个是active状态,我的是cluster2是active<br>通过jps得到namenode的进程,将其kill</p>
<h4 id="kill-cluster2-namenode-进程"><a href="#kill-cluster2-namenode-进程" class="headerlink" title="kill cluster2 namenode 进程"></a>kill cluster2 namenode 进程</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  kill之后,可以再看http://cluster2:50070的和cluster1的状态,成功切换</span></span><br><span class="line"><span class="comment"># 所以也是在cluster2中重新启动NameNode</span></span><br><span class="line">hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
<h4 id="将cluster1这个虚拟机关机"><a href="#将cluster1这个虚拟机关机" class="headerlink" title="将cluster1这个虚拟机关机"></a>将cluster1这个虚拟机关机</h4><p>现在是cluster1为active,,cluster2至少要等30s才能切换.<br>然后重新启动cluster1之后执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start zkfc</span><br><span class="line">hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
<h4 id="手动切换-但不推荐使用"><a href="#手动切换-但不推荐使用" class="headerlink" title="手动切换,但不推荐使用"></a>手动切换,但不推荐使用</h4><p>现在cluster2是active,在cluster1中执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs haadmin -transitionToStandby nn2 --forcemanual</span><br><span class="line"><span class="comment"># namenode的状态</span></span><br><span class="line">hdfs haadmin -getServiceState nn2 <span class="comment"># standby</span></span><br></pre></td></tr></table></figure>
<pre><code>查看Yarn状态
</code></pre><p>在zookeeper1-3的随便一台在执行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zkCli.sh</span><br><span class="line">get /yarn-leader-election/yrc/ActiveBreadCrumb </span><br><span class="line"><span class="comment"># yrcrm1表明rm1(cluster3)是运行状态</span></span><br></pre></td></tr></table></figure></p>
<p>也可以通过访问:<br>YARN:<a href="http://cluster3:8088" target="_blank" rel="noopener">http://cluster3:8088</a><br>YARN:<a href="http://cluster4:8088" target="_blank" rel="noopener">http://cluster4:8088</a><br>会自动跳转到运行状态的地址上</p>
<pre><code>Yarn的HA测试
</code></pre><p>我的是cluster3是active,在cluster4在执行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar pi 5 5</span><br></pre></td></tr></table></figure></p>
<p>在cluster3在杀死ResourceManager进程</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#重启启动 resourcemanager</span></span><br><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
<p>Yarn的HA不像HDFS的YA一样,YARN正在跑的程序突然中断则意味着程序的失败</p>
<h3 id="动态增加DataNode节点和数量管理"><a href="#动态增加DataNode节点和数量管理" class="headerlink" title="动态增加DataNode节点和数量管理"></a>动态增加DataNode节点和数量管理</h3><p>在zookeeper3中kill掉datanode进程<br>再查看<a href="http://cluster1:50070的Live" target="_blank" rel="noopener">http://cluster1:50070的Live</a> Nodes数量,则会显示Live NOdes:2,Dead NOdes:1,block副本不会变多</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在zookeeper1-3中</span></span><br><span class="line">vim /root/hadoop-2.8.1/tmp/dfs/data/current/VERSION</span><br><span class="line"><span class="comment"># 是由clusterID的决定这个datanode是否在同一个集群上</span></span><br></pre></td></tr></table></figure>
<p>新加一个datanode节点,只需要hadoop包,然后启动datanode就行了</p>
<p>clone一台zookeeper1的名为zookeeper4,并在zookeeper4运行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># zookeeper4 192.168.1.228 jdk,hadoop,zookeeper zookeeper journalnode datanode nodemanager </span></span><br><span class="line"><span class="comment"># vim /etc/sysconfig/network-scripts/ifcfg-enp0s3 # 为228 service network restart</span></span><br><span class="line">    rm -rf /root/hadoop-2.8.1/tmp</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"192.168.1.228 zookeeper4"</span>&gt;&gt; /etc/hosts</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"zookeeper4"</span>&gt;&gt; /root/hadoop-2.8.1/etc/hadoop/slaves </span><br><span class="line">    scp /etc/hosts root@cluster1:/etc/hosts</span><br><span class="line">    scp /etc/hosts root@cluster2:/etc/hosts</span><br><span class="line">    scp /etc/hosts root@cluster3:/etc/hosts</span><br><span class="line">    scp /etc/hosts root@cluster4:/etc/hosts</span><br><span class="line">    scp /etc/hosts root@zookeeper1:/etc/hosts</span><br><span class="line">    scp /etc/hosts root@zookeeper2:/etc/hosts</span><br><span class="line">    scp /etc/hosts root@zookeeper3:/etc/hosts</span><br><span class="line">    scp /root/hadoop-2.8.1/etc/hadoop/slaves \</span><br><span class="line">        root@cluster1:/root/hadoop-2.8.1/etc/hadoop/slaves</span><br><span class="line">    scp /root/hadoop-2.8.1/etc/hadoop/slaves \</span><br><span class="line">        root@cluster2:/root/hadoop-2.8.1/etc/hadoop/slaves</span><br><span class="line">    scp /root/hadoop-2.8.1/etc/hadoop/slaves \</span><br><span class="line">        root@cluster3:/root/hadoop-2.8.1/etc/hadoop/slaves</span><br><span class="line">    scp /root/hadoop-2.8.1/etc/hadoop/slaves \</span><br><span class="line">        root@cluster4:/root/hadoop-2.8.1/etc/hadoop/slaves</span><br><span class="line">    scp /root/hadoop-2.8.1/etc/hadoop/slaves \</span><br><span class="line">        root@zookeeper1:/root/hadoop-2.8.1/etc/hadoop/slaves</span><br><span class="line">    scp /root/hadoop-2.8.1/etc/hadoop/slaves \</span><br><span class="line">        root@zookeeper2:/root/hadoop-2.8.1/etc/hadoop/slaves</span><br><span class="line">    scp /root/hadoop-2.8.1/etc/hadoop/slaves \</span><br><span class="line">        root@zookeeper3:/root/hadoop-2.8.1/etc/hadoop/slaves</span><br><span class="line">    hadoop-daemon.sh start datanode</span><br><span class="line">    ll /root/hadoop-2.8.1/tmp/dfs/data/current/BP-xx\</span><br><span class="line">        /current/finalized/subdir0/subdir0</span><br><span class="line">    <span class="comment"># 会自动将block副本复制到这个节点上,来保存三个副本</span></span><br><span class="line">    <span class="comment"># 在cluster3,cluster14</span></span><br><span class="line">    <span class="comment"># yarn-daemon.sh start nodemanager</span></span><br><span class="line">    <span class="comment"># 在cluster1,cluster12刷新集群节点</span></span><br><span class="line">    <span class="comment"># hdfs dfsadmin -refreshNodes</span></span><br></pre></td></tr></table></figure></p>
<p>现在再将zookeeper3的datanode启动起来<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></p>
<p>目前将会有四个节点,四个副本,导致了数据的冗余,hadoop会自动的清除掉冗余的数据</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/27/hadoop_cluster/" data-id="cjgra84pe001s05lmm60dz1q1" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/27/hadoop_cluster/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/27/hadoop_cluster/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <article id="post-hadoop_hive" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/27/hadoop_hive/">hadoop hive(五)</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/27/hadoop_hive/">
            <time datetime="2017-09-27T11:31:15.000Z" itemprop="datePublished">2017-09-27</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/大数据/">大数据</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>hadoop工具(一):<a href="https://hive.apache.org" target="_blank" rel="noopener">hive</a>:它只是一个工具可在任意一个节点安装,和集群没有任何关系,.<br><img src="/2017/09/27/hadoop_hive/hive.jpg" title="hive的作用"></p>
<h4 id="安装使用hive-cluster1"><a href="#安装使用hive-cluster1" class="headerlink" title="安装使用hive(cluster1)"></a>安装使用hive(cluster1)</h4><pre><code>install mysql 
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://dev.mysql.com/downloads/repo/yum/ 查看对应版本</span></span><br><span class="line">wget https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm</span><br><span class="line">rpm -ivh mysql57-community-release-el7-9.noarch.rpm</span><br><span class="line">yum install -y mysql-server</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"skip-grant-tables"</span> &gt;&gt; /etc/my.cnf </span><br><span class="line">systemctl start mysqld</span><br><span class="line">mysql -uroot -proot</span><br><span class="line">    flush privileges;</span><br><span class="line">    ALTER USER <span class="string">'root'</span>@<span class="string">'localhost'</span> IDENTIFIED BY <span class="string">'root'</span>;</span><br><span class="line">sed -i -e <span class="string">'/^skip-grant-tables/d'</span> /etc/my.cnf </span><br><span class="line">systemctl restart mysqld</span><br><span class="line">mysql -uroot -proot</span><br><span class="line">    CREATE DATABASE `hive` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;</span><br><span class="line">    grant all privileges on *.* to root@localhost identified by <span class="string">'root'</span>;</span><br><span class="line">    flush privileges;</span><br></pre></td></tr></table></figure>
<pre><code>install hive
</code></pre><p>scp ./apache-hive-2.1.1-bin.tar.gz root@cluster1:/root</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root</span><br><span class="line">tar -zxvf apache-hive-2.1.1-bin.tar.gz</span><br><span class="line">mv apache-hive-2.1.1-bin hive</span><br><span class="line">mv hive hadoop-2.8.1/</span><br><span class="line"><span class="built_in">cd</span> hadoop-2.8.1/hive/conf/</span><br><span class="line"><span class="comment"># cp hive-default.xml.template hive-site.xml</span></span><br><span class="line">cp hive-env.sh.template hive-env.sh</span><br><span class="line">cp hive-log4j2.properties.template hive-log4j2.properties</span><br><span class="line">cp hive-exec-log4j2.properties.template hive-exec-log4j2.properties</span><br><span class="line">vim hive-site.xml</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=<span class="literal">true</span>&amp;amp;useUnicode=<span class="literal">true</span>&amp;amp;characterEncoding=UTF-8&amp;amp;useSSL=<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<pre><code>hive/lib目录下放mysql.jar
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp ./mysql-connector-java-5.1.44-bin.jar root@cluster1:/root/hadoop-2.8.1/hive/lib/</span><br></pre></td></tr></table></figure>
<pre><code>配置环境变量
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"export HIVE_HOME=/root/hadoop-2.8.1/hive"</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"export PATH=\$&#123;PATH&#125;:\$&#123;HIVE_HOME&#125;/bin"</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"export HIVE_CONF_DIR=\$&#123;HIVE_HOME&#125;/conf"</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<pre><code>启动hive,建立在集群之上
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动三台datanode(ZK)</span></span><br><span class="line">zkServer.sh start </span><br><span class="line">hadoop-daemon.sh start journalnode</span><br><span class="line"><span class="comment"># 启动start-dfs.sh</span></span><br><span class="line">start-dfs.sh </span><br><span class="line"><span class="comment"># hive在第一次登录的时候需要用如下命令初始化    </span></span><br><span class="line">schematool -dbType mysql -initSchema</span><br><span class="line"><span class="comment"># 启动hive metastore进程</span></span><br><span class="line">hive --service metastore &amp; </span><br><span class="line"><span class="comment"># 运行hive</span></span><br><span class="line">hive</span><br></pre></td></tr></table></figure>
<p>创建一些数据<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /root/d.data</span><br><span class="line">1 iphone8 64G 8000</span><br><span class="line">2 iphone7 64G 7000</span><br><span class="line">3 iphone6 64G 6000</span><br><span class="line">4 iphone5 64G 5000</span><br><span class="line">5 iphone4 64G 4000</span><br></pre></td></tr></table></figure></p>
<pre><code>hive语法
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">SHOW TABLES;</span><br><span class="line">create table t_order(id int,name string,container string,price double)</span><br><span class="line">row format delimited </span><br><span class="line">fields terminated by <span class="string">' '</span>;</span><br><span class="line">SHOW TABLES;</span><br><span class="line"><span class="comment"># 数据本来只那里,只能用来查看</span></span><br><span class="line"><span class="comment"># 所以不能使用 insert into **</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向表中加载数据</span></span><br><span class="line">load data <span class="built_in">local</span> inpath <span class="string">'/root/d.data'</span> into table t_order;</span><br><span class="line"><span class="comment"># 查看与统计</span></span><br><span class="line">select * from t_order;</span><br><span class="line">select count(*) from t_order; <span class="comment"># 执行的MapReduce程序</span></span><br></pre></td></tr></table></figure>
<pre><code>通过mysql查看hive上传的时的表的信息
</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">user hive;</span><br><span class="line">show tables;</span><br><span class="line"><span class="comment"># 记录元数据的表</span></span><br><span class="line">select * from DBS;</span><br><span class="line"><span class="comment"># DB_LOCATION_URI: hdfs://ns1/user/hive/warehouse</span></span><br><span class="line"><span class="comment"># 查看数据库的内容 http://cluster1:50070/explorer.html#/user/hive/warehouse</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看在hive中创建的表</span></span><br><span class="line">select * from TBLS;</span><br><span class="line"><span class="comment"># 表中的字段</span></span><br><span class="line">select * from COLUMNS_V2;</span><br></pre></td></tr></table></figure>
<p>用hive创建数据库或表就相当于在hdfs中创建目录</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/27/hadoop_hive/" data-id="cjgra84qk001x05lmp2gjthrv" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/27/hadoop_hive/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/27/hadoop_hive/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <article id="post-zookeeper" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/25/zookeeper/">zookeeper(五)</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/25/zookeeper/">
            <time datetime="2017-09-25T12:01:15.000Z" itemprop="datePublished">2017-09-25</time>
        </a>
    </div>


                        
                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/大数据/">大数据</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>Zookeeper是Google的Chubby的一个开源的实现,是Hadoop的分布协调服务,它包含一个简单的原语集,分布式应用程序可以基于它实现同步服务,配置维护和命名服务等,保证hadoop的HA(高可用),它本身也是个集群(提供少量数据的存储和管理)</p>
<p>大部分分布式应用需要一个主控,协调器或控制器来管理物理分布的子进程(资源,任务分配等)<br>Zookeeper:提供通用的分布式锁服务,用以协调分布式应用</p>
<p>Zookeeper安装和配置(集群模式)<br>在一台虚拟机上运行如下脚本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://file.femnyy.com/file/install_zookeeper.sh |sudo sh</span><br></pre></td></tr></table></figure></p>
<p>准备工作</p>
<ol>
<li>clone三台之后,修改主机名为zookeeper1,zookeeper2,zookeeper3,修改/etc/hosts</li>
<li>修改IP /etc/sysconfig/network-scripts/  在的三个IP</li>
<li>关闭防火墙</li>
<li>ssh免登陆</li>
<li>安装JDK,配置环境变量</li>
<li>zoo.conf的配置dataDir中的目录下创建一个myid文件<br>再修改vim /root/zookeeper-3.4.10/data/myid 对应的Id号<br>启动Zookeeper:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在三台虚拟机中都执行</span></span><br><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>查看Zookeeper状态:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在三台虚拟机中都执行</span></span><br><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure></p>
<p>提供一个命令行的客户端<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">zkCli.sh</span><br><span class="line"><span class="built_in">help</span></span><br><span class="line"><span class="comment"># 创建一个共同的配置文件,所有的zookeeper集群都能访问到</span></span><br><span class="line">create /zp241 path:/home/femn/ </span><br><span class="line">get /zp241 </span><br><span class="line"><span class="comment"># 启动另一个虚拟机的命令行客户端也可以看到上传的内容</span></span><br><span class="line">zkCli.sh</span><br><span class="line">get /zp241 </span><br><span class="line">quit</span><br></pre></td></tr></table></figure></p>
<p>zookeeper管理客户所存放的数据采用的是类似于文件树的结构<br>每一个节点叫做一个node:节点分为两种类型短暂的和持久<br>短暂的Node的客户端会话结束时,zookeeper会将该短暂的node删除,同时 短暂的node不可以有子节点<br><img src="https://drive.google.com/file/d/0B9NEWVh_ricqWDVEeXo3aGdvRjQ/view?usp=sharing" alt=""></p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/25/zookeeper/" data-id="cjgra84wx004p05lmnfqgklhf" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/25/zookeeper/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/25/zookeeper/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <article id="post-hadoop_mapreduce" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/23/hadoop_mapreduce/">hadoop MapReduce Yarn(四)</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/23/hadoop_mapreduce/">
            <time datetime="2017-09-23T12:01:15.000Z" itemprop="datePublished">2017-09-23</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/大数据/">大数据</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h4 id="hadoop运行jar包"><a href="#hadoop运行jar包" class="headerlink" title="hadoop运行jar包"></a>hadoop运行jar包</h4><p>运行一个mapreduce程序job(打包成一个jar包)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar </span><br><span class="line"><span class="built_in">cd</span> /root/hadoop-2.8.1/share/hadoop/mapreduce</span><br><span class="line"><span class="comment"># 用mapreduce计算圆周率 map的任务数量 每一map的取样数</span></span><br><span class="line">hadoop jar hadoop-mapreduce-examples-2.8.1.jar pi 5 5</span><br><span class="line"><span class="comment"># yarn 创建了tmp ,同时mapreduce程序创建了user目录</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行计算单词出现的次数</span></span><br><span class="line"><span class="comment"># wordcount 将此目录下的所有文件进行统计 结果输出到此目录下</span></span><br><span class="line">vim test.txt</span><br><span class="line">    hello world</span><br><span class="line">    hello femn</span><br><span class="line">    hello leipengkai</span><br><span class="line">    hello friend</span><br><span class="line"></span><br><span class="line">hadoop fs -put test.txt /wordcount/input</span><br><span class="line">hadoop jar hadoop-mapreduce-examples-2.8.1.jar wordcount \</span><br><span class="line">    /wordcount/input /wordcount/output</span><br></pre></td></tr></table></figure></p>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p>处理海量数据的运算, 即使是一个很简单的逻辑,要把它变成分布式运行的程序将会面临很多的其它问题:</p>
<p>运算代码程序的资源分发和启动程序的环境配置,以及代码分发到哪些datanode上,并且还得监控datanode运行状态是否正常 以及datanode的调试汇总</p>
<p>解决思路:运算往数据方移动,而不是数据移动到运算这方来.</p>
<p>MapReduce分成两个步骤去完成业务逻辑:<br>Map逻辑和Reduce逻辑都会在分布在datanode中,先执行Map,再执行Reduce.在Map程序时可高并发执行</p>
<p>实例代码</p>
<pre><code>vim WCMAP.java
</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.wcmapreduce;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapred.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.StringUtils;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4个泛型中,前两个是指定map输入数据类型,KEY是输入的key类型,</span></span><br><span class="line"><span class="comment">// VALUEIN是输入的value的类型,后面两个是map输出给reduce的输出数据类型</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认情况下,框架传递给我们的map的输入数据中,</span></span><br><span class="line"><span class="comment">// key是要处理的文本(block)中一行的起始偏移量,这一行的内容作为value</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WCMap</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>&gt;</span>&#123;</span><br><span class="line"><span class="comment">// Long,String,String,Long等内存对象 经过序列化之后再通过网络传递到节点中</span></span><br><span class="line"><span class="comment">// hadoop实现了自己的序列化机制 去掉多余的java序列化信息	</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> LongWritable one =<span class="keyword">new</span> LongWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line">    <span class="comment">// map()框架第每读一行数据就调用一次该方法,</span></span><br><span class="line">    <span class="comment">// 对节点中的文本处理完所有的map之后才进入reduce</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key,Text value,Context context)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException, InterruptedException</span>&#123;</span><br><span class="line">        <span class="comment">// 具体业务逻辑就写在这个方法体中,而且我们业务要处理的数据已经被框架传递进来</span></span><br><span class="line"><span class="comment">// 在方法的参数中key-value中</span></span><br><span class="line">        <span class="comment">// key是这一行数据的起始偏移量 value是这一行的文本内容 </span></span><br><span class="line">        <span class="comment">// context传到reduce的工具不用自己去找节点</span></span><br><span class="line">        String line = value.toString();</span><br><span class="line">        <span class="keyword">char</span> split = <span class="string">' '</span>;</span><br><span class="line">        String[] words =StringUtils.split(line, split);</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">//遍历这个单词数组输出为k-v形式 k:单词 v:1</span></span><br><span class="line">        <span class="keyword">for</span> (String word: words) &#123;</span><br><span class="line">            context.write(<span class="keyword">new</span> Text(word), <span class="keyword">new</span> LongWritable(<span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">//	 StringTokenizer itr = new StringTokenizer(value.toString());</span></span><br><span class="line"><span class="comment">//	 while(itr.hasMoreTokens()) &#123;</span></span><br><span class="line"><span class="comment">//		 word.set(itr.nextToken());</span></span><br><span class="line"><span class="comment">//		 context.write(word, one);</span></span><br><span class="line"><span class="comment">//		 &#125;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<pre><code>vim WCReduce.java
</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.wcmapreduce;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WCReduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">LongWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 框架在map处理完之后,将所有的k-v缓存起来,进行分级,然后传递一个组,&lt;k,vs&#123;&#125;&gt;</span></span><br><span class="line">    <span class="comment">//调用一次reduce方法  &lt;hello,&#123;1,1...&#125;&gt;</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;LongWritable&gt; values,Context context)</span> </span></span><br><span class="line"><span class="function">                    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line"><span class="comment">//		super.reduce(key, values, context);</span></span><br><span class="line">        <span class="keyword">long</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (LongWritable v:values) &#123;</span><br><span class="line">            count += v.get();</span><br><span class="line">        &#125;</span><br><span class="line">        context.write(key, <span class="keyword">new</span> LongWritable(count));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<pre><code>vim WCRunner.java
</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.wcmapreduce;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="comment">//import org.apache.hadoop.mapred.jobcontrol.Job;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WCRunner</span> </span>&#123;</span><br><span class="line">    <span class="comment">//用来描述一个特定的作业</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"mapreduce.job.jar"</span>,<span class="string">"/root/wc.jar"</span>);    </span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置整个job手忙脚乱的那些类在哪个jar包中</span></span><br><span class="line">        job.setJarByClass(WCRunner.class);</span><br><span class="line">        <span class="comment">//该作业使用哪个类作为逻辑处理中的map,哪个作为reduce</span></span><br><span class="line">        job.setMapperClass(WCMap.class);</span><br><span class="line">        job.setReducerClass(WCReduce.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定map输出数据类型k-v</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定reduce输出数据类型k-v</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//该作业要处理的数据所在的路径以及输出结果存放路径</span></span><br><span class="line">        <span class="comment">// hdfs只有一个test.txt文件</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(<span class="string">"hdfs://cluster1:9000/"</span>));</span><br><span class="line"></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"hdfs://cluster1:9000/wc/output"</span>));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//提交集群运行</span></span><br><span class="line">        <span class="comment">//yarn机制</span></span><br><span class="line">        job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="在本地测试可以启动Bebug模式-直接在虚拟机下用eclipse运行WCRunner"><a href="#在本地测试可以启动Bebug模式-直接在虚拟机下用eclipse运行WCRunner" class="headerlink" title="在本地测试可以启动Bebug模式,直接在虚拟机下用eclipse运行WCRunner"></a>在本地测试可以启动Bebug模式,直接在虚拟机下用eclipse运行WCRunner</h4><p>注意:如果是eclipse它会自动加载core-site.xml和hdfs-site.xml的配置文件,<br>所以可以写成如下,也是读取hdfs文件系统<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(<span class="string">"/"</span>));</span><br><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"/wc/output"</span>));</span><br></pre></td></tr></table></figure></p>
<p>使用dhfs的话,可以不用启动yarn,只启动dhfs,这时的Mapreduce程序将跑在本机<br>不通过yarn分配</p>
<p>如果想要yarn分配在Node Manage运行Mapreduce,则在src下加上mapred-site.xml和yarn-site.xml文件<br>并加上如下代码,再运行<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conf.set(<span class="string">"mapreduce.job.jar"</span>,<span class="string">"/root/wc.jar"</span>);</span><br></pre></td></tr></table></figure></p>
<p>也可以不用从hdfs中读写文件:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(<span class="string">"/root/test.txt"</span>));</span><br><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"/root/output"</span>));</span><br></pre></td></tr></table></figure></p>
<h4 id="在集群中运行-将将整个项目打包成jar-让hadoop-yarn分发运行Mapreduce程序"><a href="#在集群中运行-将将整个项目打包成jar-让hadoop-yarn分发运行Mapreduce程序" class="headerlink" title="在集群中运行,将将整个项目打包成jar,让hadoop yarn分发运行Mapreduce程序"></a>在集群中运行,将将整个项目打包成jar,让hadoop yarn分发运行Mapreduce程序</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm -f -R hdfs://cluster1:9000/*</span><br><span class="line">hadoop fs -put test.txt hdfs://cluster1:9000/</span><br><span class="line">hadoop jar wc.jar cn.itcast.hadoop.wcmapreduce.WCRunner </span><br><span class="line"><span class="comment"># -Dmapreduce.input.fileinputformat.input.dir.recursive=true</span></span><br></pre></td></tr></table></figure>
<p>注意:如果使用jar包运行的话,必须得指定成hdfs的文件系统格式<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(<span class="string">"hdfs://cluster1:9000/"</span>));</span><br><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"hdfs://cluster1:9000/wc/output"</span>));</span><br></pre></td></tr></table></figure></p>
<p>查看运行的结果<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat  hdfs://cluster1:9000/wc/output/part-r-00000</span><br></pre></td></tr></table></figure></p>
<h4 id="将信息打印到控制台"><a href="#将信息打印到控制台" class="headerlink" title="将信息打印到控制台"></a>将信息打印到控制台</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_ROOT_LOGGER=DEBUG,console</span><br></pre></td></tr></table></figure>
<p>总结MR程序的提交运行模式</p>
<pre><code>本地模式
</code></pre><p>在eclipse里面直接运行main方法,不添加mapred-site.xml和yarn-site.xml<br>也会提交给localjobnumber执行,输出输出数据按如下设置保存在对应路径下:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(<span class="string">"/"</span>));</span><br><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"/wc/output"</span>));</span><br></pre></td></tr></table></figure></p>
<pre><code>集群模式运行
</code></pre><ol>
<li><p>将项目打成jar包,上传到服务器上,然后用hadoop命令提交:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar wc.jar cn.itcast.hadoop.wcmapreduce.WCRunner</span><br></pre></td></tr></table></figure>
</li>
<li><p>在eclipse中运行main,在src下加上mapred-site.xml和yarn-site.xml文件<br>并加上如下代码,再运行</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conf.set(<span class="string">"mapreduce.job.jar"</span>,<span class="string">"/root/wc.jar"</span>);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>Map进程数不是由block大小决定的,而是由一个切片(split)对应一个Map进程<br>Map task的并发数量是由切片的数量决定的,有多少个切片就启动多少个Map task</p>
<p>切片是个逻辑概念,指文件中数据中偏移量范围,block是物理概念<br>切片的具体大小应该根据所处理的文件大小来调整</p>
<img src="/2017/09/23/hadoop_mapreduce/shuffle.jpg" title="MapReduce,Shuffle:分组,排序以及各种内存和磁盘缓存机制">
<img src="/2017/09/23/hadoop_mapreduce/yarn.jpg" title="yarn的资源分配和调度">

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/23/hadoop_mapreduce/" data-id="cjgra84qq002105lm148vo2mu" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/23/hadoop_mapreduce/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/23/hadoop_mapreduce/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <article id="post-hadoop_RPC" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/23/hadoop_RPC/">hadoop RPC(三)</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/23/hadoop_RPC/">
            <time datetime="2017-09-23T11:51:15.000Z" itemprop="datePublished">2017-09-23</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/大数据/">大数据</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h4 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h4><p>远程过程调用(RPC):hadoop的节点之间的进程通信(类与类之间),以及与客户端的通信.心跳也是通过RPC完成的<br>为什么datanode定期会向Namenode汇报block信息</p>
<p>RPC的现实技术:动态代理,反射,socker通信生成RPC客户端</p>
<pre><code>serveice
</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.hdfs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.ipc.RPC;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.ipc.RPC.Builder;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.ipc.RPC.Server;</span><br><span class="line"></span><br><span class="line">publci <span class="class"><span class="keyword">class</span> <span class="title">ServiceStart</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> HadoopIllegalArgumentException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        Builder builder = <span class="keyword">new</span> RPC.Builder(<span class="keyword">new</span> Configuration());</span><br><span class="line">        builder.setBindAddress(<span class="string">"cluster1"</span>).setPort(<span class="number">10000</span>)</span><br><span class="line">            .setProtocol(LoginInter.class).setInstance(<span class="keyword">new</span> LoginServer());</span><br><span class="line">        Server server = builder.build();</span><br><span class="line">        server.start();</span><br><span class="line">        <span class="comment">// 多个业务逻辑处理</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.hdfs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginServer</span> <span class="keyword">implements</span> <span class="title">LoginInter</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">login</span><span class="params">(String username, String passwd)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> username + <span class="string">"success!!"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<pre><code>client
</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.hdfs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.InetSocketAddress;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.ipc.RPC;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginControl</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">        LoginInter proxy = RPC.getProxy(LoginInter.class, <span class="number">1L</span>,</span><br><span class="line">         <span class="keyword">new</span> InetSocketAddress(<span class="string">"192.168.1.222"</span>,<span class="number">10000</span>), <span class="keyword">new</span> Configuration());</span><br><span class="line">        String r = proxy.login(<span class="string">"femn"</span>, <span class="string">"femn"</span>);</span><br><span class="line">        System.out.println(r);</span><br><span class="line">        <span class="comment">// 当增加服务器提供服务时,客户端能够感知服务端.</span></span><br><span class="line">        <span class="comment">// 在不改变的情况下,知道去调用新服务器的服务</span></span><br><span class="line">        <span class="comment">// 服务调用动态转发和负载均衡的实现,使用zookeeper可以很容易的实现</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<pre><code>service and client
</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.hdfs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">LoginInter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> versionId=<span class="number">1L</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">login</span><span class="params">(String username,String passwd)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="/2017/09/23/hadoop_RPC/RPC.jpg" title="RPC实现机制">
<img src="/2017/09/23/hadoop_RPC/RPC_zookeeper.jpg" title="zookeeper实现:服务调用动态转发和负载均衡的实现">

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/23/hadoop_RPC/" data-id="cjgra84p6001m05lmw924ig87" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/23/hadoop_RPC/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/23/hadoop_RPC/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <article id="post-hadoop_hdfs" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/23/hadoop_hdfs/">hadoop HDFS(二)</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/23/hadoop_hdfs/">
            <time datetime="2017-09-23T11:41:15.000Z" itemprop="datePublished">2017-09-23</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/大数据/">大数据</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h4 id="hdfs的shell命令"><a href="#hdfs的shell命令" class="headerlink" title="hdfs的shell命令"></a>hdfs的shell命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs  <span class="comment"># 帮助命令</span></span><br><span class="line">hadoop fs -df -h /</span><br><span class="line">hadoop fs -du -s -h hdfs://cluster1:9000/*</span><br><span class="line">hadoop fs -rm -f -R hdfs://cluster1:9000/*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传文件,保存在/root/hadoop-2.8.1/tmp/dfs</span></span><br><span class="line">hadoop fs -put install_hadoop.sh hdfs://cluster1:9000/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载 只是权限变了</span></span><br><span class="line">hadoop fs -get hdfs://cluster1:9000/install_hadoop.sh ./ </span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line">hadoop fs -mkdir -p /wordcount/input <span class="comment"># 同下</span></span><br><span class="line">hadoop fs -mkdir -p hdfs://cluster1:9000/wordcount/input</span><br><span class="line"></span><br><span class="line"><span class="comment"># 浏览器查看文件</span></span><br><span class="line">http://192.168.1.222:50070</span><br><span class="line"><span class="comment"># 通过上面的浏览器--Utilities--Browse the file system就可以看到上传的文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看目录</span></span><br><span class="line">hadoop fs -ls /wordcount/output</span><br><span class="line"><span class="comment"># 查看文件内容</span></span><br><span class="line">hadoop fs -cat /wordcount/output/part-r-00000</span><br></pre></td></tr></table></figure>
<img src="/2017/09/23/hadoop_hdfs/HDFS.jpg" title="HDFS实现机制">
<p>/root/hadoop-2.8.1/tmp/dfs/data/current/BP-XX/current/finalized:保存datanode主机的 block块的地方</p>
<h4 id="java客户端调用HDFS-API"><a href="#java客户端调用HDFS-API" class="headerlink" title="java客户端调用HDFS API"></a>java客户端调用HDFS API</h4><pre><code>安装eclipse,配置所需要的jar包和配置文件
</code></pre><ol>
<li>/root/hadoop-2.8.1/share/hadoop/common/下jar包,以及common jar中的依赖包common/bin 的所有jar</li>
<li>/root/hadoop-2.8.1/share/hadoop/hdfs/下jar包,以及hdfs jar中的依赖包hdfs/bin 的所有jar,以及yarn,mapreduce目录下的</li>
<li><p>将/root/hadoop-2.8.1/etc下的 core-site.xml和hdfs-site.xml文件放在Project的src目录下</p>
<p> <code>代码实现</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.hadoop.hdfs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.compress.utils.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.LocatedFileStatus;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.RemoteIterator;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsUtil</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://cluster1:9000/"</span>);</span><br><span class="line">        <span class="comment">// 设置权限</span></span><br><span class="line">        fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://cluster1:9000/"</span>),conf,</span><br><span class="line">            <span class="string">"root"</span>);</span><br><span class="line">        <span class="comment">//如果在集群中只需要指定dfs.nameservices的值即可:hdfs://ns1/</span></span><br><span class="line">        <span class="comment">//fs需要哪些成员才能读写hdfs文件 </span></span><br><span class="line">        <span class="comment">// fs--&gt;RPCProxy--&gt;NameNode.open(src)</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">download</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// input stream</span></span><br><span class="line">        Path src =<span class="keyword">new</span> Path(<span class="string">"hdfs://cluster1:9000/install_hadoop.sh"</span>);</span><br><span class="line">        FSDataInputStream in =fs.open(src);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//ouput local</span></span><br><span class="line">        FileOutputStream os= </span><br><span class="line">            <span class="keyword">new</span> FileOutputStream(<span class="string">"/root/Downloads/install2.sh"</span>);</span><br><span class="line">        IOUtils.copy(in, os);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">download2</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        fs.copyFromLocalFile(</span><br><span class="line">                <span class="keyword">new</span> Path(<span class="string">"hdfs://cluster1:9000/upload2.txt"</span>),</span><br><span class="line">                <span class="keyword">new</span> Path(<span class="string">"/root/Downloads/install2.sh"</span>)</span><br><span class="line">                );</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">upload</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// to upload a file to hdfs</span></span><br><span class="line">        Path dst =<span class="keyword">new</span> Path(<span class="string">"hdfs://cluster1:9000/upload.txt"</span>);</span><br><span class="line">        FSDataOutputStream os =fs.create(dst);</span><br><span class="line">        </span><br><span class="line">        FileInputStream in= </span><br><span class="line">            <span class="keyword">new</span> FileInputStream(<span class="string">"/root/Downloads/install2.sh"</span>);</span><br><span class="line">        IOUtils.copy(in, os);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">upload2</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        fs.copyFromLocalFile(</span><br><span class="line">                <span class="keyword">new</span> Path(<span class="string">"/root/Downloads/install2.sh"</span>), </span><br><span class="line">                <span class="keyword">new</span> Path(<span class="string">"hdfs://cluster1:9000/a/b/upload2.txt"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">mkdir</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">        </span><br><span class="line">        fs.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/a/b"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rm</span><span class="params">()</span> <span class="keyword">throws</span> IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">        fs.delete(<span class="keyword">new</span> Path(<span class="string">"/a"</span>),<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">listFiles</span><span class="params">()</span> <span class="keyword">throws</span> FileNotFoundException, IllegalArgumentException, IOException </span>&#123;</span><br><span class="line">        RemoteIterator&lt;LocatedFileStatus&gt; files = fs.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">while</span>(files.hasNext()) &#123;</span><br><span class="line"></span><br><span class="line">            LocatedFileStatus file = files.next();</span><br><span class="line">            <span class="comment">//LocatedFileStatus 是通过RPC机制 得到的 fs也是类似</span></span><br><span class="line">            Path filepath = file.getPath();</span><br><span class="line">            String fileName = filepath.getName();</span><br><span class="line">            System.out.println(fileName);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"--------------"</span>);</span><br><span class="line">        FileStatus[] listStatus = fs.listStatus(<span class="keyword">new</span> Path(<span class="string">"/"</span>));</span><br><span class="line">        <span class="keyword">for</span>(FileStatus status: listStatus) &#123;</span><br><span class="line">            String name =status.getPath().getName();</span><br><span class="line">            System.out.println(name);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="权限问题"><a href="#权限问题" class="headerlink" title="权限问题"></a>权限问题</h4><p>如果不是在虚拟机上测试的话,会有权限的问题,需要在eclipse的Run Configuration的Arguments中的VM arguments中增加如下信息<br>-DHADOOP_USER_NAME=root</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/23/hadoop_hdfs/" data-id="cjgra84pi001u05lm0slc4l5i" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/23/hadoop_hdfs/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/23/hadoop_hdfs/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <article id="post-hadoop" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/23/hadoop/">hadoop简介与安装(一)</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/23/hadoop/">
            <time datetime="2017-09-23T11:31:15.000Z" itemprop="datePublished">2017-09-23</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/hadoop/">hadoop</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/大数据/">大数据</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h4 id="介绍hadoop"><a href="#介绍hadoop" class="headerlink" title="介绍hadoop"></a>介绍hadoop</h4><p>在海量数据的场景下,为了解决分布式部署中的公共问题一些框架就出现了hadoop,zookeeper<br>hadoop:由很多的技术框架组成的一个生态系统.它是一个上层的应用软件(java编写的)<br>不关是用来做海量数据储存的,因为在解决海量数据的处理中,解决了一些分布式很共同的问题,把解决这些问题的方法抽离出来,形成各种各样的框架.将这些框架单独拿出来也可以在项目中使用.</p>
<p>hadoop三个主要框架:</p>
<h4 id="海量数据的存储-HDFS-分布式集群的文件系统-区别本机的文件系统"><a href="#海量数据的存储-HDFS-分布式集群的文件系统-区别本机的文件系统" class="headerlink" title="海量数据的存储(HDFS):分布式集群的文件系统,区别本机的文件系统"></a>海量数据的存储(HDFS):分布式集群的文件系统,区别本机的文件系统</h4><h4 id="海量数据的分析-运算模型-MapReduce-分析运算的模型-自己写运算逻辑-程序-写出来的就是MapReduce程序-通过YARM分配到节点之后运行MapReduce程序"><a href="#海量数据的分析-运算模型-MapReduce-分析运算的模型-自己写运算逻辑-程序-写出来的就是MapReduce程序-通过YARM分配到节点之后运行MapReduce程序" class="headerlink" title="海量数据的分析(运算模型)(MapReduce):分析运算的模型,自己写运算逻辑(程序),写出来的就是MapReduce程序,通过YARM分配到节点之后运行MapReduce程序"></a>海量数据的分析(运算模型)(MapReduce):分析运算的模型,自己写运算逻辑(程序),写出来的就是MapReduce程序,通过YARM分配到节点之后运行MapReduce程序</h4><p>Map程序:在不同节点并发运行<br>Reduce程序:全局处理,只在一同节点上运行,通过网络取得Map程序的结果.在分组统计时,Reduce也可以有多个</p>
<p>MapReduce:擅长海量离线日志分析,可由hive工具编写<br>storm:实时的流计算<br>spark:实时的迭代运算</p>
<h4 id="资源管理调度-YARN-集群"><a href="#资源管理调度-YARN-集群" class="headerlink" title="资源管理调度(YARN):集群"></a>资源管理调度(YARN):集群</h4><h4 id="安装hadoop"><a href="#安装hadoop" class="headerlink" title="安装hadoop:"></a>安装hadoop:</h4><p>集群的安装是很繁琐的事,Cloudera这个公司开发的安装系统(脚本)之后,只需要在一个节点,在浏览器中打开Cloudera,然后选择你所需要的服务,点确定之后,所以的程序包自动下载并安装好,同时还提供对集群的管理监控</p>
<p>但个人还是使用apache官方的hadoop</p>
<pre><code>环境为: centos7 + hadoop.2.8.1 + virtualbox5 + jdk8
</code></pre><p>前提:</p>
<ol>
<li><a href="https://www.femn.me/2017/09/20/virtualbox/">virtualbox5网络配置</a>,联网成功</li>
<li>vim /etc/sysconfig/network-scripts/ifcfg-enp0s3 设置IP为192.168.1.222,并重启network</li>
<li>在/root目录下执行如下脚本,并且请在此目录提前下载好hadoop-2.8.1.tar.gz</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://file.femnyy.com/file/install_hadoop.sh | sudo sh</span><br></pre></td></tr></table></figure>
<pre><code>注意:之后的所有操作也是root用户操作
</code></pre><h4 id="访问-http-192-168-1-222-50070"><a href="#访问-http-192-168-1-222-50070" class="headerlink" title="访问:http://192.168.1.222:50070"></a>访问:<a href="http://192.168.1.222:50070" target="_blank" rel="noopener">http://192.168.1.222:50070</a></h4><p>巨坑:所有的服务都成功开启,但就是在主机访问不了,关闭了防火墙也不行,弄了半天的virtualbox的网络设置(自认为是没有错的)也不行,没想到居然是配置文件的问题<br><img src="/2017/09/23/hadoop/error1.png" title="配置文件的巨坑"></p>
<h4 id="centos-7启动图形界面"><a href="#centos-7启动图形界面" class="headerlink" title="centos 7启动图形界面"></a>centos 7启动图形界面</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法一</span></span><br><span class="line">yum group list</span><br><span class="line">yum group install <span class="string">"GNOME Desktop"</span></span><br><span class="line">startx</span><br><span class="line"><span class="comment"># 当重新启动时执行,就可以进入系统了</span></span><br><span class="line"><span class="comment"># You might have to hit 1, then 2 to agree to the license, then C to continue.</span></span><br><span class="line">1--2--c--yes</span><br><span class="line"></span><br><span class="line"><span class="comment"># yum group install "GNOME Desktop" "Graphical Administration Tools"</span></span><br><span class="line"><span class="comment"># 开机时自动就是设置图形界面</span></span><br><span class="line"><span class="comment"># ln -sf /lib/systemd/system/runlevel5.target /etc/systemd/system/default.target </span></span><br><span class="line"><span class="comment"># reboot</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法二</span></span><br><span class="line">init 5</span><br></pre></td></tr></table></figure>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/23/hadoop/" data-id="cjgra84pa001p05lm3opcr6vp" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/23/hadoop/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/23/hadoop/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <article id="post-internet" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 itemprop="name">
            <a class="article-title" href="/2017/09/20/internet/">网络基础与协议</a>
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2017/09/20/internet/">
            <time datetime="2017-09-20T09:52:19.000Z" itemprop="datePublished">2017-09-20</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/server/">server</a>
    </div>

                        
                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>网络就是一种辅助双方或者多方能够连接在一起的工具<br>网络的目的就是为了联通多方然后进行通信用的,即把数据从一方传递给另外一方</p>
<p>而所谓的网络编程就是,让在不同的电脑上的软件能够进行数据传递,即进程之间的通信(网络socket)</p>
<p>不同计算机之间都约定遵守的网络通信协议叫做TCP/IP协议族<br>因为互联网协议包含了上百种协议标准,但是最重要的两个协议是TCP和IP协议,所以,大家把互联网的协议简称TCP/IP协议<br><img src="/2017/09/20/internet/tcp-ip.png" title="常用的电脑之间的数据传输协议 四层模型以及七层模型(OSI)"></p>
<h4 id="网络基础术语"><a href="#网络基础术语" class="headerlink" title="网络基础术语"></a>网络基础术语</h4><p>ip(Internet Protocol)地址:⽤来在⽹络中标记⼀台电脑的⼀串数字(ipv4:32位/ipv6:64位)<br><img src="/2017/09/20/internet/ip-class.png" title="ip地址分类"><br>注意:如下ip网段属于私⽹IP,不在公⽹中使⽤的,它们的范围是:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10.0.0.0～10.255.255.255</span><br><span class="line">172.16.0.0～172.31.255.255</span><br><span class="line">192.168.0.0～192.168.255.255</span><br><span class="line">127.0.0.1~127.255.255.255 <span class="comment"># ⽤于回路测</span></span><br></pre></td></tr></table></figure></p>
<p>⼦⽹掩码(netmask):确定了一个IP地址的32位二进制数字中哪些是网络号,哪些是主机号</p>
<p>端口(Port):区分不同的服务<br>因为IP地址与网络服务(HTTP(万维网服务),FTP(文件传输),SMTP(电子邮件)等)的关系是一对多的关系.<br>实际上是通过”IP地址+端口号”来区分不同的服务的<br>端口区别不同电脑的进程,进程号是区别同一台电脑中的进程</p>
<p>arp协议:通过ip得到mac地址</p>
<p>mac地址(物理地址):产商序列(前3个字节)和网卡序列(后3个字节)组成电脑的唯一标识</p>
<p>交换机(还有路由功能)与集线器(hub:向所有的电脑进行广播):同一网段的直接通信<br>交换机的作⽤:</p>
<ol>
<li>转发过滤:当⼀个数据帧的⽬的地址在MAC地址表中有映射时,它被转发到连接⽬的节点的端⼝⽽不是所有端⼝(如该数据帧为⼴播帧则转发 ⾄所有端⼝)</li>
<li>学习功能:以太⽹交换机了解每⼀端⼝相连设备的MAC地址,并将地址 同相应的端⼝映射起来存放在交换机缓存中的MAC地址表中,但到了一定时间会自动清空<br>如果PC不知⽬标IP所对应的的MAC,那么可以看出,pc会先发送arp⼴ 播,得到对⽅的MAC,然后在进⾏数据的传送<br>当switch第⼀次收到arp⼴播数据,会把arp⼴播数据包转发给所有端⼝ (除来源端⼝);如果以后还有pc询问此IP的MAC,那么只是向⽬标的 端⼝进⾏转发数据</li>
</ol>
<p>rarp协议:根据mac地址找IP</p>
<p>ping 192.168.1.1–&gt;走ICMP协议</p>
<p>网关(Gateway):发送的ip不在同一个网段内,那么会把这个数据发送给默认网关<br>因为跨网之间不能直接通信这是TCP/UDP协议规定的</p>
<p>路由(就是一个网关设备):连接不同网段间的通信,至少两个网卡(同时网卡设置时,必须是不同网段)</p>
<p>RIP(路由协议):多个路由器之间的通信</p>
<p>TTL:指一个数据包在网络上经过路由器数量的最大值(也就是说一个数据包经过了多少个路由器,一般最大值是128)</p>
<p>MSL:一个数据包在网络中存储的最长时间(保证数据包的存活时间,一般是1-2分钟)</p>
<p>NAT(网络地址转换器):私有IP不能直接上网,必须通过路由器的转换成公有IP(也是国内的路由器所具有的功能)</p>
<h4 id="TCP协议"><a href="#TCP协议" class="headerlink" title="TCP协议"></a>TCP协议</h4><p>tcp(传输控制协议)在通信开始之前,⼀定要先建⽴相关的链接,才能发送数据,注重数据传输稳定(一定能接收到)<br><img src="/2017/09/20/internet/tcp.png" title="tcp协议与Socket通信过程"></p>
<p>可以通过packet tracer 来模拟tcp协议的三次握手与四次挥手过程<br><img src="/2017/09/20/internet/tcp2.png" title="tcp协议的三次握手与四次挥手"></p>
<img src="/2017/09/20/internet/tcp-status.png" title="tcp的十种状态和2MSL问题">
<p>即第3次握手完成后发送了第四次握手的ACK包后就进入了TIME_WAIT状态,<br>必须在此状态上停留两倍的MSL时间,等待2MSL时间主要目的是怕最后一个ACK包对方没收到,<br>那么对方在超时后将重发第三次握手的FIN包,主动关闭端接到重发的FIN包后可以再发一个ACK应答包</p>
<p>当是服务先close时,为了避免2MSL的等待状态出现,所导致的端口被占用的问题</p>
<p>serSocket.setsockopt(SOL_SOCKET, SO_REUSEADDR , 1)</p>
<h4 id="TCP通信过程-网络是双向的-所以在手机配置路由协议的时候-返回的路由协议也要配置好"><a href="#TCP通信过程-网络是双向的-所以在手机配置路由协议的时候-返回的路由协议也要配置好" class="headerlink" title="TCP通信过程(网络是双向的,所以在手机配置路由协议的时候,返回的路由协议也要配置好)"></a>TCP通信过程(网络是双向的,所以在手机配置路由协议的时候,返回的路由协议也要配置好)</h4><img src="/2017/09/20/internet/mac-ip.png" title="传递数据包中目标IP始终不变,而MAC在两两设备之间都在变">
<h4 id="UDP广播"><a href="#UDP广播" class="headerlink" title="UDP广播"></a>UDP广播</h4><p>udp(用户数据包协议)通信模型中,在通信开始之前,不需要建⽴相关的链接,只需要发送数据即可,注重速度流畅<br>单播(点对点)<br>多播(一对多)<br>广播(一对所有,只向交换机发一份数据,然后交换机进行广播发送)</p>
<img src="/2017/09/20/internet/tcp-udp.png" title="tcp协议与udp协议通信的区别">
<p>tcp在三次握手过程中的数据格式有syn,syn+ack和ack</p>
<h4 id="TCP长-短连接"><a href="#TCP长-短连接" class="headerlink" title="TCP长/短连接"></a>TCP长/短连接</h4><ol>
<li>⻓连接可以省去较多的TCP建立和关闭的操作,减少浪费,节约时间.对于频繁请求资源的客户来说,较适用⻓连接</li>
<li>短连接对于服务器来说管理较为简单,存在的连接都是有用的连接,不需要额外的控制手段,如果客户请求频繁,将在TCP的建立和关闭操作上浪费时间和带宽</li>
</ol>
<h4 id="处理应用层的HTTP协议-无状态-无连接"><a href="#处理应用层的HTTP协议-无状态-无连接" class="headerlink" title="处理应用层的HTTP协议(无状态,无连接)"></a>处理应用层的HTTP协议(无状态,无连接)</h4><p>应用层的协议:根据应用场景不一样,从而对数据进行不同格式的封装(将应用层的数据能拿到传输层中去send()或rece()</p>
<p>服务器与客户端共同遵守才使得Server-client之间看得懂而进行交流),比如ftp(传输文件),ssh(远程登陆),http(网页),smtp(邮件)</p>
<p>所以应用层要解决的问题是:传递什么数据(封装数据)</p>
<img src="/2017/09/20/internet/udp-tcp-http.png" title="浏览器访问网页的过程">
<p>tcp三次握手之后,使用http协议传输数据报文给下面三层(理解为一个整体快递公司,传输数据方式(快递公司)–&gt;IP(地理位置坐标)–&gt;具体的传输工具)</p>
<p>socket是操作系统提供的tcp/udp传输协议的工具</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">物理层:电器连接</span><br><span class="line">数据链路层:交换机,STP,帧中继</span><br><span class="line">网络层:路由器,IP 协议</span><br><span class="line">传输层:TCP、UDP 协议(socket)</span><br><span class="line"><span class="comment"># http包通过socket方式打包成TCP包</span></span><br><span class="line">会话层:建立通信连接,网络拨号</span><br><span class="line">表示层:每次连接只处理一个请求</span><br><span class="line"><span class="comment"># https(http+ssl):通过对应用层的加密</span></span><br><span class="line">应用层:HTTP、FTP,SSH,SMTP</span><br></pre></td></tr></table></figure>
<p>HTML超文本文件,HTTP:超文本传输协议</p>
<p>http协议的数据包,传输的是html格式文件,而不是字符串格式</p>
<h5 id="http客户端-浏览器-app-爬虫-与服务器如何收发数据"><a href="#http客户端-浏览器-app-爬虫-与服务器如何收发数据" class="headerlink" title="http客户端(浏览器,app,爬虫)与服务器如何收发数据:"></a>http客户端(浏览器,app,爬虫)与服务器如何收发数据:</h5><p>浏览器和服务器都会自动生成socket, 响应头/请求头Content-Length:128响应体/请求体</p>
<p>浏览器引擎:就是解析HTML格式(也可以说是对字符串的解析)成网页的算法,同时也有JS的解析器<br>JS解析器已经脱离了前端发展成Node.js这各后台的服务器了</p>
<p>服务器的开发实际上就是在服务端的rece()和send()之间数据处理开发</p>
<p>http协议是无状态的,一次请求之后就会关闭 http1.0短连接,即使是长连接也是无状态</p>
<p>默认情况下所在HTTP1.1中所有连接都被保持,除非在请求头或响应头中指明要关闭:Connection: Close </p>
<p>Keep-Alive功能使客户端到服务器端的连接持续有效,当出现对服务器的后继请求时,Keep-Alive功能避免了建立或者重新建立连接</p>
<h4 id="URI-全球资源标识"><a href="#URI-全球资源标识" class="headerlink" title="URI:全球资源标识"></a>URI:全球资源标识</h4><p>通过位置来标识:URL:全球资源定位符(Location:表示位于服务器的那个位置)?k=value&amp;(包含在请求头的Query String)<br>通过名字来标识资源:URN(N:Name)</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="https://www.femn.me/2017/09/20/internet/" data-id="cjgra84r8002d05lm24vl6tac" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="https://www.femn.me/2017/09/20/internet/#comments" class="article-comment-link disqus-comment-count" data-disqus-url="https://www.femn.me/2017/09/20/internet/">Comments</a>
    

        </footer>
    </div>
    
</article>



    <nav id="page-nav">
        <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">recent</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/hadoop/">hadoop</a></p>
                            <p class="item-title"><a href="/2017/09/28/storm/" class="title">hadoop storm(八)</a></p>
                            <p class="item-date"><time datetime="2017-09-28T11:41:15.000Z" itemprop="datePublished">2017-09-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/hadoop/">hadoop</a></p>
                            <p class="item-title"><a href="/2017/09/28/hbase/" class="title">hadoop hbase(七)</a></p>
                            <p class="item-date"><time datetime="2017-09-28T11:31:15.000Z" itemprop="datePublished">2017-09-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/hadoop/">hadoop</a></p>
                            <p class="item-title"><a href="/2017/09/27/hadoop_cluster/" class="title">hadoop HDFS HA高可用的集群搭建部署(六)</a></p>
                            <p class="item-date"><time datetime="2017-09-27T11:41:15.000Z" itemprop="datePublished">2017-09-27</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/hadoop/">hadoop</a></p>
                            <p class="item-title"><a href="/2017/09/27/hadoop_hive/" class="title">hadoop hive(五)</a></p>
                            <p class="item-date"><time datetime="2017-09-27T11:31:15.000Z" itemprop="datePublished">2017-09-27</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"></p>
                            <p class="item-title"><a href="/2017/09/25/zookeeper/" class="title">zookeeper(五)</a></p>
                            <p class="item-date"><time datetime="2017-09-25T12:01:15.000Z" itemprop="datePublished">2017-09-25</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DRF/">DRF</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/docker/">docker</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python3/">python3</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/server/">server</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/shell/">shell</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/tool/">tool</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a><span class="category-list-count">2</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a><span class="archive-list-count">14</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a><span class="archive-list-count">54</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Django/">Django</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/server/">server</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/计算机/">计算机</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面向对象/">面向对象</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/server/" style="font-size: 10px;">server</a> <a href="/tags/大数据/" style="font-size: 20px;">大数据</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/计算机/" style="font-size: 10px;">计算机</a> <a href="/tags/面向对象/" style="font-size: 10px;">面向对象</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
                    <li>
                        <a href="https://hub.docker.com/">Hub_docker</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2018 leipengkai<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        
    
    <script>
    var disqus_config = function () {
        
        this.page.identifier = '';
    };
    (function() { 
        var d = document, s = d.createElement('script');  
        s.src = '//' + 'femn' + '.disqus.com/count.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>




    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>