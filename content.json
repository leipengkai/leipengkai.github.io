{"meta":{"title":"Femn","subtitle":null,"description":null,"author":"leipengkai","url":"https://www.femn.me"},"pages":[{"title":"About","date":"2017-09-01T03:47:38.085Z","updated":"2017-09-01T03:47:38.057Z","comments":true,"path":"about/index.html","permalink":"https://www.femn.me/about/index.html","excerpt":"","text":"为什么写博客初衷:为了解决有点健忘的毛病,同时也记录自己学习和成长的过程后续:希望通过写博客来学习和巩固更加的技能知识,不断的提高自己的水平 自述(学习-运动-游戏-工作)学习从小学到大学基本概括为中等偏上吧,一直中规中矩的学习.运动从初中一直到现在. 初中:在初中的一个暑假,我来到北京的大舅家,通过两个月的吃喝我成功变成了一个胖子,所以初中同学就叫我红胖子(当时比较开朗和搞笑),因为这样我才有机会让自己运动起来,并一直保持到现在,这也是我人生中的一个重大的事件 高中: 报了体育特长生 大学: 大一到大学三上学期,一直都挺充实的:自学吉它(最好时的水平能弹卡农,成功),还学过画画(失败),其余的时间图书馆(现在只记得看过哪几大类的书).从大三下学期起,上面的这些爱好的时间的占用率就明显减少了很多,因为LOL出现在我的生活中了,LOL从2013年一直影响到2015年年底 工作: 2014当过半年的健身教练,因为半年来一直没有业绩(当时不知道没有业绩的人,老板是很讨厌的),然后大概是外出去售健身卡,有一天我没有去(可能是感觉有点骗人,或者说是自己心里过意不去,就不想去售健身卡),然后大晚上的,Boss就来到我的住处,当时我正在玩LOL(下班之后玩会). 我只记得他说:看你住的地方(比较乱),再看看你的业绩,怎么对得起你的母校!然后我就被开了.解释下这半年的工作我是很开心的,因为是自己喜欢的,而且也很拼命的锻炼自己,业绩问题是希望自己多学点技能之后,对会员有实质的帮助之后,再去开会员(自己的嘴巴也笨). 2015年 在广东的电子厂工作7-8个月,这是被迫的,当时也不想去找教练方面的工作,所以是很不高兴的,这几个月的时间里,相当于是浪费了吧,只是偶尔还会看看健身方面的东西,但也是表面上的,而下班之后又会玩LOL. 当然这个工作真的做的不开心,所以离职了.在家里玩了一个月的LOL(电子厂都不想去,那还能去做什么),这给家里人急的啊,我妈妈都哭了几次,我爸也愁啊(爸爸妈妈真的辛苦了!).当时家人叫我去学电脑,而我还是想去学健身,同时我也意识到我不能再玩LOL了.最后我还是北上去学电脑了(在这里还得谢谢我大舅这个方案,同时我在培训的期间我只玩过一次LOL,在毕业后的几天中玩过几次) 培训:我人生中的又一大转折点,又让我回归到有技术含量的行列中了,同时也很幸运是孙鹏当我们的老师,教了我们很多知识(包括一些好玩好用的东西),不至于成为这个世纪的文盲,同时也让我知道真正的大神不仅仅技术牛逼,而且人品也是好得没话说. 再次工作:遇到了我大哥,在工作技术,生活方式,人际关系处理上都给了我很大的帮助,主要也是我们玩得来.同时我也真正戒掉LOL. 经验:学习用心用时,运动的话就两个字坚持,游戏适当(本人已经不敢玩),工作的话就认真写代码,保持危机感"},{"title":"docker","date":"2017-08-12T07:53:58.000Z","updated":"2017-08-11T23:53:58.557Z","comments":true,"path":"docker/index-1.html","permalink":"https://www.femn.me/docker/index-1.html","excerpt":"","text":""},{"title":"docker","date":"2017-08-04T15:15:20.000Z","updated":"2017-08-04T07:16:52.895Z","comments":true,"path":"docker/index.html","permalink":"https://www.femn.me/docker/index.html","excerpt":"","text":""},{"title":"linux","date":"2017-08-05T11:14:36.000Z","updated":"2017-08-05T03:15:49.649Z","comments":true,"path":"linux/index.html","permalink":"https://www.femn.me/linux/index.html","excerpt":"","text":""},{"title":"python3","date":"2017-08-04T08:08:47.000Z","updated":"2017-08-04T00:10:32.390Z","comments":true,"path":"python3/index.html","permalink":"https://www.femn.me/python3/index.html","excerpt":"","text":""},{"title":"python3","date":"2017-08-12T07:56:08.000Z","updated":"2017-08-11T23:56:08.130Z","comments":true,"path":"python3/index-1.html","permalink":"https://www.femn.me/python3/index-1.html","excerpt":"","text":""},{"title":"Tags","date":"2017-09-01T00:27:16.145Z","updated":"2017-08-03T13:35:35.368Z","comments":true,"path":"tags/index.html","permalink":"https://www.femn.me/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2017-08-12T08:17:15.000Z","updated":"2017-08-12T00:17:15.977Z","comments":true,"path":"categories/index-1.html","permalink":"https://www.femn.me/categories/index-1.html","excerpt":"","text":""},{"title":"Categories","date":"2017-09-01T00:27:16.141Z","updated":"2017-08-03T13:35:35.368Z","comments":true,"path":"categories/index.html","permalink":"https://www.femn.me/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-08-12T08:17:04.000Z","updated":"2017-08-12T00:17:04.517Z","comments":true,"path":"tags/index-1.html","permalink":"https://www.femn.me/tags/index-1.html","excerpt":"","text":""}],"posts":[{"title":"hadoop hive","slug":"hadoop_hive","date":"2017-09-27T11:41:15.000Z","updated":"2017-09-26T12:19:52.446Z","comments":true,"path":"2017/09/27/hadoop_hive/","link":"","permalink":"https://www.femn.me/2017/09/27/hadoop_hive/","excerpt":"","text":"hadoop工具:hive:它只是一个工具可在任意一个节点安装，和集群没有任何关系,hbase数据统计分量 install mysql12345678910111213141516# https://dev.mysql.com/downloads/repo/yum/ 查看对应版本wget https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpmrpm -ivh mysql57-community-release-el7-9.noarch.rpmyum install -y mysql-serverecho \"skip-grant-tables\" &gt;&gt; /etc/my.cnf systemctl start mysqldmysql -uroot -proot flush privileges; ALTER USER 'root'@'localhost' IDENTIFIED BY 'root';sed -i -e '/^skip-grant-tables/d' /etc/my.cnf systemctl restart mysqldmysql -uroot -proot CREATE DATABASE `hive` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci; grant all privileges on *.* to root@localhost identified by 'root'; flush privileges;echo \"skip-grant-tables\" &gt;&gt; /etc/my.cnf cd /roottar -zxvf apache-hive-2.1.1-bin.tar.gzmv apache-hive-2.1.1-bin hivemv hive hadoop-2.8.1/ hive/lib目录下放mysql.jar1scp ./mysql-connector-java-5.1.44-bin.jar root@cluster1:/root/hadoop-2.8.1/hive/lib/ cd hadoop-2.8.1/hive/conf/ cp hive-default.xml.template hive-site.xmlvim hive-site.xml javax.jdo.option.ConnectionURL jdbc:mysql://localhost:3306/hive?useSSL=false javax.jdo.option.ConnectionDriverName com.mysql.jdbc.Driver javax.jdo.option.ConnectionUserName root javax.jdo.option.ConnectionPassword root hive.metastore.schema.verification false 配置环境变量 echo \"export HIVE_HOME=/root/hadoop-2.8.1/hive\" &gt;&gt; ~/.bashrc echo \"export PATH=\\${PATH}:\\${HIVE_HOME}/bin\" &gt;&gt; ~/.bashrc source ~/.bashrc hive在第一次登录的时候需要用如下命令初始化schematool -dbType mysql -initSchemahive –service metastore &amp; create database cluster1;user cluster1;create table order(id int,name string,money string);数据本来只那里,只能用来查看","categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://www.femn.me/categories/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://www.femn.me/tags/大数据/"}]},{"title":"zookeeper","slug":"zookeeper","date":"2017-09-25T12:01:15.000Z","updated":"2017-09-26T01:40:12.998Z","comments":true,"path":"2017/09/25/zookeeper/","link":"","permalink":"https://www.femn.me/2017/09/25/zookeeper/","excerpt":"","text":"Zookeeper是Google的Chubby的一个开源的实现,是Hadoop的分布协调服务,它包含一个简单的原语集,分布式应用程序可以基于它实现同步服务,配置维护和命名服务等,保证hadoop的HA(高可用),它本身也是个集群(提供少量数据的存储和管理) 大部分分布式应用需要一个主控,协调器或控制器来管理物理分布的子进程(资源，任务分配等)Zookeeper:提供通用的分布式锁服务,用以协调分布式应用 Zookeeper安装和配置(集群模式)在一台虚拟机上运行如下脚本1curl https://file.femnyy.com/file/install_zookeeper.sh |sudo sh 准备工作 clone三台之后,修改主机名为zookeeper1,zookeeper2,zookeeper3,修改/etc/hosts 修改IP /etc/sysconfig/network-scripts/ 在的三个IP 关闭防火墙 ssh免登陆 安装JDK,配置环境变量 zoo.conf的配置dataDir中的目录下创建一个myid文件再修改vim /root/zookeeper-3.4.10/data/myid 对应的Id号启动Zookeeper:12# 在三台虚拟机中都执行zkServer.sh start 查看Zookeeper状态:12# 在三台虚拟机中都执行zkServer.sh status 提供一个命令行的客户端123456789zkCli.shhelp# 创建一个共同的配置文件,所有的zookeeper集群都能访问到create /zp241 path:/home/femn/ get /zp241 # 启动另一个虚拟机的命令行客户端也可以看到上传的内容zkCli.shget /zp241 quit zookeeper管理客户所存放的数据采用的是类似于文件树的结构每一个节点叫做一个node:节点分为两种类型短暂的和持久短暂的Node的客户端会话结束时,zookeeper会将该短暂的node删除，同时 短暂的node不可以有子节点","categories":[],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://www.femn.me/tags/大数据/"}]},{"title":"hadoop MapReduce","slug":"hadoop_mapreduce","date":"2017-09-23T12:01:15.000Z","updated":"2017-09-25T01:04:26.079Z","comments":true,"path":"2017/09/23/hadoop_mapreduce/","link":"","permalink":"https://www.femn.me/2017/09/23/hadoop_mapreduce/","excerpt":"","text":"hadoop运行jar包运行一个mapreduce程序job(打包成一个jar包)1234567891011121314151617hadoop jar cd /root/hadoop-2.8.1/share/hadoop/mapreduce# 用mapreduce计算圆周率 map的任务数量 每一map的取样数hadoop jar hadoop-mapreduce-examples-2.8.1.jar pi 5 5# yarn 创建了tmp ,同时mapreduce程序创建了user目录# 运行计算单词出现的次数# wordcount 将此目录下的所有文件进行统计 结果输出到此目录下vim test.txt hello world hello femn hello leipengkai hello friendhadoop fs -put test.txt /wordcount/inputhadoop jar hadoop-mapreduce-examples-2.8.1.jar wordcount \\ /wordcount/input /wordcount/output MapReduce处理海量数据的运算, 即使是一个很简单的逻辑,要把它变成分布式运行的程序将会面临很多的其它问题: 运算代码程序的资源分发和启动程序的环境配置,以及代码分发到哪些datanode上,并且还得监控datanode运行状态是否正常 以及datanode的调试汇总 解决思路:运算往数据方移动,而不是数据移动到运算这方来. MapReduce分成两个步骤去完成业务逻辑:Map逻辑和Reduce逻辑都会在分布在datanode中,先执行Map,再执行Reduce.在Map程序时可高并发执行 实例代码 vim WCMAP.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344package cn.itcast.hadoop.wcmapreduce;import java.io.IOException;import java.util.StringTokenizer;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapred.OutputCollector;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.util.StringUtils;// 4个泛型中,前两个是指定map输入数据类型,KEY是输入的key类型,// VALUEIN是输入的value的类型,后面两个是map输出给reduce的输出数据类型// 默认情况下,框架传递给我们的map的输入数据中,// key是要处理的文本(block)中一行的起始偏移量,这一行的内容作为valuepublic class WCMap extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt;&#123;// Long,String,String,Long等内存对象 经过序列化之后再通过网络传递到节点中// hadoop实现了自己的序列化机制 去掉多余的java序列化信息 private final static LongWritable one =new LongWritable(1); private Text word = new Text(); // map()框架第每读一行数据就调用一次该方法, // 对节点中的文本处理完所有的map之后才进入reduce protected void map(LongWritable key,Text value,Context context) throws IOException, InterruptedException&#123; // 具体业务逻辑就写在这个方法体中,而且我们业务要处理的数据已经被框架传递进来// 在方法的参数中key-value中 // key是这一行数据的起始偏移量 value是这一行的文本内容 // context传到reduce的工具不用自己去找节点 String line = value.toString(); char split = ' '; String[] words =StringUtils.split(line, split); // //遍历这个单词数组输出为k-v形式 k:单词 v:1 for (String word: words) &#123; context.write(new Text(word), new LongWritable(1)); &#125;// StringTokenizer itr = new StringTokenizer(value.toString());// while(itr.hasMoreTokens()) &#123;// word.set(itr.nextToken());// context.write(word, one);// &#125; &#125;&#125; vim WCReduce.java 123456789101112131415161718192021222324package cn.itcast.hadoop.wcmapreduce;import java.io.IOException;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Reducer;public class WCReduce extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt; &#123; // 框架在map处理完之后,将所有的k-v缓存起来,进行分级,然后传递一个组,&lt;k,vs&#123;&#125;&gt; //调用一次reduce方法 &lt;hello,&#123;1,1...&#125;&gt; @Override protected void reduce(Text key, Iterable&lt;LongWritable&gt; values,Context context) throws IOException, InterruptedException &#123; // TODO Auto-generated method stub// super.reduce(key, values, context); long count = 0; for (LongWritable v:values) &#123; count += v.get(); &#125; context.write(key, new LongWritable(count)); &#125;&#125; vim WCRunner.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package cn.itcast.hadoop.wcmapreduce;import java.io.IOException;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;//import org.apache.hadoop.mapred.jobcontrol.Job;public class WCRunner &#123; //用来描述一个特定的作业 public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; // TODO Auto-generated method stub Configuration conf = new Configuration(); conf.set(\"mapreduce.job.jar\",\"/root/wc.jar\"); Job job = Job.getInstance(conf); //设置整个job手忙脚乱的那些类在哪个jar包中 job.setJarByClass(WCRunner.class); //该作业使用哪个类作为逻辑处理中的map,哪个作为reduce job.setMapperClass(WCMap.class); job.setReducerClass(WCReduce.class); //指定map输出数据类型k-v job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(LongWritable.class); //指定reduce输出数据类型k-v job.setOutputKeyClass(Text.class); job.setOutputValueClass(LongWritable.class); //该作业要处理的数据所在的路径以及输出结果存放路径 // hdfs只有一个test.txt文件 FileInputFormat.setInputPaths(job, new Path(\"hdfs://cluster1:9000/\")); FileOutputFormat.setOutputPath(job, new Path(\"hdfs://cluster1:9000/wc/output\")); //提交集群运行 //yarn机制 job.waitForCompletion(true); &#125;&#125; 在本地测试可以启动Bebug模式,直接在虚拟机下用eclipse运行WCRunner注意:如果是eclipse它会自动加载core-site.xml和hdfs-site.xml的配置文件,所以可以写成如下,也是读取hdfs文件系统12FileInputFormat.setInputPaths(job, new Path(\"/\"));FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\")); 使用dhfs的话，可以不用启动yarn,只启动dhfs，这时的Mapreduce程序将跑在本机不通过yarn分配 如果想要yarn分配在Node Manage运行Mapreduce,则在src下加上mapred-site.xml和yarn-site.xml文件并加上如下代码,再运行1conf.set(\"mapreduce.job.jar\",\"/root/wc.jar\"); 也可以不用从hdfs中读写文件:12FileInputFormat.setInputPaths(job, new Path(\"/root/test.txt\"));FileOutputFormat.setOutputPath(job, new Path(\"/root/output\")); 在集群中运行,将将整个项目打包成jar,让hadoop yarn分发运行Mapreduce程序1234hadoop fs -rm -f -R hdfs://cluster1:9000/*hadoop fs -put test.txt hdfs://cluster1:9000/hadoop jar wc.jar cn.itcast.hadoop.wcmapreduce.WCRunner # -Dmapreduce.input.fileinputformat.input.dir.recursive=true 注意:如果使用jar包运行的话，必须得指定成hdfs的文件系统格式12FileInputFormat.setInputPaths(job, new Path(\"hdfs://cluster1:9000/\"));FileOutputFormat.setOutputPath(job, new Path(\"hdfs://cluster1:9000/wc/output\")); 查看运行的结果1hadoop fs -cat hdfs://cluster1:9000/wc/output/part-r-00000 将信息打印到控制台1export HADOOP_ROOT_LOGGER=DEBUG,console vim flow.txt 13431776451 100 500 12947589034 1000 100000 12935848599 100000 50000000hadoop fs -rm -f -R hdfs://cluster1:9000/*hadoop fs -put flow.txt hdfs://cluster1:9000/hadoop jar flow.jar cn.itcast.hadoop.flowsum.FlowRunner hdfs://cluster1:9000/ hdfs://cluster1:9000/wc/ouput总结MR程序的提交运行模式 本地模式 在eclipse里面直接运行main方法,不添加mapred-site.xml和yarn-site.xml也会提交给localjobnumber执行,输出输出数据按如下设置保存在对应路径下:12FileInputFormat.setInputPaths(job, new Path(\"/\"));FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\")); 集群模式运行 将项目打成jar包,上传到服务器上，然后用hadoop命令提交: 1hadoop jar wc.jar cn.itcast.hadoop.wcmapreduce.WCRunner 在eclipse中运行main,在src下加上mapred-site.xml和yarn-site.xml文件并加上如下代码,再运行 1conf.set(\"mapreduce.job.jar\",\"/root/wc.jar\"); Map进程数不是由block大小决定的,而是由一个切片(split)对应一个Map进程Map task的并发数量是由切片的数量决定的,有多少个切片就启动多少个Map task 切片是个逻辑概念,指文件中数据中偏移量范围,block是物理概念切片的具体大小应该根据所处理的文件大小来调整","categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://www.femn.me/categories/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://www.femn.me/tags/大数据/"}]},{"title":"hadoop MapReduce","slug":"hadoop_MapReduce","date":"2017-09-23T12:01:15.000Z","updated":"2017-09-25T02:28:45.013Z","comments":true,"path":"2017/09/23/hadoop_MapReduce/","link":"","permalink":"https://www.femn.me/2017/09/23/hadoop_MapReduce/","excerpt":"","text":"hadoop运行jar包运行一个mapreduce程序job(打包成一个jar包)1234567891011121314151617hadoop jar cd /root/hadoop-2.8.1/share/hadoop/mapreduce# 用mapreduce计算圆周率 map的任务数量 每一map的取样数hadoop jar hadoop-mapreduce-examples-2.8.1.jar pi 5 5# yarn 创建了tmp ,同时mapreduce程序创建了user目录# 运行计算单词出现的次数# wordcount 将此目录下的所有文件进行统计 结果输出到此目录下vim test.txt hello world hello femn hello leipengkai hello friendhadoop fs -put test.txt /wordcount/inputhadoop jar hadoop-mapreduce-examples-2.8.1.jar wordcount \\ /wordcount/input /wordcount/output MapReduce处理海量数据的运算, 即使是一个很简单的逻辑,要把它变成分布式运行的程序将会面临很多的其它问题: 运算代码程序的资源分发和启动程序的环境配置,以及代码分发到哪些datanode上,并且还得监控datanode运行状态是否正常 以及datanode的调试汇总 解决思路:运算往数据方移动,而不是数据移动到运算这方来. MapReduce分成两个步骤去完成业务逻辑:Map逻辑和Reduce逻辑都会在分布在datanode中,先执行Map,再执行Reduce.在Map程序时可高并发执行 实例代码 vim WCMAP.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344package cn.itcast.hadoop.wcmapreduce;import java.io.IOException;import java.util.StringTokenizer;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapred.OutputCollector;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.util.StringUtils;// 4个泛型中,前两个是指定map输入数据类型,KEY是输入的key类型,// VALUEIN是输入的value的类型,后面两个是map输出给reduce的输出数据类型// 默认情况下,框架传递给我们的map的输入数据中,// key是要处理的文本(block)中一行的起始偏移量,这一行的内容作为valuepublic class WCMap extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt;&#123;// Long,String,String,Long等内存对象 经过序列化之后再通过网络传递到节点中// hadoop实现了自己的序列化机制 去掉多余的java序列化信息 private final static LongWritable one =new LongWritable(1); private Text word = new Text(); // map()框架第每读一行数据就调用一次该方法, // 对节点中的文本处理完所有的map之后才进入reduce protected void map(LongWritable key,Text value,Context context) throws IOException, InterruptedException&#123; // 具体业务逻辑就写在这个方法体中,而且我们业务要处理的数据已经被框架传递进来// 在方法的参数中key-value中 // key是这一行数据的起始偏移量 value是这一行的文本内容 // context传到reduce的工具不用自己去找节点 String line = value.toString(); char split = ' '; String[] words =StringUtils.split(line, split); // //遍历这个单词数组输出为k-v形式 k:单词 v:1 for (String word: words) &#123; context.write(new Text(word), new LongWritable(1)); &#125;// StringTokenizer itr = new StringTokenizer(value.toString());// while(itr.hasMoreTokens()) &#123;// word.set(itr.nextToken());// context.write(word, one);// &#125; &#125;&#125; vim WCReduce.java 123456789101112131415161718192021222324package cn.itcast.hadoop.wcmapreduce;import java.io.IOException;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Reducer;public class WCReduce extends Reducer&lt;Text, LongWritable, Text, LongWritable&gt; &#123; // 框架在map处理完之后,将所有的k-v缓存起来,进行分级,然后传递一个组,&lt;k,vs&#123;&#125;&gt; //调用一次reduce方法 &lt;hello,&#123;1,1...&#125;&gt; @Override protected void reduce(Text key, Iterable&lt;LongWritable&gt; values,Context context) throws IOException, InterruptedException &#123; // TODO Auto-generated method stub// super.reduce(key, values, context); long count = 0; for (LongWritable v:values) &#123; count += v.get(); &#125; context.write(key, new LongWritable(count)); &#125;&#125; vim WCRunner.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package cn.itcast.hadoop.wcmapreduce;import java.io.IOException;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;//import org.apache.hadoop.mapred.jobcontrol.Job;public class WCRunner &#123; //用来描述一个特定的作业 public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException &#123; // TODO Auto-generated method stub Configuration conf = new Configuration(); conf.set(\"mapreduce.job.jar\",\"/root/wc.jar\"); Job job = Job.getInstance(conf); //设置整个job手忙脚乱的那些类在哪个jar包中 job.setJarByClass(WCRunner.class); //该作业使用哪个类作为逻辑处理中的map,哪个作为reduce job.setMapperClass(WCMap.class); job.setReducerClass(WCReduce.class); //指定map输出数据类型k-v job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(LongWritable.class); //指定reduce输出数据类型k-v job.setOutputKeyClass(Text.class); job.setOutputValueClass(LongWritable.class); //该作业要处理的数据所在的路径以及输出结果存放路径 // hdfs只有一个test.txt文件 FileInputFormat.setInputPaths(job, new Path(\"hdfs://cluster1:9000/\")); FileOutputFormat.setOutputPath(job, new Path(\"hdfs://cluster1:9000/wc/output\")); //提交集群运行 //yarn机制 job.waitForCompletion(true); &#125;&#125; 在本地测试可以启动Bebug模式,直接在虚拟机下用eclipse运行WCRunner注意:如果是eclipse它会自动加载core-site.xml和hdfs-site.xml的配置文件,所以可以写成如下,也是读取hdfs文件系统12FileInputFormat.setInputPaths(job, new Path(\"/\"));FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\")); 使用dhfs的话，可以不用启动yarn,只启动dhfs，这时的Mapreduce程序将跑在本机不通过yarn分配 如果想要yarn分配在Node Manage运行Mapreduce,则在src下加上mapred-site.xml和yarn-site.xml文件并加上如下代码,再运行1conf.set(\"mapreduce.job.jar\",\"/root/wc.jar\"); 也可以不用从hdfs中读写文件:12FileInputFormat.setInputPaths(job, new Path(\"/root/test.txt\"));FileOutputFormat.setOutputPath(job, new Path(\"/root/output\")); 在集群中运行,将将整个项目打包成jar,让hadoop yarn分发运行Mapreduce程序1234hadoop fs -rm -f -R hdfs://cluster1:9000/*hadoop fs -put test.txt hdfs://cluster1:9000/hadoop jar wc.jar cn.itcast.hadoop.wcmapreduce.WCRunner # -Dmapreduce.input.fileinputformat.input.dir.recursive=true 注意:如果使用jar包运行的话，必须得指定成hdfs的文件系统格式12FileInputFormat.setInputPaths(job, new Path(\"hdfs://cluster1:9000/\"));FileOutputFormat.setOutputPath(job, new Path(\"hdfs://cluster1:9000/wc/output\")); 查看运行的结果1hadoop fs -cat hdfs://cluster1:9000/wc/output/part-r-00000 将信息打印到控制台1export HADOOP_ROOT_LOGGER=DEBUG,console vim flow.txt 13431776451 100 500 12947589034 1000 100000 12935848599 100000 50000000hadoop fs -rm -f -R hdfs://cluster1:9000/*hadoop fs -put flow.txt hdfs://cluster1:9000/hadoop jar flow.jar cn.itcast.hadoop.flowsum.FlowRunner hdfs://cluster1:9000/ hdfs://cluster1:9000/wc/ouput总结MR程序的提交运行模式 本地模式 在eclipse里面直接运行main方法,不添加mapred-site.xml和yarn-site.xml也会提交给localjobnumber执行,输出输出数据按如下设置保存在对应路径下:12FileInputFormat.setInputPaths(job, new Path(\"/\"));FileOutputFormat.setOutputPath(job, new Path(\"/wc/output\")); 集群模式运行 将项目打成jar包,上传到服务器上，然后用hadoop命令提交: 1hadoop jar wc.jar cn.itcast.hadoop.wcmapreduce.WCRunner 在eclipse中运行main,在src下加上mapred-site.xml和yarn-site.xml文件并加上如下代码,再运行 1conf.set(\"mapreduce.job.jar\",\"/root/wc.jar\"); Map进程数不是由block大小决定的,而是由一个切片(split)对应一个Map进程Map task的并发数量是由切片的数量决定的,有多少个切片就启动多少个Map task 切片是个逻辑概念,指文件中数据中偏移量范围,block是物理概念切片的具体大小应该根据所处理的文件大小来调整 Shuffle:分组,排序以及各种内存和磁盘缓存机制","categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://www.femn.me/categories/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://www.femn.me/tags/大数据/"}]},{"title":"hadoop RPC","slug":"hadoop_RPC","date":"2017-09-23T11:51:15.000Z","updated":"2017-09-25T08:53:57.908Z","comments":true,"path":"2017/09/23/hadoop_RPC/","link":"","permalink":"https://www.femn.me/2017/09/23/hadoop_RPC/","excerpt":"","text":"RPC远程过程调用(RPC):hadoop的节点之间的进程通信(类与类之间),以及与客户端的通信.心跳也是通过RPC完成的为什么datanode定期会向Namenode汇报block信息 RPC的现实技术:动态代理,反射,socker通信生成RPC客户端 serveice 123456789101112131415161718192021package cn.itcast.hadoop.hdfs;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.ipc.RPC;import org.apache.hadoop.ipc.RPC.Builder;import org.apache.hadoop.ipc.RPC.Server;publci class ServiceStart&#123; public static void main(String[] args) throws HadoopIllegalArgumentException, IOException &#123; Builder builder = new RPC.Builder(new Configuration()); builder.setBindAddress(\"cluster1\").setPort(10000) .setProtocol(LoginInter.class).setInstance(new LoginServer()); Server server = builder.build(); server.start(); // 多个业务逻辑处理 &#125;&#125; 12345678package cn.itcast.hadoop.hdfs;public class LoginServer implements LoginInter &#123; @Override public String login(String username, String passwd) &#123; return username + \"success!!\"; &#125;&#125; client 123456789101112131415161718192021package cn.itcast.hadoop.hdfs;import java.io.IOException;import java.net.InetSocketAddress;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.ipc.RPC;public class LoginControl &#123; public static void main(String[] args) throws IOException &#123; // TODO Auto-generated method stub LoginInter proxy = RPC.getProxy(LoginInter.class, 1L, new InetSocketAddress(\"192.168.1.222\",10000), new Configuration()); String r = proxy.login(\"femn\", \"femn\"); System.out.println(r); // 当增加服务器提供服务时,客户端能够感知服务端. // 在不改变的情况下,知道去调用新服务器的服务 // 服务调用动态转发和负载均衡的实现,使用zookeeper可以很容易的实现 &#125;&#125; service and client 123456package cn.itcast.hadoop.hdfs;public interface LoginInter &#123; public static final long versionId=1L; public String login(String username,String passwd);&#125;","categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://www.femn.me/categories/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://www.femn.me/tags/大数据/"}]},{"title":"hadoop HDFS","slug":"hadoop_hdfs","date":"2017-09-23T11:41:15.000Z","updated":"2017-09-26T12:00:43.356Z","comments":true,"path":"2017/09/23/hadoop_hdfs/","link":"","permalink":"https://www.femn.me/2017/09/23/hadoop_hdfs/","excerpt":"","text":"hdfs的shell命令/root/hadoop-2.8.1/tmp/dfs/namesecondary/current:保存namenode主机的文件/root/hadoop-2.8.1/tmp/dfs/data/current/BP-992785269-127.0.0.1-1505977526476/current/finalized:保存datanode主机的 block块的地方 1234567891011121314151617181920212223hadoop fs # 帮助命令hadoop fs -df -h /hadoop fs -du -s -h hdfs://cluster1:9000/*hadoop fs -rm -f -R hdfs://cluster1:9000/*# 上传文件,保存在/root/hadoop-2.8.1/tmp/dfshadoop fs -put install_hadoop.sh hdfs://cluster1:9000/# 下载 只是权限变了hadoop fs -get hdfs://cluster1:9000/install_hadoop.sh ./ # 创建目录hadoop fs -mkdir -p /wordcount/input # 同下hadoop fs -mkdir -p hdfs://cluster1:9000/wordcount/input# 浏览器查看文件http://192.168.1.222:50070# 通过上面的浏览器--Utilities--Browse the file system就可以看到上传的文件# 查看目录hadoop fs -ls /wordcount/output# 查看文件内容hadoop fs -cat /wordcount/output/part-r-00000 java客户端调用HDFS API安装eclipse,配置所需要的jar包和配置文件 /root/hadoop-2.8.1/share/hadoop/common/下jar包,以及common jar中的依赖包common/bin 的所有jar /root/hadoop-2.8.1/share/hadoop/hdfs/下jar包,以及hdfs jar中的依赖包hdfs/bin 的所有jar,以及yarn,mapreduce目录下的 将/root/hadoop-2.8.1/etc下的 core-site.xml和hdfs-site.xml文件放在Project的src目录下 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package cn.itcast.hadoop.hdfs;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.net.URI;import java.net.URISyntaxException;import org.apache.commons.compress.utils.IOUtils;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FSDataInputStream;import org.apache.hadoop.fs.FSDataOutputStream;import org.apache.hadoop.fs.FileStatus;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.LocatedFileStatus;import org.apache.hadoop.fs.Path;import org.apache.hadoop.fs.RemoteIterator;import org.junit.Before;import org.junit.Test;public class HdfsUtil &#123; FileSystem fs = null; @Before public void init() throws IOException, InterruptedException, URISyntaxException &#123; Configuration conf = new Configuration(); conf.set(\"fs.defaultFS\", \"hdfs://cluster1:9000/\"); // 设置权限 fs = FileSystem.get(new URI(\"hdfs://cluster1:9000/\"),conf,\"root\"); //如果在集群中只需要指定dfs.nameservices的值即可:hdfs://ns1/ //fs需要哪些成员才能读写hdfs文件 // fs--&gt;RPCProxy--&gt;NameNode.open(src) &#125; @Test public void download() throws IOException &#123; // input stream Path src =new Path(\"hdfs://cluster1:9000/install_hadoop.sh\"); FSDataInputStream in =fs.open(src); //ouput local FileOutputStream os= new FileOutputStream(\"/root/Downloads/install2.sh\"); IOUtils.copy(in, os); &#125; @Test public void download2() throws IOException &#123; fs.copyFromLocalFile(new Path(\"hdfs://cluster1:9000/upload2.txt\"), new Path(\"/root/Downloads/install2.sh\") ); &#125; @Test public void upload() throws IOException &#123; // to upload a file to hdfs Path dst =new Path(\"hdfs://cluster1:9000/upload.txt\"); FSDataOutputStream os =fs.create(dst); FileInputStream in= new FileInputStream(\"/root/Downloads/install2.sh\"); IOUtils.copy(in, os); &#125; @Test public void upload2() throws IOException &#123; fs.copyFromLocalFile(new Path(\"/root/Downloads/install2.sh\"), new Path(\"hdfs://cluster1:9000/a/b/upload2.txt\")); &#125; @Test public void mkdir() throws IllegalArgumentException, IOException &#123; fs.mkdirs(new Path(\"/a/b\")); &#125; @Test public void rm() throws IllegalArgumentException, IOException &#123; fs.delete(new Path(\"/a\"),true); &#125; @Test public void listFiles() throws FileNotFoundException, IllegalArgumentException, IOException &#123; RemoteIterator&lt;LocatedFileStatus&gt; files = fs.listFiles(new Path(\"/\"), true); while(files.hasNext()) &#123; LocatedFileStatus file = files.next(); //LocatedFileStatus 是通过RPC机制 得到的 fs也是类似 Path filepath = file.getPath(); String fileName = filepath.getName(); System.out.println(fileName); &#125; System.out.println(\"--------------\"); FileStatus[] listStatus = fs.listStatus(new Path(\"/\")); for(FileStatus status: listStatus) &#123; String name =status.getPath().getName(); System.out.println(name); &#125; &#125;&#125; 权限问题如果不是在虚拟机上测试的话,会有权限的问题,需要在eclipse的Run Configuration的Arguments中的VM arguments中增加如下信息-DHADOOP_USER_NAME=root 也可以将hdfs://cluster1:9000/设置为所有人可读写权限 元数据的可靠性有保证，但hadoop的HA(高可用)不高 HA高可用的集群搭建 clone三台之后,修改主机名为zookeeper1,zookeeper2,zookeeper3,修改/etc/hosts 修改IP /etc/sysconfig/network-scripts/ 在的三个IP 关闭防火墙 ssh免登陆ssh keygen -t rsa 安装JDK,配置环境变量 实际操作7台机器 集群规划 cluster1 192.168.1.221 jdk,hadoop namenode zkfccluster2 192.168.1.222 jdk,hadoop namenode zkfccluster3 192.168.1.223 dk,hadoop resourcemanagercluster4 192.168.1.224 jdk,hadoop resourcemanagerzookeeper1 192.168.1.225 jdk,hadoop,zookeeper zookeeper journalnode datanode nodemanagerzookeeper2 192.168.1.226 jdk,hadoop,zookeeper zookeeper journalnode datanode nodemanagerzookeeper3 192.168.1.227 jdk,hadoop,zookeeper zookeeper journalnode datanode nodemanager 在一台虚拟机上执行如下脚本(cluster1)1curl https://file.femnyy.com/file/install_hadoop_true.sh | sudo sh 前提:修改了网卡设置，网络正常.同时在/root目录下有hadoop-2.8.1.tar.gz，jdk8.tar.gz和zookeeper-3.4.10.tar.gz这三个包 然后就clone 6台虚拟机,进入开启这6台虚拟机,修改IP,重新启动网络1234vim /etc/sysconfig/network-scripts/ifcfg-enp0s3vim /etc/sysconfig/network-scripts/ifcfg-enp0s8service network restartifconfig 然后在cluster1中执行SSH免密码登陆 1ssh-copy-id cluster1 cluster2 zookeeper1 zookeeper2 zookeeper3 在cluster3中执行如下命令1ssh-copy-id zookeeper1 zookeeper2 zookeeper3 在zookeeper2在执行如下命令1echo 2 &gt; /root/zookeeper-3.4.10/data/myid 在zookeeper3在执行如下命令1echo 3 &gt; /root/zookeeper-3.4.10/data/myid 环境配置好了之后,一定严格按下面步骤进行操作启动zookeeper集群(分别在zookeeper1-3上启动zk) 123zkServer.sh start# 查看状态,一个leader,两个followerzkServer.sh status 启动journalnode(分别在zookeeper1-3上执行) 123hadoop-daemon.sh start journalnode# 检验是否有JournalNode进程jps 格式化HDFS 123456# 在cluster1上执行hdfs namenode -format# 格式化后会在根据core-site.xml中的hadoop.tmp.dir配置生成个文件,我是设置成/root/hadoop-2.8.1/tmp，然后将这个tmp目录cp到cluster2下scp -r /root/hadoop-2.8.1/tmp/ root@cluster2:/root/hadoop-2.8.1/# 或者在cluster2执行如下命令,效果也是一样的hdfs namenode -bootstrapStandby 格式化ZKFC(在cluster1上执行即可) 123456789101112hdfs zkfc -formatZK# 在zookeeper1在执行,查看建立的数据节点zkCli.ss ls / # [zookeeper, hadoop-ha]ls /hadoop-ha # [ns1]get /hadoop-ha/ns1 # 因为没有运行,数据都是空的如果改了配置文本想重新启动就不需要再启动上面的内容了,比如改了所有虚拟机的hdfs-site.xml文件,只需要在cluster1 stop-dfs.sh 再运行start-dfs.sh就可以了如是下次重新启动时就启动zk集群和start-dfs.sh和start-yarn.sh,就可以了 启动HDFS(在cluster1上执行即可) 1start-dfs.sh 启动YARN(在cluster3上执行) 将Namenode和Resourcemanager分开是因为性能问题1start-yarn.sh 启动YARN daemon(在cluster4上执行) 1yarn-daemon.sh start resourcemanager 访问HDFS: http://cluster1:50070HDFS: http://cluster2:50070YARN: http://cluster3:8088 改进: dfs.datanode.http.address datanode的HTTP服务器和端口 50075hdfs-site.xml 0.0.0.0:50075 HDFS HA 测试测试上传 在zookeeper1-3集群中在执行1cd /root/hadoop-2.8.1/tmp/dfs/data/current/BP-xx/current/finalized/ 在cluster1在执行1234hadoop fs -put /root/hadoop-2.8.1.tar.gz /# 执行完成后会在zookeeper1-3中 cd subdir0/subdir0/看到两个block块mkdir 1 &amp;&amp; cd 1hadoop fs -get /hadoop-2.8.1.tar.gz 测试namenode切换 HDFS: http://cluster2:50070知道哪个是active状态,通过jps得到namenode的进程，将其kill,我的是cluster2是active123# kill之后,可以再看http://cluster2:50070的和cluster1的状态,成功切换# 所以也是在cluster2中重新启动NameNodehadoop-daemon.sh start namenode 现在是cluster1为active,然后将cluster1这个虚拟机关机,cluster2至少要等30s才能切换.然后重新启动cluster1之后执行 12hadoop-daemon.sh start zkfchadoop-daemon.sh start namenode 现在cluster2是active,在cluster1中执行 1234# 也可以成功切换,但不推荐使用hdfs haadmin -transitionToStandby nn2 --forcemanual# namenode的状态hdfs haadmin -getServiceState nn2 # standby 查看Yarn状态 在zookeeper1-3的随便一台在执行12zkCli.shget /yarn-leader-election/yrc/ActiveBreadCrumb # yrcrm1表明rm1(cluster3)是运行状态 也可以通过http://cluster3:8088来查看，会自动跳转到运行状态的地址上 Yarn的HA测试 在cluster4在执行1hadoop jar hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar pi 5 5 在cluster3在杀死ResourceManager进程 12#重启启动 resourcemanageryarn-daemon.sh start resourcemanager Yarn的HA不像HDFS的YA一样,YARN正在跑的程序突然中断则意味着程序的失败 动态增加DataNode节点和数量管理 在zookeeper3中kill掉datanode进程再查看http://cluster1:50070的Live Nodes数量,则会显示Live NOdes:2,Dead NOdes:1,block副本不会变多 123# 在zookeeper1-3中vim /root/hadoop-2.8.1/tmp/dfs/data/current/VERSION# 是由clusterID的决定这个datanode是否在同一个集群上 新加一个datanode节点,只需要hadoop包，然后启动datanode就行了 clone一台zookeeper1的名为zookeeper4,并在zookeeper4运行12345678910111213141516171819202122# zookeeper4 192.168.1.228 jdk,hadoop,zookeeper zookeeper journalnode datanode nodemanager # vim /etc/sysconfig/network-scripts/ifcfg-enp0s3 # 为228 service network restart rm -rf /root/hadoop-2.8.1/tmp echo \"192.168.1.228 zookeeper4\"&gt;&gt; /etc/hosts echo \"zookeeper4\"&gt;&gt; /root/hadoop-2.8.1/etc/hadoop/slaves scp /etc/hosts root@cluster1:/etc/hosts scp /etc/hosts root@cluster2:/etc/hosts scp /etc/hosts root@cluster3:/etc/hosts scp /etc/hosts root@cluster4:/etc/hosts scp /etc/hosts root@zookeeper1:/etc/hosts scp /etc/hosts root@zookeeper2:/etc/hosts scp /etc/hosts root@zookeeper3:/etc/hosts scp /root/hadoop-2.8.1/etc/hadoop/slaves root@cluster1:/root/hadoop-2.8.1/etc/hadoop/slaves scp /root/hadoop-2.8.1/etc/hadoop/slaves root@cluster2:/root/hadoop-2.8.1/etc/hadoop/slaves scp /root/hadoop-2.8.1/etc/hadoop/slaves root@cluster3:/root/hadoop-2.8.1/etc/hadoop/slaves scp /root/hadoop-2.8.1/etc/hadoop/slaves root@cluster4:/root/hadoop-2.8.1/etc/hadoop/slaves scp /root/hadoop-2.8.1/etc/hadoop/slaves root@zookeeper1:/root/hadoop-2.8.1/etc/hadoop/slaves scp /root/hadoop-2.8.1/etc/hadoop/slaves root@zookeeper2:/root/hadoop-2.8.1/etc/hadoop/slaves scp /root/hadoop-2.8.1/etc/hadoop/slaves root@zookeeper3:/root/hadoop-2.8.1/etc/hadoop/slaves hadoop-daemon.sh start datanode ll /root/hadoop-2.8.1/tmp/dfs/data/current/BP-1937453453-127.0.0.1-1506392610571/current/finalized/subdir0/subdir0 # 会自动将block副本复制到这个节点上,来保存三个副本 不需要下面的操作在cluster3,cluster141yarn-daemon.sh start nodemanager 在cluster1,cluster12刷新集群节点1hdfs dfsadmin -refreshNodes 现在再将zookeeper3的datanode启动起来1hadoop-daemon.sh start datanode 目前将会有四个节点,四个副本,导致了数据的冗余,hadoop会自动的清除掉冗余的数据","categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://www.femn.me/categories/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://www.femn.me/tags/大数据/"}]},{"title":"hadoop简介","slug":"hadoop","date":"2017-09-23T11:31:15.000Z","updated":"2017-09-25T10:12:07.772Z","comments":true,"path":"2017/09/23/hadoop/","link":"","permalink":"https://www.femn.me/2017/09/23/hadoop/","excerpt":"","text":"介绍hadoop在海量数据的场景下,为了解决分布式部署中的公共问题一些框架就出现了hadoop,zookeeperhadoop:由很多的技术框架组成的一个生态系统.它是一个上层的应用软件(java编写的)不关是用来做海量数据储存的,因为在解决海量数据的处理中,解决了一些很共同的问题,把解决这些的方法抽离出来,形成各种各样的框架.将这些框架单独拿出来也可以在项目中使用. hadoop解决问题:海量数据的存储(HDFS):分布式集群的文件系统,区别本机的文件系统 海量数据的分析(运算模型)(MapReduce:分析运算的模型,自己写运算逻辑(程序),写出来的就是MapReduce程序,给YARM运行),spark,storm,hive程序Map程序:在不同节点并发运行Reduce程序:全局处理,只在一同节点上运行,通过网络取得Map程序的结果.分组统计时,Reduce也可以有多个 MapReduce:擅长海量离线日志分析spark:实时的迭代运算storm:实时的流计算 资源管理调度(YARN):集群 安装hadoop:集群的安装是很繁琐的事,Cloudera这个公司开发的安装系统(脚本)之后,只需要在一个节点,在浏览器中打开Cloudera,然后选择你所需要的服务,点确定之后,所以的程序包自动下载并安装好,同时还提供对集群的管理监控 但个人还是使用apache官方的hadoop,伪分布式部署 centos7 + hadoop.2.8.1 + virtualbox5 virtualbox5配置1curl https://file.femnyy.com/file/install_hadoop.sh | sudo sh 注意:此脚本是在/root目录下执行,并且请在此目录提前下载好hadoop-2.8.1.tar.gz,之后的操作也是root用户操作 访问:http://192.168.1.222:50070巨坑:所有的服务都成功开启,但就是在主机访问不了,关闭了防火墙也不行,弄了半天的virtualbox的网络设置(自认为是没有错的)也不行,没想到居然是配置文件的问题 centos 7启动图形界面123456789101112131415# 方法一yum group listyum group install \"GNOME Desktop\"startx# 当重新启动时执行,就可以进入系统了# You might have to hit 1, then 2 to agree to the license, then C to continue.1--2--c--yes# yum group install \"GNOME Desktop\" \"Graphical Administration Tools\"# 开机时自动就是设置图形界面# ln -sf /lib/systemd/system/runlevel5.target /etc/systemd/system/default.target # reboot# 方法二init 5","categories":[{"name":"hadoop","slug":"hadoop","permalink":"https://www.femn.me/categories/hadoop/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://www.femn.me/tags/大数据/"}]},{"title":"VirtualBox下虚拟机的网络配置","slug":"virtualbox","date":"2017-09-20T09:51:19.000Z","updated":"2017-09-25T04:17:55.879Z","comments":true,"path":"2017/09/20/virtualbox/","link":"","permalink":"https://www.femn.me/2017/09/20/virtualbox/","excerpt":"","text":"基本思路 从主机可以通过静态IP访问到每一个虚拟机,从虚拟机中可以访问主机(主机也有一个固定的静态IP)(Host-only Adapter 模式)注意:这里设置是主机的IPV4,不是虚拟机的 虚拟机之间组成一个由静态IP构成的网络,而且虚拟机之间可以互相访问 (Internal Network 模式)注意,虚拟机之间的内网名字可以随便起,这里叫做 intnet.如果在配置在第二个虚拟机的时候,也要记得选择 intnet 这个内网名字,这样虚拟机之间才可以互相通信 从主机,从虚拟机都可以访问internet (NET 模式) 具体操作在Virtualbox中设置全局变量的 Host-only Networks1打开Virtualbox--任务栏--File--Preferences--Network--Host-only Networks 配置虚拟机的网卡1选择一个虚拟机--Settings--Network--&gt;设置三个网卡 保存,启动虚拟机,安装系统进入虚拟机内部配置网卡 修改静态IP,与主机同一个网段,实现主机与虚拟机的通信123456vi /etc/sysconfig/network-scripts/ifcfg-enp0s3 BOOTPROTO=static ONBOOT=yes IPADDR=192.168.1.220 PREFIX=24 BROADCAST=192.168.1.255 修改静态IP,与虚拟机同一个网段,实现虚拟机之间的通信注意:虚拟机内网我们选择 192.168.0. 这个网段12345vi /etc/sysconfig/network-scripts/ifcfg-enp0s8 BOOTPROTO=static ONBOOT=yes IPADDR=192.168.0.2 PREFIX=24 实现连接internet12vi /etc/sysconfig/network-scripts/ifcfg-enp0s9 ONBOOT=yes 重新启动网络1service network restart 或者使用些脚本来配置这三个网卡的信息,如果有错误请重新启动虚拟机就可以了1curl https://file.femnyy.com/file/centos7_net.sh |sudo sh 关机保存上面的配置好的虚拟机clone虚拟机,然后进入clone后的虚拟机,修改如下配置及可 1234567# 设置一个没有使用的IPvi /etc/sysconfig/network-scripts/ifcfg-enp0s3 IPADDR=192.168.1.220# 设置一个新的内网IP vi /etc/sysconfig/network-scripts/ifcfg-enp0s8 IPADDR=192.168.0.2# 因为internet的网络设置是DHCP,所以不用配置","categories":[{"name":"server","slug":"server","permalink":"https://www.femn.me/categories/server/"}],"tags":[]},{"title":"内存信息的生成与交换","slug":"内存交换","date":"2017-09-10T08:10:53.000Z","updated":"2017-09-23T11:10:15.716Z","comments":true,"path":"2017/09/10/内存交换/","link":"","permalink":"https://www.femn.me/2017/09/10/内存交换/","excerpt":"","text":"由C编译的程序占用内存情况123456789101112131415161718//main.cpp int a = 0; //全局初始化区 char *p1; //全局未初始化区 main() &#123; int b; //栈 char s[] = \"abc\"; //栈 char *p2; //栈 char *p3 = \"123456\"; //123456\\\\0在常量区,p3在栈上. static int c =0;//全局(静态)初始化区 p1 = (char *)malloc(10); p2 = (char *)malloc(20);//分配得来得10和20字节的区域就在堆区. strcpy(p1, \"123456\"); //123456\\\\0放在常量区, // 编译器可能会将它与p3所指向的\"123456\"优化成一个地方. char *s = \"hello, world\"; printf(\"%s\\n\",&amp;s[7]);//world&#125; 如图 不能进行交换12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;/**void swap(int a, int b);*/void swap(int a, int b)&#123; int tmp = a; a = b; b = tmp;&#125;int main(void)&#123; /* main函数会分配一个内存空间 */ int x = 1; int y = 2;/* main函数中会为x,y分配两个紧邻的内存空间 * */ printf(\"x is %i\\n\", x); printf(\"y is %i\\n\", y); printf(\"Swapping...\\n\"); printf(\"Swapped.\\n\"); swap(x, y); /* swap函数也会分配独立的内存空间,并且是在main内存空间之上 */ printf(\"x is %i\\n\", x); printf(\"y is %i\\n\", y); &#125; 成功交换123456789101112131415161718192021222324252627282930313233343536#include &lt;stdio.h&gt;void swap(int *a, int *b);int main(void)&#123; int x = 1; int y = 2; printf(\"x is %i\\n\", x); printf(\"y is %i\\n\", y); printf(\"Swapping...\\n\"); swap(&amp;x, &amp;y);/* &amp;表示内存地址,提供的是内存地址值 * 这个传递的不是x,y本身,而是x,y的int型地址 * 使一个函数能够使用另一个函数的内存块 */ printf(\"Swapped!\\n\"); printf(\"x is %i\\n\", x); printf(\"y is %i\\n\", y); &#125;/* *//* */void swap(int *a, int *b) /* 当有函数调用swap函数时,函数原型使用*号之后, * a不再是一个整形数,而是一个int型指针,指的是内存地址本身的值*/&#123;/* 但是在函数中,*意思是定位到这个内存地址指向的值 * swap函数起了作用 来修改本来不属于它的内存, * 不在它的作用域的变量 */ int tmp = *a; *a = *b; *b = tmp;/*但 = 左边的 表示内存地址的值 */&#125;/*当这个函数调用完成之后swap内存空间将会被释放 */ 如图 123456789101112131415161718192021int main(void)&#123; printf(\"s: \");/* 指针是操作内存地址的方法 stack栈 heap堆:为函数分配的内存地址(指针)*/ string *s = get_string(); string *t = s;/*t为指针,s为具体的值*/ int *x; int *y; x = malloc(sizeof(int));/*内存分配: 表示向系统申请存在空间的字节数 已经有预定指向内存地址了*/ /* x = 52;会重新分配新内存,而上面的内存也就浪费掉了*/ *x = 52; /* *y = 12; 这个没有事先分配的内存地址*/ y = x; *y = 12;&#125;","categories":[{"name":"C","slug":"C","permalink":"https://www.femn.me/categories/C/"}],"tags":[{"name":"计算机","slug":"计算机","permalink":"https://www.femn.me/tags/计算机/"}]},{"title":"归并排序","slug":"MER","date":"2017-09-05T11:31:15.000Z","updated":"2017-09-23T11:10:15.700Z","comments":true,"path":"2017/09/05/MER/","link":"","permalink":"https://www.femn.me/2017/09/05/MER/","excerpt":"","text":"数据结构和算法动态可视化工具:VisuAlgo 递归:函数的自我调用(重复做同一件事,也可以用迭代语句),适用于如果你可以写一个函数,并让它调用自己,只是每次减少参数值,这时就可以用递归思想但不断的递归可能会造成内存耗尽,所以合法的检查(基本条件)是正确解决整个问题的关键所在. 1234567891011121314def sigma(int): if int &lt;= 0:return 0 sum = 0 for i in range(int+1): sum+=i print(sum)sigma(100)# 递归def sigma1(int): if int &lt;=0:return 0 # 终止条件 else: return int+sigma1(int-1)print(sigma1(100)) 归并排序:归并排序是建立在归并操作上的一种有效的排序算法,该算法是采用分治法(Divide and Conquer)的一个非常典型的应用.将已有序的子序列合并,得到完全有序的序列;即先使每个子序列有序,再使子序列段间有序.若将两个有序表合并成一个有序表,称为二路归并 归并排序的算法我们通常用递归实现,先把待排序区间[s,t]以中点二分,接着把左边子区间排序,再把右边子区间排序,最后把左区间和右区间用一次归并操作合并成有序的区间[s,t] 归并过程为:比较a[i]和a[j]的大小,若a[i]≤a[j],则将第一个有序表中的元素a[i]复制到r[k]中,并令i和k分别加上1;否则将第二个有序表中的元素a[j]复制到r[k]中,并令j和k分别加上1,如此循环下去,直到其中一个有序表取完,然后再将另一个有序表中剩余的元素复制到r中从下标k到下标t的单元 123456789101112131415161718192021222324252627282930313233343536def merge(left, right): i, j = 0, 0 result = [] while i &lt; len(left) and j &lt; len(right): if left[i] &lt;= right[j]: result.append(left[i]) i += 1 else: result.append(right[j]) j += 1 result += left[i:] result += right[j:] print(result) return resultdef merge_sort(lists): if len(lists) &lt;= 1: return lists num = int((len(lists) / 2)+0.5) # 二分查找 logN 拆分成单个元素 left = merge_sort(lists[:num]) right = merge_sort(lists[num:]) print(left,right,sep='下面') return merge(left, right) # 合并之后就是有序的了print(merge_sort([1,6,4,2,9,7,5,8,3])) # 归并排序 (合并过程的次数也是N)N*logN # T(n) = 0,if n &lt; 2 #合法的检查 基本条件 # T(n) = T(n/2) +T(n/2)+n ,if n &gt;1 # 算法的核心:拆分 合并 # T(4) = 2 * T(2) + 4 # T(2) = 2 * T(1) + 2 # T(1) = 0 # 8个元素排序需要8×log8 = 24 递归和合并过程123456789101112131415161718192021222324252627282930313233# 1merge( merge_sort([1,6,4,2,7]),merge_sort([7,5,8,3]) )# 2merge( merge( merge_sort([1,6,4]),merge_sort([2,7])), merge( merge_sort([7,5]),merge_sort([8,3])) )# 3merge( merge( merge( merge_sort([1,6]),merge_sort(4)), merge( merge_sort([2]),merge_sort([7])) ), merge( merge( merge_sort([7]),merge_sort([5])), merge( merge_sort(8),merge_sort(3)) ) )# 4merge( merge( merge( merge( merge_sort([1]),merge_sort([6])), merge_sort(4) ), merge( merge_sort([2]), merge_sort([7])) ), merge( merge( merge_sort([7]), merge_sort([5])), merge( merge_sort(8), merge_sort(3)) ) ) 如图:","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.femn.me/tags/算法/"}]},{"title":"冒泡和简单选择排序算法","slug":"BUB","date":"2017-09-05T09:19:32.000Z","updated":"2017-09-23T11:10:15.664Z","comments":true,"path":"2017/09/05/BUB/","link":"","permalink":"https://www.femn.me/2017/09/05/BUB/","excerpt":"","text":"冒泡排序(Bubble Sort又称为泡沫排序或气泡排序):是一种简单的排序算法.它重复地走访过要排序的数列,一次比较两个元素,如果他们的顺序错误就把他们交换过来.走访数列的工作是重复地进行直到没有再需要交换,也就是说该数列已经排序完成.这个算法的名字由来是因为越小的元素会经由交换慢慢”浮”到数列的顶端,而最大数在第一次的外循环就固定了实例分析 以列表[5, 1, 4, 2, 8] 为例说明12345678910111213141516# 第一次外循环( 5 1 4 2 8 ) → ( 1 5 4 2 8 ), 5 &gt; 1 交换位置( 1 5 4 2 8 ) → ( 1 4 5 2 8 ), 5 &gt; 4 交换位置( 1 4 5 2 8 ) → ( 1 4 2 5 8 ), 5 &gt; 2 交换位置( 1 4 2 5 8 ) → ( 1 4 2 5 8 ), 5 &lt; 8 位置不变# 第二次外循环(除开最后一个元素8,对剩余的序列)( 1 4 2 5 8 ) → ( 1 4 2 5 8 ), 1 &lt; 4 位置不变( 1 4 2 5 8 ) → ( 1 2 4 5 8 ), 4 &gt; 2 交换位置( 1 2 4 5 8 ) → ( 1 2 4 5 8 ), 4 &lt; 5 位置不变# 第三次外循环(除开已经排序好的最后两个元素,# 可以注意到上面的数组其实已经排序完成,但是程序本身并不知道# 所以还要进行后续的循环,直到剩余的序列为 1)( 1 2 4 5 8 ) → ( 1 2 4 5 8 )( 1 2 4 5 8 ) → ( 1 2 4 5 8 )# 第四次外循环(最后一次)( 1 2 4 5 8 ) → ( 1 2 4 5 8 ) 代码实现:123456789101112131415161718def bubble_sort(lists): # 冒泡排序 count = len(lists) n = 0 for i in range(0, count): for j in range(i + 1, count): if lists[i] &gt; lists[j]: lists[i], lists[j] = lists[j], lists[i] n+=1 print(n) return listsprint(bubble_sort([5,1,4,2,8]))print(bubble_sort([8,5,4,2,1]))# 输出如下# 4# [1, 2, 4, 5, 8]# 10# [1, 2, 4, 5, 8] 简单选择排序算法:在要排序的一组数中,选出最小(或者最大)的一个数与第1个位置的数交换;然后在剩下的数当中再找最小(或者最大)的与第2个位置的数交换,依次类推,直到第n-1个元素(倒数第二个数)和第n个元素(最后一个数)比较为止. 以列表[5, 1, 4, 2, 8] 为例说明第一趟: 1,5,4,3,8第二趟: 1,3,4,5,8第三趟: 1,3,4,5,8第四趟: 1,3,4,5,8第五趟: 1,3,4,5,8 代码实现:12345678910`def select_sort(lists): count = len(lists) for i in range(0, count): min = i for j in range(i + 1, count): if lists[min] &gt; lists[j]: min = j lists[min], lists[i] = lists[i], lists[min] return listsprint(select_sort([5, 1, 4, 2, 8]))","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://www.femn.me/tags/算法/"}]},{"title":"shell_sed_awk","slug":"shell-grep-sed-awk","date":"2017-08-23T09:05:44.000Z","updated":"2017-09-23T11:10:15.708Z","comments":true,"path":"2017/08/23/shell-grep-sed-awk/","link":"","permalink":"https://www.femn.me/2017/08/23/shell-grep-sed-awk/","excerpt":"","text":"Sed全名为Stream EDitor,即流式编辑器,行编辑器sed常用用法12sed [options] 'script(模式命令)' input_file...sed [options] -f script_file(sed脚本) input_file... options -n 静默模式,不打印模式空间中的内容 -e 执行模式命令,适用于多脚本处理 -i 直接操作原文件1234567sed -n -e '1p' -e '37,40p' /etc/passwd &gt; passwd.txt &amp;&amp; cat passwd.txt # 输出如下root:x:0:0:root:/root:/bin/bashrtkit:x:118:126:RealtimeKit,,,:/proc:/bin/falsesaned:x:119:127::/var/lib/saned:/bin/falseusbmux:x:120:46:usbmux daemon,,,:/var/lib/usbmux:/bin/falsefemn:x:1000:1000:femn,,,:/home/femn:/bin/bash 模式命令 s:替换 p:打印 d:删除 a:增加 g:表示一行上的替换所有的匹配123456sed -e '1,37d' /etc/passwd# 输出如下saned:x:119:127::/var/lib/saned:/bin/falseusbmux:x:120:46:usbmux daemon,,,:/var/lib/usbmux:/bin/falsefemn:x:1000:1000:femn,,,:/home/femn:/bin/bashmysql:x:121:130:MySQL Server,,,:/nonexistent:/bin/false a \\:在模式匹配到的行后面添加新内容i 前面12345678910sed -e '/root/i \\this is head' \\ -e '/femn/a \\this is tail\\n' passwd.txt # 输出如下this is headroot:x:0:0:root:/root:/bin/bashrtkit:x:118:126:RealtimeKit,,,:/proc:/bin/falsesaned:x:119:127::/var/lib/saned:/bin/falseusbmux:x:120:46:usbmux daemon,,,:/var/lib/usbmux:/bin/falsefemn:x:1000:1000:femn,,,:/home/femn:/bin/bashthis is tail 匹配内容的行’/{content}/‘ 可以使用正则匹配1234sed -n -e '/\\&lt;root\\&gt;/s/bin/nologin/p' -e 's/femn/hehe/p' passwd.txt# 输出如下root:x:0:0:root:/root:/nologin/bashhehe:x:1000:1000:femn,,,:/home/femn:/bin/bash -f 指定文件1234vim ss /\\&lt;root\\&gt;/s/bin/nologin/p s/femn/hehe/psed -n -f ss passwd.txt sed脚本 123456vim ss.sh #!/bin/sed -f /\\&lt;root\\&gt;/s/bin/nologin/p s/femn/hehe/pchmod a+u ss.sh./ss.sh passwd.txt 删除注释和空行 显示删除之后的行数12sed -e '/^#/d' -e '/^$/d' passwd.txt | wc -lwc -l !$ # 上个文件多少行 个人的一个实用脚本,将中文符号换成英文12345678910111213141516#!/bin/bash for i in `ls /home/femn/blog/source/_posts/*.md`do sed -i -e 's/:/:/g' \\ -e 's/;/;/g' \\ -e 's/,/,/g' \\ -e 's/././g' \\ -e 's/(/(/g' \\ -e 's/)/)/g' \\ -e 's/\"/\"/g' \\ -e 's/\"/\"/g' \\ -e \"s/'/'/g\" \\ -e \"s/'/'/g\" \\ \"$i\"done awk擅于处理列awk的一些内建变量 FS 输入字段分隔符 默认是空格或Tab $0 当前记录(这个变量中存放着整个行 的内容) $1~$n 当前记录的第n个字段,字段间由FS分隔 OFS 输出字段分隔符, 默认也是空格 NR 已经读出的记录数,就是行号 FNR 文件自己的行号 12345678user_redis=`cat /etc/passwd|grep redis|awk -F : '&#123;print $1&#125;'`awk 'BEGIN&#123;FS=\":\"&#125; &#123;print $1,$3,$6&#125;' &lt; passwd.txt# 如下输出root 0 /rootrtkit 118 /procsaned 119 /var/lib/sanedusbmux 120 /var/lib/usbmuxfemn 1000 /home/femn 匹配内容123456awk -F: '$1==\"root\" || $1 ~ /femn|mysql/ &#123;print NR, FNR, $1,$3,$6&#125;' OFS=\"\\t\" passwd.txt# 如下输出1 1 root 0 /root 5 5 femn 1000 /home/femn# -F: 指定分隔符为':'去分隔文件 默认为空格或Tab# ~ 表示匹配模式开始./ /中是模式.这就是一个正则表达式的匹配.!~ 表示取反 把指定的列输出到文件1234567891011awk 'NR!=1&#123;if($1 ~ /root|femn/) print &gt; \"1.txt\"; \\ else if($1 ~ /mysql/) print &gt; \"2.txt\"; \\ else print &gt; \"3.txt\" &#125;' passwd.txtvim 1.txt emn:x:1000:1000:femn,,,:/home/femn:/bin/bash # NR!=1表示不处理表头,所以没有root的那一行vim 2.txt # 是个空的vim 3.txt rtkit:x:118:126:RealtimeKit,,,:/proc:/bin/false saned:x:119:127::/var/lib/saned:/bin/false usbmux:x:120:46:usbmux daemon,,,:/var/lib/usbmux:/bin/false 注意其中的if-else-if语句,可见awk其实是个脚本解释器 统计12345678910ll *.txt | awk '&#123;print $5,$9&#125;'# 输出如下46 1.txt0 2.txt151 3.txt229 passwd.txtll *.txt |awk '&#123;sum+=$5&#125; END &#123;print sum&#125;'# 输出如下426 统计每个用户的进程的占了多少内存,sum的RSS那一列1ps aux | awk 'NR!=1&#123;a[$1]+=$6;&#125; END &#123; for(i in a) print i \", \" a[i]\"KB\";&#125;' 按连接数查看客户端IP1netstat -ntu | awk '&#123;print $5&#125;' | cut -d: -f1 | sort | uniq -c | sort -nr awk脚本123456789awk -F: 'BEGIN &#123;i=1&#125; &#123; if ($7==\"/bin/bash\") i+=1 &#125; END &#123;print \"number \"i&#125;' &lt; /etc/passwd# 输出如下number 3vim aa BEGIN &#123;i=1&#125; &#123; if ($7==\"/bin/bash\") i+=1 &#125; END &#123;print \"number \"i&#125;cat /etc/passwd | awk -F: -f aa","categories":[{"name":"shell","slug":"shell","permalink":"https://www.femn.me/categories/shell/"}],"tags":[]},{"title":"pymongo基本操作","slug":"pymongo","date":"2017-08-18T14:48:02.000Z","updated":"2017-09-23T11:10:15.700Z","comments":true,"path":"2017/08/18/pymongo/","link":"","permalink":"https://www.femn.me/2017/08/18/pymongo/","excerpt":"","text":"知道了大概的mongodb命令后,再下载Mongodb的python驱动,sudo pip3 install pymongo ,然后在python文件中导入相应的库,进行如下的配置: 1234567from pymongo import MongoClient_client = MongoClient('127.0.0.1', 27017) #主机IP,Port#先创建一个名为Mongodb的数据库,再连接到此数据库_db = _client['Mongodb']_db.authenticate('username', 'password')#如果是设置了密码登陆时test = _db['test'] # 表名femn = _db['femn'] 返回结果insert , insert_one , insert_many12345insert(&#123;'name':1&#125;) # &lt;class 'bson.objectid.ObjectId'&gt; insert([&#123;'name':1&#125;,&#123;'name':2&#125;]) # [ObjectId('xx'),ObjectId('xx')]insert_one # r.inserted_id &lt;class 'bson.objectid.ObjectId'&gt;insert_many # &lt;class 'pymongo.results.InsertManyResult'&gt;print(r.inserted_ids) # list [ObjectId('xx'), ObjectId('xx')] update1&#123;'ok': 1, 'updatedExisting': True, 'nModified': 1, 'n': 1&#125; upsert=True1&#123;'ok':1,'nModified':0,'upserted':ObjectId(''),'n':1,'updatedExisting':True&#125; update_one123r = db.test.update_one(&#123;'_id':'xx'&#125;,&#123;'$set':&#123;'name':'femn'&#125;&#125;) # &lt;pymongo.results.UpdateResult object at 0x7f9cb2ebaaf8&gt;r.raw_result =&#123;'nModified': 0, 'n': 1, 'updatedExisting': True, 'ok': 1&#125; delete_many delete_one 1234result = db.test.delete_many(&#123;'x': 1&#125;) #pymongo.results.DeleteResultresult.deleted_count # 2result.raw_result # &#123;'n': 2, 'ok': 1&#125; #n表示匹配成功删除的个数 和delete_one是一样的 find find_one123find() find(&#123;&#125;) # return 一个pymongo.cursor.CursorTypefind_one(&#123;'_id':'xx'&#125;) # return dict 如果没有则返回Nonefind_one_and_update() # return dict find find_one 命令123456femn.find(filter=&#123;'field':'xx'&#125;, projection=&#123;'mobile':1,'name':0&#125;,limit=10,skip=0, sort=[('update_time':pymongo.DESCENDING)])femn.find(&#123;'name':xx&#125;,&#123;'name':1&#125;).limit().skip(). sort=([('update_time':pymongo.DESCENDING)]) filter中的多个查询操作符 $all $in $nin 此字段可包含(或排除)多个值的文档12345(&#123;filed:&#123;'$all':[]&#125;&#125;) # 这个字段是数组并满足这个数组的值和指定的相同的文档(&#123;filed:&#123;'$in','$nin' :['x']&#125;&#125;) # 而这个只表示'x'在字段不管是数组类型的值,还是字符串类型的值,只要有这个'x'的文档就行 $regex 正规匹配字段的值12(&#123;filed:&#123;'$regex': '%s' % student_name&#125;&#125;) 就是 ' *%s* '(&#123;filed:&#123;'$not':&#123;'$regex':'femn'&#125;&#125;&#125;) $exists 判断文档是否有此字段12(&#123;filed: &#123;'$exists': False&#125;&#125;)#得到所有不存在flag字段的文档 可取True $or 满足一个字段的值就行12(&#123;'gender': '女', '$or': [&#123;'expand.expand_time': '2015-01-01'&#125;, &#123;'coin': &#123;'$lt': 2&#125;&#125;]&#125;) $slice12(&#123;'expand.expand_time':&#123;'$slice':[5,3]&#125;&#125;)# 不是分片,去掉前5个后,再取3个 ,-5时去掉后5个取,取最后3个 混合包含和排除不能同时用 1(&#123;'album_id':&#123;'$in':[i]&#125;&#125;,projection=&#123;'play_count':1,'cover_image':1&#125;) 混合包含和排除不能同时用,既in:[],cover_image:1,comment:0不能同时使用,但可以 in:[],cover_image:1,comment:1 其它的查询操作符 $eachMatch,$gt:2, $lte, $gte, $lt, ‘$slice’ $ne不等于 find_one_and_update命令12345678910111213141516171819202122232425262728find_one_and_update(q,u,p,upsert=False, return_document=ReturnDocument.AFTER)test.update(&#123;'name':'femn'&#125;, &#123; # update中的多个更新操作符 '$set':&#123;'name':'xx'&#125;, # 改变某个字段的值 '$inc':&#123;'age':-1&#125;, # 增加或减少 一个字段内容是数值的值 '$addToSet':&#123;'name_list':&#123;'$each':['','']&#125;&#125;, # 往一个数组的字段,添加不一样的内容,可避免反复添加 # $each 一次性增加多个值 # $push 往一个数组的字段中,可重复的添加一样的内容 '$pull':&#123;'list':&#123;'key':'value'&#125;&#125;, # 删除数组中 所有key为value的数组都会删除掉 将所有匹配到的数据都删除 '$pullAll':&#123;'l':[1,2,3]&#125; # 一次性删除多个数组 &#125;)test.update(&#123;'_id':id&#125;,&#123;'$set': &#123;'recording':&#123;'openid':openid,'book_id':book_id&#125;&#125;&#125;) # recording 是一个Object类型test.find_one(&#123;'_id':bookcase_id,recording.book_id':book_id&#125;) 改变数值中的值 通过位置或者操作符$ 123456789101112131415# 通过$test.update(&#123;\"relationships.fname\":\"xiong\",'_id':id&#125;, &#123;$set:&#123;\"relationships.$.age\":22&#125;&#125;) # 通过位置用来定位查询文档已匹配的元素,并进行更新test.update(&#123;'_id':id&#125;, &#123;'$inc':&#123;'book_class.'+str(i)+'.class_count':count&#125;&#125;)# 指定一个数组中的一个字段改变 test.update(&#123;'_id':id&#125;, &#123;'activity_history':&#123;'click_total':1,per:1,'login':1&#125;&#125;&#125;)# 此方法不行 换成如下方法test.update(&#123;'_id':id&#125;, &#123;'$inc':&#123;'activity_history.0.click_total':1, 'activity_history.0.2017-02':1, 'activity_history.0.login':1&#125;&#125;,) 注意pull一个个的数组是个整体1234567'reservation_list':[&#123;'time':\"\",'device_id':'', 'order_book':[&#123;1&#125;,&#123;2&#125;]&#125;,&#123;...&#125;,&#123;...&#125;] # 错误的设计 不可能单独的删除order_book中的1,2还保留着... # 它会删除整个的那个数组reservation_list'reservation_list':[&#123;'device_id':'','book_id':'', 'book_plu':'','shelf_number':101&#125;] # 所以要将order_book中保存的信息,放出来 数组字段的内容album_id = [&#39;1&#39;,&#39;xx&#39;],不是JSON类型1234test.update(&#123;'_id':id&#125;,&#123;'$pull':&#123;'album_id':'xx'&#125;&#125;) # album_id必须是数组&#123;'$pull': &#123;'album_id': &#123;'$in': ['xx']&#125;&#125; #也可以使用其它的查询操作符 $gt 删除以字典形式保存的数组12 &#123;'$pull': &#123;'praise': &#123;'user_id': user_id,'_id':'xx'&#125;&#125; &#123;'$pull': &#123;'save_receiver_address': &#123;'flag': del_flag&#125;&#125;&#125;)","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"mongodb基本命令","slug":"mongodb","date":"2017-08-18T11:56:18.000Z","updated":"2017-09-23T11:10:15.700Z","comments":true,"path":"2017/08/18/mongodb/","link":"","permalink":"https://www.femn.me/2017/08/18/mongodb/","excerpt":"","text":"先去mongodb官网下载mongod,配置好环境变量.最好也再下个robomongo,进行更好的图形界面管理 mongodb官方文档 mongodb中文文档 启动Mongod:1mongod --dbpath /home/python/data/mongodb --logpath /home/python/data/log --auth 或者用配置文件的方式启动:123456mongod -f ./mongod.confvim ./mongod.conf dbpath = /home/python/data/mongodb/ logpath = /home/python/data/log port = 27017 auth = true 进入Mongo的CLI:123monogo -uusername -ppasswd 192.168.0.197:27017/db # 如果有语言上的错误export LC_ALL=C 选择admin数据库,并认证:12use admindb.auth('username','password') 指定好当前数据库后,用db命令查看,之后用密码登陆. 查看所有的数据库 1show dbs 创建或选定数据库12use 1 # 该命令将创建一个新的数据库,如果它不存在,否则将返回现有的数据库.db.dropDatabase('1') # 删除数据库 创建集合(表),删除表,显示所有表 123db.createCollection('test')db.test.drop()show collections 创建文档(记录) 1db.test_table.insert(&#123;'1':1&#125;) 指定数据库,一定要先选定再创建,创建用户角色 123456use testdb.createUser( &#123;user: \"femn2014\",pwd: \"femn2014\",roles: [ &#123; role : \"readWrite\", db: \"test\" &#125; ]&#125;); role:”sysadmin”,”read”,”readWrite”,”sysadmin”和”root”角色只能在第一次创建一次,之后创建的必须是其它的角色,同时也要注意db:’xxx’要改变,如果指定的是admin数据库,则此用户可以看到所有的数据库,并只是针对db:’test’这个数据库有读写操作. 指定数据库之后,查看用户12use testdb.getUsers() 一旦创建好用户之后,就必须要切换到admin数据库中,才能进行对用户角色的管理用admin数据库,查看,管理所有数据库中的所有用户123use admindb.system.users.find()db.system.users.remove(&#123;user:'femn2014'&#125;) 删除用户 得到test表的索引1db.test.getIndexes() 创建新的索引,此命令不会覆盖掉之前的索引 1db.test.ensureIndex(&#123;'mobile':1&#125;) 创建二维索引,通过查询location这个数组,来得到文档 12db.test.ensureIndex(&#123;\"location\" : \"2d\"&#125;,&#123;\"background\" : true&#125;, &#123;min:-180,max:180&#125;) MongoDB的Geospatial Indexing 2d默认取值范围[-179,-179]到[180,180] 包含这两个点,超出范围将报错 备份Mongo:123mongodump --host=192.168.1.217 --port=27017 --username=username \\ --password=passwd --authenticationDatabase admin -dMongodb \\ -cfemn -o /home/python/nosql_dump 恢复Mongo:123456mongorestore -udba -pdba --host=60.205.140.13 --port=27017 \\ --authenticationDatabase admin -dbozhongboyue -cvideo \\ --drop /home/python/nosql_dump/1-5/bozhongboyue/video.bson# 不经常使用如下命令mongoexport --host=192.168.1.217 --port=27017 --username=username \\ --password=passwd --authenticationDatabase admin -dMongodb -cfemn -o femn.json","categories":[{"name":"数据库","slug":"数据库","permalink":"https://www.femn.me/categories/数据库/"}],"tags":[]},{"title":"ghost下载与使用","slug":"ghost","date":"2017-08-18T11:11:58.000Z","updated":"2017-09-23T11:10:15.688Z","comments":true,"path":"2017/08/18/ghost/","link":"","permalink":"https://www.femn.me/2017/08/18/ghost/","excerpt":"","text":"在VPS中,推荐下载最新的ghost1234567891011yum install gcc nodejsnpm install -g ghost-climkdir /var/www/blogcd /var/www/blogghost install localhttp://localhost:2368/# 将url换成你博客的地址vim config.development.json url: http://www.femnyy.comghost restarthttp://www.femnyy.com 配置一下nginx 1234567891011121314151617vim /etc/nginx/conf.d/ghost.conf server &#123; # 定义一个虚拟主机 listen 80; #server_name myip; #server_name 0.0.0.0; 上面的公网IP也不行了, #server_name mydomians; error server_name myip www.femnyy.com; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:2368; &#125; &#125; nginx -t systemctl start nginx systemctl enable nginx setsebool -P httpd_can_network_connect true 访问 http://www.femnyy.com or http://myip/ghost ghost 命令123ghost -h# 其它命令ghost ls/update/start/stop/restart ghost管理界面的一些基本操作同时在管理界面能操作的,就不要去动服务器中的ghost代码,本人能力有限,改了几次,配置都不能用了,只能重新安装(在旧版本中) 设置标签 再将Tab 设置成Navigation,同样新版本也可以操作Design了. 备份你的博客 导入博客 Labs –&gt; Export /Import 提高被搜索的概率 setting –&gt; Meta Date –&gt; 输入搜索时的关键字 开始写博客 有关Markdown的语法手册 图片的处理使用七牛的对象存储 或者用sm.ms支持https 不推荐安装旧版本,旧版本安装不好友,想更新ghost版本也费劲,主要是有可以还安不成功参考于此 install nodejs and setting npm source123456789101112yum -y updateyum install -y gcc-c++ make unzip netstatcurl --silent --location https://rpm.nodesource.com/setup_4.x | bash -yum -y install nodejsnode -vmkdir -p /var/www/cd /var/www/wget https://ghost.org/zip/ghost-latest.zipunzip -uo ghost-latest.zip -d /var/www/ghostcd ghostnpm config set registry http://registry.npmjs.org/npm config set strict-ssl false 其中当npm install –production,下载依赖包时,可能会遇到内存不足的问题,可以通过增加交换空间来解决 12345678sudo dd if=/dev/zero of=/swapfile bs=1024 count=1024ksudo mkswap /swapfilesudo swapon /swapfilevim /etc/fstabecho 10 | sudo tee /proc/sys/vm/swappinessecho vm.swappiness = 10 | sudo tee -a /etc/sysctl.confsudo chown root:root /swapfile sudo chmod 0600 /swapfile install ghost 123456789101112131415cd /var/www/ghostnpm install --production# start ghostcp config.example.js config.jsvim config.js config = &#123; production: &#123; url: 'http://myip'sudo firewall-cmd --permanent --add-port=80/tcpsudo firewall-cmd --permanent --add-port=2368/tcpfirewall-cmd --reloadnpm start --productionss -lnp |grep 2368http://localhost:2368/ghostkill -9 ** use pm2 manage ghost 之后就可以不用 nohup npm start –production 启动了 12345678npm install -g pm2echo \"export NODE_ENV=production\" &amp;gt;&amp;gt; ~/.profile. ~/.profilepm2 start index.js --name ghost# pm2其它命令pm2 show/start/stop ghostpm2 status/logs/save# 自从我修改了default.hbs之后,pm2就用不了了,害得我还得去重新install ghost install nginx1234yum -y install epel-releaseyum -y updateyum -y install nginx# 配置方法和最新的ghost配置一样 访问 http://www.femnyy.com or http://myip/ghost 如果是在国内安装的话,可能会比较慢,推荐用淘宝镜像安装,你可以使用我们定制的 cnpm (gzip 压缩支持) 命令行工具代替默认的 npm: 1npm install -g cnpm --registry=https://registry.npm.taobao.org update nodejs npm123sudo npm cache clean -fsudo npm install -g nsudo n stable ghost文档帮助","categories":[{"name":"server","slug":"server","permalink":"https://www.femn.me/categories/server/"}],"tags":[]},{"title":"vim基本语法","slug":"vim_grammar","date":"2017-08-17T15:44:24.000Z","updated":"2017-09-23T11:10:15.716Z","comments":true,"path":"2017/08/17/vim_grammar/","link":"","permalink":"https://www.femn.me/2017/08/17/vim_grammar/","excerpt":"","text":"普通模式下操作符 &gt;G &gt;gg # 缩进 y复制 d删除 C == c$ #c是修改,删除之后进入插入模式 s == cl # l一个字符 aw一个单词(iw不涉及到空格,ciw推荐) ap一个段落 S == ^cc # 删除一整行 # g命令空间 g~l # 反转大小写 guw # 转化成小写 gUU # 转化成大写 :!nginx -s reload # 使用外部命令 当前文件中的移动u # 撤消 &lt;ctrl-r&gt; # 重做 动作命令 w b e ge # 对单词 动作的移动程度和方向 W B E gE # 对字串 动作的移动程度和方向 * 和 #符号 # 匹配光标当前的所有单词 % # 匹配括号移动 f+ # 查找当前行的下一个&apos;+&apos;字符,定位到&apos;+&apos; F上一个 t+ # 查找当前行的下一个&apos;+&apos;字符,定位到&apos;+&apos;的上一个字符 T上一个 3fa → 在当前行查找第三个出现的a ; # 重复 , # 退回 yaw yt, f,dt. d/ge&lt;CR&gt; # 查找动作告诉d操作符删除什么 #Vim的文本对象由两个字符组成,第一个字符永远是i或a.文本对象自身并不是动作命令,不能用它们在文档中移动 # 但我们却可以在可视化及操作符待决模式中使用文本对象 #操作分隔符的文本对象 m{a-zA-Z}要在其内部 a)==ab a}==aB at#一对XML标签 it #XML标签内部 vi) ci) # 操作文本块的文本对象 daw ciw # 设置位置标记 m{a-zA-Z}#小写每个缓冲区局部可见,大写全局可见 mm `m # Vim的自动位置标记 &apos;&apos; # 当前文件中上次跳转动作之前的位置 &apos;. # 上次修改过的地方 &apos;^ # 插入 &apos;[ # 上次修改或复制的起始位置 &apos;] # 结束 &apos;&lt; # 高亮选区 &apos;&gt; # 结束 # 括号间的跳转 % # 当不同文件之间的移动和跳转 任何改变当前窗口中活动文件的命令,都可以称为跳转命令 Vim会把执行跳转命令之前和之后的光标位置,记录到跳转列表中 &apos;&lt;ff&gt;&apos; @: # 重复上次的Ex命令 :s%/old/new/g # 替换 1&lt;ctrl-a&gt; # 对当前行的一下数字加1 1&lt;ctrl-x&gt;:减一 # 重绘屏幕 zz #把当前行显示在窗口正中 &lt;ctrl-d&gt;(D) # 向下滚屏 &lt;ctrl-u&gt;(U) # 上 H/M/L # 跳到屏幕最上,中,下方 # 可视化模式 v # 命令行模式 : # 命令行窗口 q: # 替换模式 R gR r{char} gr{char} # 覆盖一个字符之后,马上又回到普通模式 #特别一点 ga #查看任意字符的编码 分别以10,16,8进制的形式显示其字符编码 J将下面的一整行,都提到光标行的末尾 &lt;ctrl-g&gt; # 显示当前文件文件名及状态 寄存器# Vim操作的是寄存器,而并非剪贴板 # &quot;{register}前缀的方式指定要用的寄存器,若不指明则使用无名寄存器 &quot;ayiw &quot;bdd &quot;&quot;yiw &quot;+yy:delete c # 分别 对应寄存器a,b,&quot;,c中 &quot;ap &quot;bp &quot;&quot;p :put c # 对应的复制 # x,s,d,c,y,p命令都会覆盖无名寄存器 # 无名寄存器(&quot;&quot;) &quot;&quot;p==p yaw daw &quot;0p # 有名寄存器(&quot;a-&quot;z) # 黑洞寄存器(&quot;_) # 复制专用寄存器(&quot;0) y命令不仅会被拷贝到无名寄存器中,还拷贝到复制专用寄存器中 # ubuntu 和mint默认安装的vim是不支持系统剪切、粘贴版的 sudo apt-get install -y vim-gnome # 对于非GUI版本的vim,剪切板是不可用的,解决方案很简单,安装一下就是了: sudo apt-get install gvim # 系统剪贴板(&quot;+) # 将系统剪贴板的内容粘贴到Vim内部 &quot;+p # 插入模式下&lt;ctrl-r&gt;+,&quot;,a,0 # 将Vim的文本捕获到系统剪贴板 &quot;+yy &quot;%p # &quot;%当前文件名 &quot;.p # &quot;.上次插入的文本 # 只读(read-only)寄存器: &quot;:,分别缓存最近命令 &quot;.,最近插入文本 &quot;%,当前文件名 &quot;#,当前交替文件名 # 代换单词 yiw jww ve p yiw jww ciw&lt;ctrl-r&gt;0&lt;Esc&gt; 宏:在录制一个宏时,要确保每条命令都可被重复执行,同时禁止使用鼠标而且当动作命令(j,n)停止时,宏将中止运行#打任意数目的按键操作录制到寄存器,用于之后的回放 # 把命令序列录制成宏 qa #录制宏的开始 q{register},从而指定一个用于保存宏的寄存器 A;&lt;Esc&gt; Ivar &lt;Esc&gt; q # 停止宏录制 j @a j@@ :reg a # 查看寄存器的内容 @a # @{register} 执行指定寄存器的内容, @@ # 重复最近高过的宏 10@a # 加次数回放宏 .命令不能执行次数 f+ s_+_&lt;Esc&gt; qq;.q 22@q # 串行的运行宏 j :next 10@a # 加次数回放宏 .命令不能执行次数 # 并行的运行宏 :&apos;&lt;,&apos;&gt;normal @a # 单个文件的多行并行运行宏 :args *.py # 建立目标文件列表 :edit! :argdo normal @a # 当在多个文件中 进行并行运行宏时,执行宏一旦失败,不方便找到到底哪个失败了 :wall # 给宏追加命令 qA # Vim会录制按键操作,但会把它们附加到寄存器a原有的内容之后 # 编辑宏 :put a # 将宏复制到缓冲区,当前光标的下方,而 &quot;ap 复制到当前光标之后 # 在缓冲区进行对宏的编辑 0 &quot;ay$ dd # 将宏从缓冲区复制回寄存器 插入模式&lt;ctrl-h&gt; &lt;ctrl-w&gt; &lt;ctrl-u&gt; # 都是删除操作 # 插入-普通模式 &lt;ctrl-o&gt; #切换到插入-普通模式,在此后可执行一条普通模式下的命令后,再回到插入模式 &lt;ctrl-o&gt;zz # # 复制专用寄存器(&quot;0) y命令不仅会被拷贝到无名寄存器中,还拷贝到复制专用寄存器中 &lt;ctrl-r&gt;0 # 0就是寄存器的名字 在命令行中yaw,默认寄存器的名字是0 &lt;ctrl-r&gt;&lt;ctrl-p&gt;0 # 它会按原义插入寄存器内的文本,并修正任何不必要的缩进 &lt;ctrl-r&gt;=9*9&lt;CR&gt; # 表达式寄存器 &lt;ctrl-r&gt;= &lt;C-p&gt;或是&lt;C-n&gt;,自动补齐功 &lt;ctrl-v&gt;065 # A用字符编码插入字符,vim所接受的字符编码共包含3位数 &lt;ctrl-v&gt;u00bf # 编码超过3位的,可以用4位16进制编码来输入 &lt;ctrl-v&gt;&lt;Tab&gt; # 如果后面跟一个非数字键,它会插入这个键本身所代表的字符 可视模式v V &lt;ctrl-v&gt; o # 切换高亮选区的活动端 gv # 重选上次的高亮选区 yyp--&gt;Vr# # ####横编排 &lt;ctrl-v&gt;3j$ #竖编排 = # 自动给缩进 命令行(EX命令)@: # 在普通模式下执行 重复上次的Ex命令 / &lt;ctrl-r&gt;= # 访问表达式寄存器也会激活命令行模式 # 有些命令可以在插入和命令行模式下通用 &lt;ctrl-r&gt;0 #复制寄存器的内容 &lt;ctrl-h&gt; &lt;ctrl-w&gt; &lt;ctrl-u&gt; # 都是删除操作 /the/ ?the? :1,$ == :% # 整个文件 :. # 光标所有行 :0 #虚拟行 位于文件第一行上方 # 删除行 :3d == 3G+dd :.d # 删除当前行 # 复制行t,移动行m :6t. # :[range]t{address} 把第六行复制到当前行下方 :t6 当前 第六行 :t. == yyp :&apos;&lt;,&apos;&gt;t$ # 将高亮选区的内容复制到文本结尾处 A; :&apos;&lt;,&apos;&gt;normal . == :&apos;&lt;,&apos;&gt;normal A; # 对高亮选区中的每一行,对其执行普通模式下的 . 命令. # 自动补全Ex命令 &lt;ctrl-d&gt; &lt;Tab&gt; &lt;Shfit-Tab&gt; :colors&lt;Tab&gt; :colorscheme &lt;Tab&gt; # 把当前光标的单词插入到命令行 &lt;ctrl-r&gt;&lt;ctrl-w&gt; # 把当前光标的字串插入到命令行 &lt;ctrl-r&gt;&lt;ctrl-a&gt; # 命令行窗口,就像一个常规的Vim缓冲区,只不过它的内容都对应着命令历史中的一个条目 q: # 打开Ex 命令历史 k j键进行移动 ,&lt;CR&gt;将会把当前行的内容当成Ex命令执行 q/ # 打开查找 :q #关闭命令行窗口 像操作普通Vim窗口一样 其它的操作也可以 &lt;ctrl-f&gt; # 从命令行模式切换到命令行窗口 # 运行shell :!{cmd} # 执行一次性命令 :shell # 启动一个交互的shell会话 exit # 退出此shell并返回Vim # 也可以在普通模式下 &lt;ctrl-z&gt;挂起Vim进程,$jobs $fg [作业号] :read !{cmd} # 将标准输出插入到光标下方 :[range]write !{cmd} # 将range(默认是整个文件)每行内容,作为此命令的输入 :%!sort -t &apos;,&apos; -k 2 # 以逗号分隔,按第二个字段进行排序 :tabnew # 创建新标签页 :split 文件路径 #分割窗口,如果不指定文件路径,默认是分割本文件 :set ignorecase #查找单词时需要忽略大小写 :set hlsearch # 可以将查找的内容设置成高亮 :set history=200 #设置保存命令的条数 参数列表(vi的一个功能)是缓冲区列表(Vim增加的功能)的强力补充vim vim_grammar.md linux.md :ls #缓冲区列表 %哪个缓冲区在当前容器中可见 #代表轮换文件&lt;ctrl-^&gt;进行快速切换 # Vim是用缓冲区列表对打开的文件进行管理的 # 选择缓冲区 :buffer N/bufname # N是Vim自动分配的编号由上面的命令行得知 bufname是文件名 :bprev :bnext :bfirst :blast #退出(保存)所有的缓冲区 :qall! :wall # 删除缓冲区 :bdelete N1 N2 # 用参数列表将缓冲区分组 # 查看参数列表 :args :args *.py # 建立目标文件列表 #如果活动缓冲区的内容发生了变化,Vim会在离开缓冲区时自动将其设为隐藏(默认会有错误信息&apos;文件已修改但未保存&apos;) #&apos;hidden&apos;设置让我们用一条;argdo {cmd}或 bufdo{cmd}命令就可以修改一组缓冲区. 分割窗口# 创建分割窗口 &lt;ctrl-w&gt;s &lt;ctrl-w&gt;v :sp[lit] {file} #载入新文件 :vsp[lit] {file} # 关闭窗口 &lt;ctrl-w&gt;c #关闭活动窗口 :clo[se] &lt;ctrl-w&gt;o #保存活动容器,关闭其它所有窗口 :on[ly] # 切换窗口 &lt;ctrl-w&gt;w # 窗口循环切换 &lt;ctrl-w&gt;h j k l #改变窗口 &lt;ctrl-w&gt;= [N]&lt;ctrl-w&gt;_ # 最大化高度 [N]&lt;ctrl-w&gt;| # 宽度 [N]&lt;ctrl-w&gt;&lt; # &gt; 在Vim中,标签页是可以容纳一系列窗口的容器口:tabnew # 创建新标签页 :tabe[dit] {filename} # 在新标签页打开{filename} 如果没有指定文件,会建立一个新标签页,里面包含一个空缓冲区 :&lt;ctrl-w&gt;T #当标签页中包含了不只一个窗口时,用此命令 把当前窗口移到一个新标签页 :tabc[lose] # 关闭当前所有标签页的窗口 :tabo[nly] # 关闭其它 [N]gt # 下 :tabn[ext] [N]gT # 切换到上一标签页 :tabp[revious] 打开文件#Vim也有工作目录的概念,这各bash及其他shell是一样的 #相对于活动文件目录下打开一个文件 :edit %:h&lt;Tab&gt; # %代表活动缓冲区的完整文件路径 :h修饰符会去除文件名 也就是此命令会被展开为当前文件所有目录的路径 :set path+=app/** # 匹配app/目录下所有子目录 :find 文件名 # netrw管理文件系统 # 打开文件管理器 $ vim . :edit %:h ==:e . ==:Explore ==:E # 上面的操作都会代替当前的缓冲区内容 # 当要保存到不存在的目录中时 :!mkdir -p %:h #-p创建任何不存在的中间目录 # 我们可以把任务委派给一个以sudo运行的shell进程,来完成工作 :w !sudo tee % &gt;/dev/null # :w将缓冲区的内容作为sudo tee的标准输入,%是当前文件 # 此时Vim会检测到该文件被一个外部程序改了,所以Vim会提示我们做出选择,是保留缓冲区的还是载入磁盘上的版本 vim对于ctage的支持,1.我们可以快速地跳到到函数及类的定义之处,实现浏览整个代码库的目的.(基于标签的跳转)2.用于建立自动补全的单词列表 安装和运行ctagesudo apt-get install exuberant-ctags sudo apt install linuxbrew-wrapper # 检测系统是否安装了ctags以及路径正确与否 brew install ctags ctags --help 用ctags创建代码库的索引# 手动创建索引 cd ~/app1.6 ctags -R * # 应该可以用!cd /home/python/app1.6 &amp;&amp; ctags -R * # Linux下的C/C++的程序员,使用VIM+Ctags的组合来写程序也许是最佳的选择 # 好像没有递归子目录,所以为子目录创建索引 cd main &amp;&amp; ctags -R * cd ../app1.6 #必须要cd到此目录或者 main目录下,可由 :set tags 查看 vim runner # 这样本地的所有代码,都正确的创建了索引,但源代码还是没有办法创建索引 :tabnew /home/python/app1.6/runner.py :set tags? &lt;ctrl-]&gt; # 会从当前所在的关键字跳转到它的定义处 , g&lt;ctrl-]&gt; &lt;ctrl-t&gt; # 充当着后退按钮","categories":[{"name":"linux","slug":"linux","permalink":"https://www.femn.me/categories/linux/"}],"tags":[]},{"title":"编译工具","slug":"linux_gcc","date":"2017-08-17T15:44:24.000Z","updated":"2017-09-23T11:10:15.696Z","comments":true,"path":"2017/08/17/linux_gcc/","link":"","permalink":"https://www.femn.me/2017/08/17/linux_gcc/","excerpt":"","text":"1vim bar.c 1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;int foo(int n);void bar(int m);int main(void)&#123; int a; char *s = \"hello, world\"; printf(\"%s\\n\",&amp;s[7]); a = 5; foo(a); return 0;&#125;int foo(int n)&#123; int b; b = n; b *=2; bar(b); return b;&#125;void bar(int m)&#123; printf(\"hi,i am bar!\\n\");&#125; gcc程序编译1gcc -g -Wall bar.c -o bar 编译可分为四个阶段:1.预处理:宏定义,头文件2.编译:c–&gt;汇编语言3.汇编:汇编成目标文件 .o (二进制文件)4.链接:把所有的目标文件和库文件链接成一个可执行的文件 gcc 参数-I /home/include:指定头文件路径,先找预设路径-L /usr/lib:库文件路径,先找指定目录,再找系统预设路径-lfun:库文件中指定函数库 libfun.a-static:静态链接库文件 .a为后缀,将所需要的函数copy到执行文件中而动态链接库以 .so为后缀 指明当程序执行时,首先必须载入这个库,缺省操作-Wall:生成所有的警告信息-g:产生调试工具所必须的-c:只生成一个.o后缀的目标文件 gdb程序调试1gdb bar 12345678910111213141516171819202122232425break main //内存中main函数的入口地址 b 行号 ,b 文件名:行号run //rlist //lprint a //殘值而已,不是我们赋的值 pprint s //也是殘值 print &amp;a next next next step next print &amp;bprint s+90 //通过gdb 可以在内存中任意跳转next //nprint snextprint s[7]print &amp;s[7]print a //残值nextprint astep //进入foo子函数 snextnext print nprint bstep //进入bar函数print mcontinue //返回0 正常退出 c继续运行程序b 5 if i=10 当i等于10时第5行断点生效delete 断点编号 :删除断点quit //q Makefile工程管理当有很多个文件都需要编译时,不可能一个一个的去gcc吧通过make命令就能够使整个软件工程完成编译和链接make在执行行,需要一个命名为Makefile的文件,它描述了整个工程的编译,链接等规则","categories":[{"name":"linux","slug":"linux","permalink":"https://www.femn.me/categories/linux/"}],"tags":[]},{"title":"linux 服务与进程","slug":"linux-server-process","date":"2017-08-17T15:44:24.000Z","updated":"2017-09-23T11:10:15.696Z","comments":true,"path":"2017/08/17/linux-server-process/","link":"","permalink":"https://www.femn.me/2017/08/17/linux-server-process/","excerpt":"","text":"linux启动流程通电 –&gt;BIOS(哪个磁盘有MBR) –&gt;MBR(哪个分区为要开启的OS) –&gt;OS –&gt;/boot(kernel) –&gt;init(PID:1) –&gt;/etc/rc*.d/ –&gt;/etc/init.d/ –&gt;用户登陆(/etc/profilc–&gt;~/.profile .bash_login .bash_profile–&gt;~/.bashrc) 添加启动项/etc/rc[0~6].d 这7个目录中,每个目录分别存放着对应运行级别加载时需要关闭或启动的服务,每个脚本文件都对应着/etc/init.d/目录下具体的服务 K开头的脚本文件代表运行级别加载时需要关闭的,S开头的代表需要执行,数字代表执行顺序因此,当我们需要开机启动自己的脚本时,只需要将可执行脚本丢在/etc/init.d目录下,然后在/etc/rc*.d中建立软链接即可 12345678910111213sudo shmod 755 /etc/init.d/sshcd /etc/init.dsudo update-rc.d ssh defaults 95 5 . # 执行顺序95,加入运行级别5级中#即在rc*.d中各建立了一个软连接,因此也可以自己手动建立软连接,如下ln -s /etc/init.d/ssh /etc/rc5.d/S95sshdsudo /etc/init.d/ssh startsudo service S95sshd start# 开机启动sudo apt-get install openssh-server# 二选一sudo /etc/init.d/ssh startsudo service sshd start 简单的启动命令Linux 在启动的时候会执行 /etc/rc.local 里面的脚本,所以只要在这里添加执行命令就可以 123456789vim /etc/rc.local/usr/bin/supervisord -c /etc/supervisor/supervisord.conf# 如果是 Ubuntu 16.04 以上,rc.local 被当成了服务,而且默认是不会启动,需要手动启用一下服务# 启动rc.local服务:sudo systemctl enable rc-local.service# 如果有图形桌面的话super键--search \"startup\"--&gt;设置开机启动选项,最重要的就是找到程序的绝对路经写上就可以.可以通过如下命令查看:vim ~/.config/autostart/chromium-browser.desktop 也可以使用第三方包来管理启动程序 定时任务12345678910111213vim /etc/crontab # 权限要一致,且要可执行# 分 时 日 月 周 命令# 每天11点执行0 11 * * * root sh /home/python/xx.sh # 每两个小时 0 */2 * * * echo \"Have a break now.\" &gt;&gt; /tmp/test.txt# 晚上11点到早上8点之间每两个小时和早上八点 0 23-7/2,8 * * * echo \"Have a good dream\" &gt;&gt; /tmp/test.txt# 保存退出即生效(刚添加的任务会到2-3分钟后才开始生效) 查看服务状态12345678910111213141516# ubuntu centosservice sshd status/stop/restart # service 在rc*.d/的名字systemctl start docker #centos启动服务systemctl enable docker # 开机启动systemctl status nginxsystemctl start firewalld.servicesystemctl enable firewalld.servicesystemctl daemon-reload # 修改启动参数时的 systemctl restart docker# 只有systmectl 状态 服务名# redhat 操作系统下chkconfig 命令chkconfig --list sshd 进程有关的“衍生出来的进程”正是 Linux 的父子进程的概念.当我们登录系统后,会取得一个 bash shell,然后我们利用这个 bash 提供的接口去执行另一个命令, 例如 bash 或者 ps 等.那些另外执行的命令也会被触发成为 PID,那个后来执行的命令产生的 PID 就是”子进程”,而原本的 bash 环境下,就称为”父进程”了123456789101112bashps -o pid,ppid,tty,time,cmd PID PPID TT TIME CMD 11373 4396 pts/12 00:00:00 bash 13043 11373 pts/12 00:00:00 bash 13110 13043 pts/12 00:00:00 ps -o pid,ppid,tty,time,cmdPID: 运行着的命令(CMD)的进程编号PPID:父进程号TTY: 命令所运行的位置(终端)TIME: 运行着的该命令所占用的CPU处理时间CMD: 该进程所运行的命令# ps 仅仅显示本终端的进程 我所做的操作是在原来的 bash shell 中执行了 bash 命令,然后又执行了 ps -o pid,ppid,comm命令.我们可以看到,第二个进程 bash 是第一个进程 bash 的子进程,而第三个进程ps是第二个进程的子进程 新的进程要通过老的进程复制自身得到,这就是 fork.fork 是一个系统调用.进程存活于内存中.每个进程都在内存中分配有属于自己的一片空间 (内存空间,包含栈、堆、全局静态区、文本常量区、程序代码区). 当一个程序调用 fork 的时候,实际上就是将上面的内存空间,又复制出来一个,构成一个新的进程,并在内核中为该进程创建新的附加信息 (比如新的 PID,而 PPID 为原进程的 PID).此后,两个进程分别地继续运行下去.新的进程和原有进程有相同的运行状态(相同的变量值,相同的指令…).我们只能通过进程的附加信息来区分两者. 工作管理(job control)是用在 bash 环境下的,也就是说,当我们登录系统取得 bash shell 之后,在单一终端机下可以同时进行多个工作的行为管理. 假如我们只有一个终端,因此在可以出现提示符让你操作的环境就成为前台(foreground),至于其他工作就可以放在后台(background)去暂停或运行程序调用 exec 的时候,进程清空自身的内存空间,并根据新的程序文件重建程序代码、文本常量、全局静态、堆和栈(此时堆和栈大小都为 0),并开始运行. 直接将命令放到后台执行 ( &amp;)将目前工作放到后台并暂停(ctrl+z)将后台工作拿到前台来处理(fg %工作序号)进程管理命令ps: PID,CMD,PORT12345678910111213141516171819202122232425262728ps # 仅仅显示本终端的进程-a # 显示终端中进行的所有进程-x # 会显示没有控制终端的进程-e # 所有的进程-u # 查看某个用户的所有进程-f # 来查看格式化的信息列表ps -u femn # 查看所有femn用户的进程 ps aux # 可以对系统进程更加全面的了解ps -aux | less # less是一个分页显示文件的工具工具,它允许你一页一页(或一个屏幕一个屏幕)地查看信息ps -ef # 所有进程 PID PPID ps -efH # 把输出的进程组成一个层级的格式 树状 ps axjf # 树状视图 等于 pstreeps -ef | grep python3 | cut -c 10-15 | xargs kill -9 # Kill 某个用户或命令的所有进程ps axjf |grep nginxpgrep nginx # 单单的得到PID,和其子进程号ps -aux --sort -pcpu | head -n 10# 根据 CPU 使用来升序排序 +pcpu倒序ps -aux --sort -pmem | head -n 10# 根据 内存 使用来升序排序ps -aux --sort -pcpu,-pmem | head -n 10# 仅仅得到本机的程序名相关的进程ps aux/-ef |grep ssserver # 程序名(命令名)或者PID netstat:PID,CMD,PORT12345678# 会牵扯到此程序 相关联的socket服务,或其它的网络相接进程(网络是双向的)netstat -anp |grep ssh #程序名 得到PID 端口号netstat -lnp |grep 8388 #端口号 得到PID,进程名sudo lsof -i :8001 #查看此端口 PID,User,进程名ll /proc/进程号 sudo lsof -p 1609killall http* 它支持通过进程名而不是进程号来结束进程,也支持通配符. top123456top # 动态显示进程 q 退出, M 内存占用降序排序,P 按CPU占用降序排序 [top使用说明](http://www.linuxidc.com/Linux/2011-03/33582.htm)ssserver内存占用随时间升高free -m # 内在的使用情况# 查看目前进程正在实际被使用的内存,是used-(buffers+cache)htop # 更加友好的显示top 进程的状态sleepingD(sleeping),往往是由于 I/O(磁盘IO,网络IO,其他外设IO) 资源得不到满足,而引发等待 举个例子,当 NFS 服务端关闭之时,若未事先 umount 相关目录,在 NFS 客户端执行 df 就会挂住整个登录会话,按 Ctrl+C 、Ctrl+Z 都无济于事.断开连接再登录,执行 ps axf 则看到刚才的 df 进程状态位已变成了 D ,kill -9 无法杀灭. 正确的处理方式,是马上恢复 NFS 服务端,再度提供服务,刚才挂起的 df 进程发现了其苦苦等待的资源,便完成任务,自动消亡.若 NFS 服务端无法恢复服务,在 reboot 之前也应将 /etc/mtab 里的相关 NFS mount 项删除,以免 reboot 过程例行调用 netfs stop 时再次发生等待资源,导致系统重启过程挂起. zombileZ(zombie) 之所以杀不死,是因为它已经死了,否则怎么叫 Zombie(僵尸).在UNIX/Linux中,每个进程都有一个父进程,进程号叫PID(Process ID), 相应地,父进程号就叫PPID(Parent PID). 当进程死亡时,它会自动关闭已打开的文件,舍弃已占用的内存、交换空间等等系统资源,然后向其父进程返回一个退出状态值,报告死讯.如果程序有 bug,就会在这最后一步出问题.子进程说我死了,父进程却没听见,所以子进程便成了僵尸.在UNIX/Linux中消灭僵尸的手段比较残忍,执行 ps axjf 找出僵尸进程的父进程号(PPID,第一列),先杀其父,然后再由进程天子 init(其PID为1,PPID为0)来一起收拾父子僵尸.注意,子进程变成僵尸只是碍眼而已,并不碍事,如果僵尸的父进程当前有要务在身,则千万不可贸然杀之. 这些进程已经死亡,但没有释放系统资源,包括内存和一些一些系统表等,如果这样的进程很多,会引发系统问题.用ps -el看出的进程状态如果是Z,就是僵尸进程.12345ps -ef|grep defunc # 可以找出僵尸进程# 清除ZOMBIE(僵尸)进程可以使用如下方法:kill –18 PPID (PPID是其父进程)# 这个信号是告诉父进程,该子进程已经死亡了,请收回分配给他的资源. 如果不行则看能否终止其父进程(如果其父进程不需要的话).先看其父进程又无其他子进程,如果有,可能需要先kill其他子进程,也就是兄弟进程.方法是:12kill –15 PID1 PID2 # (PID1,PID2是僵尸进程的父进程的其它子进程).kill –15 PPID # 然后再kill父进程,这样僵尸进程就可能被完全杀掉了","categories":[{"name":"linux","slug":"linux","permalink":"https://www.femn.me/categories/linux/"}],"tags":[{"name":"server","slug":"server","permalink":"https://www.femn.me/tags/server/"}]},{"title":"shadowsocks","slug":"shadowsocks-server","date":"2017-08-16T15:24:48.000Z","updated":"2017-09-23T11:10:15.708Z","comments":true,"path":"2017/08/16/shadowsocks-server/","link":"","permalink":"https://www.femn.me/2017/08/16/shadowsocks-server/","excerpt":"","text":"用shadowsocks作为翻墙的工具一般的翻墙工具还有VPN,pptp是VPN的一种,我们在这里介绍的是shadowsocks翻墙工具 shadowsocks 官网 centos7 install shadowsocks 123456789101112131415161718yum install python-setuptools &amp;&amp; easy_install pip pip install shadowsocksvim /root/ss/ssserver.json &#123; \"server\": \"0.0.0.0\", \"server_port\": 8388, \"local_address\": \"127.0.0.1\", \"local_port\": 1080, \"password\": \"yourpassword\", \"timeout\": 300, \"method\": \"aes-256-cfb\", \"fast_open\": false &#125;systemctl start firewalld.servicesystemctl enable firewalld.servicefirewall-cmd --permanent --add-port=8388/tcpfirewall-cmd --reload 启动 ssserver服务1nohup ssserver -c /root/ss/ssserver.json -d start &amp; 查看ssserver 有没有启动成功 1ps aux |grep ssserver 如果没有成功,可能是因为/root/ss/ssserver.json 的server_ip的原因,我买了个国际阿里云的ECS服务器,我写的是公网的IP,结果一直运行不起来因为公网是通过nat IP实现的(所以在安全组中只能是选择内网进行配置),所以改成Privaty IP就可以正常启动了,最好是设置为0.0.0.0就好. 阿里云的ECS服务器上配置使用任意端口的服务后,端口会自动开启监听,但它还有一个安全组的概念,最好设置一个(内网 入 允许 全部 -1/-1 0.0.0.0/0 优先级110)这样就完全可以由ECS的系统完全的操作防火墙,就像没有安全组概念一样了. centos7 install BBR 要注意下sudo grub2-set-default 0,应该是为0的,使用最新的,文档却写成了11234567891011121314151617181920212223242526# update kernet# look current kernetuname -r# Install the ELRepo repo:sudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgsudo rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm# install newer kernetsudo yum --enablerepo=elrepo-kernel install kernel-ml -y# look install newer kernetrpm -qa | grep kernelsudo egrep ^menuentry /etc/grub2.cfg | cut -f 2 -d \\'# setting newer kernetsudo grub2-set-default 0sudo shutdown -r nowuname -r# enable BBrecho 'net.core.default_qdisc=fq' | sudo tee -a /etc/sysctl.confecho 'net.ipv4.tcp_congestion_control=bbr' | sudo tee -a /etc/sysctl.confsudo sysctl -psudo sysctl net.ipv4.tcp_available_congestion_controlnet.ipv4.tcp_available_congestion_control = bbr cubic renosudo sysctl -n net.ipv4.tcp_congestion_controlbbrlsmod |grep bbr # output tcp_bbr 16384 0 client install shadowsocks 123456#ubuntusudo add-apt-repository ppa:hzwhuang/ss-qt5sudo apt-get updatesudo apt-get install shadowsocks-qt5ss-qt5# 将ssserver.json的配置,设置到ss中 注意:一定要再去配置下代理Pxory 0.0.0.0:1080 或者用本地的.pac文件,Local Port就必须和service.pac文件(此文件是过滤网址用的,如果访问文件中的网址则走代理)启动的端口一致.http://pac.ddcc.me/1.pac == local.pac 在国际里云购买的ESC,配置好shadowsocks之后,在手机上能正常使用,也不需要去设置代理,但在Ubuntu桌面下却一直用不了 如果自己不想搭建服务器的话,可以按下面的操作进行翻墙: Shadowsocks免费账号分享,但这个网址要先翻墙才行,哈哈 具体的使用:在免费账号分享的这个网址上 1.使用二维码:点击二维码会出现一个二维码的图 这里打开shadowsocks软件–&gt;点鼠标右键–&gt;add–&gt;scan QR code on screen 2.使用生成二维码的url:在add–&gt;选择url中ss以及后面的部分如果失败的话,可以换其它的二维码试试. 这个是我大哥自己搭建的一些ss帐号 ubuntu /etc/resolv.conf123nameserver 127.0.1.1# nameserver 8.8.8.8search DHCP HOST 加速SS的链接速度","categories":[{"name":"server","slug":"server","permalink":"https://www.femn.me/categories/server/"}],"tags":[]},{"title":"内容分发网络","slug":"CDN-server","date":"2017-08-16T15:24:48.000Z","updated":"2017-09-23T11:10:15.664Z","comments":true,"path":"2017/08/16/CDN-server/","link":"","permalink":"https://www.femn.me/2017/08/16/CDN-server/","excerpt":"","text":"CDN:内容分发网络(Content delivery network或Content distribution network,缩写:CDN)是指一种通过互联网互相连接的电脑网络系统,利用最靠近每位用户的服务器,更快、更可靠地将音乐、图片、视频、应用程序及其他文件发送给用户,来提供高性能、可扩展性及低成本的网络内容传递给用户 CDN的作用1.加速您网站的访问:访问者的每个访问请求,都会被自动发送到物理距离最近、速度最快的节点上.将blog内容的所有的东西(图片,文字,视频)都是保存在自己的服务器中,要从自己的服务器中取得,当如果某个页面需要加载很多内容时,速度就会变慢.而cdn就会把所以网址上的东西,全部分送到它们在全世界各地所架设的云端的伺服务器上,也就是说我的网址会被散播(拆解)到全世界的伺服务器上,取最近的. 2.防骇客,抵御DoS攻击,访问我们的网址,相当于访问到云端的伺服务器上.3.可以承受网站的流量,节省您的流量:您的网站内容将被缓存在 CloudFlare 的节点中,访问者并不直接从您的主机获取内容,从而最大限度地节省主机的流量同时网站的下载速度也会比以往的快些. 使用cloudflare加速cloudflare是一个国外著名的免费CDN网站加速服务公司甚至可以在网站主服务器宕机的情况下,访问者依然可以通过 CloudFlare 的分发服务器访问到您的网站 使用cloudflare的教程 但使用了cloudflare之后,就不再支持泛域名的解析了,所以还得多配置nginx.","categories":[{"name":"server","slug":"server","permalink":"https://www.femn.me/categories/server/"}],"tags":[]},{"title":"sshd","slug":"sshd-server","date":"2017-08-16T15:24:48.000Z","updated":"2017-09-23T11:10:15.712Z","comments":true,"path":"2017/08/16/sshd-server/","link":"","permalink":"https://www.femn.me/2017/08/16/sshd-server/","excerpt":"","text":"server12345678910111213141516171819202122232425sudo apt-get install openssh-serverps ef|grep sshsudo /etc/init.d/ssh start 或者 service sshd start# 创建一个普通用户useradd usernamepasswd usernamevim /etc/ssh/sshd_config Port 22333 PermitRootLogin no TCPKeepAlive yes ClientAliveInterval 360 ClientAliveCountMax 20# 给普通用户附sudo权限chmod u+w /etc/sudoersvim /etc/sudoers root ALL=(ALL) ALL username ALL=(ALL) ALLchmod u-w /etc/sudoers/etc/init.d/ssh startservice sshd restartfirewall-cmd --permanent --add-port=22333/tcpfirewall-cmd --reload client1ssh -p 22333 username@ip SSH无密码登录123456789# client:生成SSH公钥ssh-keygen -t rsa -C \"邮箱\" # 将SSH公钥上传到Linux服务器ssh-copy-id -p 22 username@remote-server# 将client端的gedit ~/.ssh/id_rsa.pub的内容放到server端~/.ssh/authorized_keys# 等同于如下cat ~/.ssh/id_rsa.pub | ssh username@your_host \\ \"cat - &gt;&gt; /home/username/.ssh/authorized_keys\"","categories":[{"name":"server","slug":"server","permalink":"https://www.femn.me/categories/server/"}],"tags":[]},{"title":"VPS搭建网站","slug":"vps-server","date":"2017-08-15T11:16:14.000Z","updated":"2017-09-23T11:10:15.716Z","comments":true,"path":"2017/08/15/vps-server/","link":"","permalink":"https://www.femn.me/2017/08/15/vps-server/","excerpt":"","text":"空间(虚拟主机,虚拟空间)它是利用软件在服务器上硬盘上划分出来的一部分容量.共享的是服务器资源.没有独立的IP和操作系统.开通以后只有一个FTP权限.它所支持的程序也是在服务器上默认配置好的.空间一般都装有面板,是傻瓜化的操作由于多台虚拟主机共享一台真实主机的资源,每个用户所要承担的各类费用大幅度降低. 自从进入IT圈,以前使用国内的空间,感觉还行,速度快,但是后面的备案系统让大多数的站长跑到墙外来选择空间:Godaddy、Dreamhost、Froghost、Photonvps等空间相信大多数的站长多多少少都会用过但是随之而来的各种问题都让大家受到精神上的折磨,不过相信大家都是比较的喜欢捣鼓吧,从2012年开始很多的站长都选择到VPS行列中了,以前高高在上的VPS现在已经沦为普通人都买得起用得起的产品了,但是想要好一点的,响应快一点的VPS主机价格还是很贵, VPS还是比较适合对网站空间要求比较高的朋友来使用的,独立IP,完全自主的控制权限这些都是一般的虚拟主机所没有的. 自从2013年digitalocean把SSD的主机价格拉到5元每月之后,相信很多人都从Linode转过来了,不为什么,价格决定啊,而且性能上和高大上的Linode差别不是很多,还是能得到大多数人的肯定,今年Vultr 的杀入,更是让大多数人目瞪口呆,因为价格更加便宜,而且内存上加到到768Ma,而价格最优惠可以到2.5美金一个月,这样的产品绝对是对国人来说是一个杀伤力 VPS(Virtual Private Server)虚拟服务器VPS就是将一台真正的服务器主机(可以理解为独立服务器),分为多台虚拟服务器主机.但是虚拟出来的每一台服务器都有主机独立的内存、CPU、硬盘,因此在性能上相当一台真实存在的主机,但是成本却是很低,降低了初学者进入VPS主机门槛VPS提供商: Vultar,DigitalOcean,Linode,virmach, Bandwagon,国际阿里云 VPS除了可以用来做网站的服务器,还可以建立自己的ssh,vpn,shadowsocks等进行代理翻墙,可以一键快速配置Docker,GitLab,wonCloud.WordPress等其它应用. Vultr VPS采用的是KVM虚拟化技术(openvz 还是 kvm 还是 xen 或者是 vmare ). 1.购买VPS:vultr官网 全球主机交流 站长工具 2.购买域名name.com 购买域名的优惠码: privacyplease 注意:目前只支持paypal或信用卡支持,不支持支付宝 3.设置DNS(将域名记录到此DNS服务器上),并将域名指定到VPS上(域名解析成IP)DNS解析 可以通过My Account –&gt; My Domains –&gt;选择Quick Links这个下拉框的Manage Domain 推荐域名管理页面(添加解析域名记录)将购买的域名放在dnspod下进行管理:便于管理多个域名,只要再修改下name.com的DNS,换成dnspod的域名解析服务器,以后就可以在这里添加解析自己的域名记录了 修改DNS解析服务器 4.申请证书,支持泛域名申请AlphaSSL免费证书教程 1.生成CSR,KEY文件注意: 邮箱:自己常用的邮箱 域名:*.femnyy.com 1234# 也可以用命令行生成openssl req -new -newkey rsa:2048 -nodes -keyout howsvps.key -out howsvps.csr#注意在填写域名时,不需要添加二级域名:femnyy.com这样认证之后的这个证书,就可以是通配使用了并没有将admin@femnyy.com的链接发到我的邮箱上,如果并没有给你发邮箱的话, 2.注册域名邮箱,本人使用的是qq注册域名邮箱 注意: 使用其他邮箱给 admin 邮箱发送一份邮件,能接收,说明没问题！ 不能使用关联的QQ邮箱如果不能接收,检查你的域名 MX / TXT 是否解析到其他地方了别名就是主机记录,别名主机就是记录值然后再加一个成员管理admin 3.免费SSL certificates注意: 认证的邮箱 与上面的1步骤要一致 4.选择你刚刚注册的域名邮箱 5.邮件确认SSL证书申请,点击 I APPROVE,之后会再来一封.crt的文件 安装AlphaSLL教程 6.再将中级证书中,SHA-256 – Orders March 31, 2014 and After的代码,复制到.crt的文件,合成最终的.crt文件 7.再将.crt key文件 复制到服务器上,nginx的配置如下,同腾讯的一样配置 8.有了泛域名之后,就可以在 server_name 增加 *.femnyy.com; 4.上面的证书没有成功的话,那就用腾讯云SSL证书 免费一年csr证书请求文件–交给CA签名后形成服务端自己的证书,认证通过之后,签证机构给你crt文件 crt+key = pem cat crt key = pem123456789101112131415161718192021222324252627282930vim /etc/nginx/conf.d/ghost server &#123; listen 80; #server_name puplic IP; #server_name 0.0.0.0; 上面的公网IP也不行了, server_name www.femnyy.com puplic_IP yy.femnyy.com; #server_name femnyy.com; rewrite ^(.*) https://$host$1 permanent; return 301 https://$server_name$request_uri; &#125; server&#123; listen 443; server_name www.femnyy.com; ssl on; #index index.htm index.html; ssl_certificate /etc/nginx/conf.d/Nginx_ssl/server.crt; ssl_certificate_key /etc/nginx/conf.d/Nginx_ssl/server.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:2368; &#125; &#125;firewall-cmd --permanent --add-port=443/tcpfirewall-cmd --reload 推荐管理主机的状态 nodequery统计访问量其实在dnspod下管理域名时,就会有流量统计这个功能,但本人使用cloudflare加速网页之后,就没有此功能了(可以看下本人的CND设置) 所以使用谷歌统计访问量注册好了之后–&gt;管理–&gt; .js跟踪信息–&gt;代码跟踪–&gt;将网站跟踪的代码复制到ghost的code injection 的Blog Footer 如果有github学生礼包的话,就可以登陆此链接,是教如何使用礼包教程这样就可以免费使用digitalocean VPS和namecheap域名了(免费使用.me的域名一年). 使用digitalocean1.gmail注册的,用paypal必须要充$5,其它支付方式,好像不需要注册时比较坑的时,要等两个小时,害得我不断的去注册个人信息 我去(英语不好哈哈)！同时还比较麻烦的就是在关联paypal的时候,还会发信息给注册paypal的邮箱,并要求回复信息,认证是本人.2.创建实例,居然是用Droplets这个单词","categories":[{"name":"server","slug":"server","permalink":"https://www.femn.me/categories/server/"}],"tags":[]},{"title":"python 函数式编程","slug":"python-fun-program","date":"2017-08-14T11:02:55.000Z","updated":"2017-09-23T11:10:15.704Z","comments":true,"path":"2017/08/14/python-fun-program/","link":"","permalink":"https://www.femn.me/2017/08/14/python-fun-program/","excerpt":"","text":"函数式编程最常见的技术就是对一个集合做Map,Reduce,Filter操作.这比起过程式的语言来说,在代码上要更容易阅读.(传统过程式的语言需要使用for/while循环,然后在各种变量中把数据倒过来倒过去的) 函数式编程的准则:不依赖于外部的数据,而且也不改变外部数据的值,而是返回一个新的值给你 12345678910111213141516171819202122232425262728293031def return_add_model_id(self, modelList): func = lambda x: modify_idKeys(x) # 闭包 model_id = self._id def modify_idKeys(goods): g = goods.copy() for keys, value in goods.items(): if keys == '_id': g[model_id] = value # g.pop('_id'),还保留着 return g return list(map(func, modelList))# 依次执行函数得到结果,并将结果组成一个新的list对象后进行返回province_list = [&#123;'name': '北京市', 'code': '11'&#125;, \\ &#123;'name':'天津市','code':'12'&#125;,&#123;'name':'河北省','code':'13'&#125;]remove_province_list = ['河北省']# 函数式编程的filter 不仅可以做判断的依据,而且还可以修改其值list(filter(lambda x: x.get('name') not in remove_province_list \\ and x.pop('code'), province_list))# [&#123;'name': '北京市'&#125;, &#123;'name': '天津市'&#125;]a = list(map(lambda x, y : x*y, [1.2, 3, 5], [2, 4, 6]))print(a)#[2.4,12,30]a = reduce(lambda x,y:x+y,a)print(a)#44.4def toUpper(item): return item.upper() list(map(toUpper, [\"hao\", \"chen\", \"coolshell\"]))# ['HAO', 'CHEN', 'COOLSHELL']","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"进程间通信(IPC)","slug":"进程间通信","date":"2017-08-14T08:10:53.000Z","updated":"2017-09-23T11:10:15.720Z","comments":true,"path":"2017/08/14/进程间通信/","link":"","permalink":"https://www.femn.me/2017/08/14/进程间通信/","excerpt":"","text":"程序(program)可执行文件(二进制文件)程序的执行实例被称为进程(process),具有并行性,互不干扰的特点Linux中的进程包含3段,和C差不多,分别为代码段,数据段和堆栈段 使用fork函数得到的子进程是继承了整个父进程的地址空间exec()只是用另一个新程序替换了当前进程的正文,数据,堆和栈1234567891011121314151617181920212223242526#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(void)&#123; pid_t result; result = fork(); // fork之后是你进程先执行还是子进程先执行是不确定的 if(result == -1)&#123; perror(\"fork\"); exit; &#125; else if(result == 0)&#123;// fork的返回值 如果在子进程中则返回0 printf(\"child process:%d\\n My PID is %d\\n\",result,getpid()); if(execlp(\"ps\",\"ps\",\"-ef\",NULL)&lt;0)&#123; perror(\"execlp error\"); &#125; &#125; else&#123;//如果在父进程中,则返回子进程ID printf(\"father process:%d\\n My PID is %d\\n\",result,getpid()); &#125;&#125; 管道pipe:单向的,先进先出,无结构的,固定大小的字节流.数据读出后将从管道中移走,其它读进程都不能再读到这些数据.进程试图读空管道时,在有数据定稿管道之前,里程将一直阻塞.同样,管道已经满时,进程再试图琯管道,在其它进程从管道中移走数据之前,写进程将一直阻塞 12345678910111213141516171819202122#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main()&#123; int pipe_fd[2]; if(pipe(pipe_fd)&lt;0) &#123; printf(\"pipe create error\\n\"); return -1; &#125; else &#123; printf(\"pipe create success \\n\"); &#125; // 其时的管理是创建在内核空间上的 close(pipe_fd[0]);//fd[0]文件描述符用于读取管道 close(pipe_fd[1]); //写入管道 &#125; 父进程写,子进程读 有名管道(FIFO) 信号(signal)共享内存消息队列(FIFO)信号量套接字(Socket)","categories":[{"name":"linux","slug":"linux","permalink":"https://www.femn.me/categories/linux/"}],"tags":[]},{"title":"python 闭包","slug":"python-closure","date":"2017-08-11T11:27:40.000Z","updated":"2017-09-23T11:10:15.704Z","comments":true,"path":"2017/08/11/python-closure/","link":"","permalink":"https://www.femn.me/2017/08/11/python-closure/","excerpt":"","text":"闭包(Closure)又称函数闭包(function closures)引用了自由变量的函数.这个被引用的自由变量将和这个函数一同存在,即使已经离开了创造它的环境也不例外.所以,有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体.闭包在运行时可以有多个实例,不同的引用环境和相同的函数组合可以产生不同的实例 在一些语言中,在函数中可以(嵌套)定义另一个函数时,如果内部的函数引用了外部的函数的变量,则可能产生闭包.运行时,一旦外部的 函数被执行,一个闭包就形成了,闭包中包含了内部函数的代码,以及所需外部函数中的变量的引用. 闭包被广泛使用于函数式编程语言 闭包可以形象的把它理解为一个封闭的包裹(封闭作用域),这个包裹就是一个函数,当然还有函数内部对应的逻辑,包裹里面的东西就是自由变量,自由变量可以在随着包裹到处游荡.当然还得有个前提,这个包裹是被创建出来的. 12345678def func(name): def inner_func(age): # 闭包 # name为自由变量 print( 'name:', name, 'age:', age) return inner_funcbb = func('the5fire')bb(26)# name: the5fire age: 26 这里面调用func的时候就产生了一个闭包——inner_func,并且该闭包持有自由变量——name,因此这也意味着,当函数func的生命周期结束之后,name这个变量依然存在,因为它被闭包引用了,所以不会被回收","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"python 装饰器","slug":"python-decorator","date":"2017-08-10T15:31:24.000Z","updated":"2017-09-23T11:10:15.704Z","comments":true,"path":"2017/08/10/python-decorator/","link":"","permalink":"https://www.femn.me/2017/08/10/python-decorator/","excerpt":"","text":"装饰器(decorator):它能对任何可调用的对象进行包装,既能够用于方法也能够用于函数,想要对一个已有的模块做一些”修饰工作”,但又不让这个小装饰(小功能)侵入到原有的模块中的代码里去, 在python中圆括号意味着调用函数.在没有圆括号的情况下,python会把函数当作普通对象 函数名是某个函数的引用(reference),所以,我们可以对同一个函数设置不同的函数名.(可以理解为,函数也是对象,可以通过赋值来设置不同的对象名) 123456789101112&gt;&gt;&gt; def succ(x): return x+1&gt;&gt;&gt; successor = succ&gt;&gt;&gt; successor(10) # 11&gt;&gt;&gt; succ(10) # 11# successor和succ都指向同一个函数(应该是对象),都指向同一个内存区域.&gt;&gt;&gt; id(successor) # 139701625513368&gt;&gt;&gt; id(succ) # 139701625513368&gt;&gt;&gt; del succ&gt;&gt;&gt; successor(10) # 11&gt;&gt;&gt; type(successor) # function 装饰器的两种类型:函数装饰器和类装饰器 函数装饰器无参数装饰器-包装无参数函数12345678910111213141516171819202122232425def decorator(func): # 装饰函数 print('hello') return func@decoratordef foo(): # 被装饰函数 回调函数 闭包函数(当有自由变量) print('foo end') # 其解释器将此方法解释为 # foo = decorator(foo) # 把一个函数当参数传到另一个函数中,然后再回调if __name__ == '__main__': foo # hello foo() # hello # foo end foo_text = decorator(foo) print(type(foo_text)) # hello # hello # &lt;class 'function'&gt; foo_text() # foo end 装饰器的功能是将被装饰的函数当作参数传递给与装饰器对应的函数(名称相同的函数),并返回包装后的(被装饰)的函数 下面这个例子向我们展示了decorator的本质:hello(foo)返回了wrapper()函数,所以,foo其实变成了wrapper的一个变量,而后面的foo()执行其实变成了wrapper()1234567891011121314151617def hello(fn): def wrapper(): print(\"hello, %s\" % fn.__name__) fn() print(\"goodby, %s\" % fn.__name__) return wrapper@hellodef foo(): print(\"i am foo\") # foo = hello(foo)if __name__ == '__main__': foo() # hello, foo # i am foo # goodby, foo 类似地12345678910111213# 多个decorator@decorator_one@decorator_twodef func(): pass # func = decorator_one(decorator_two(func))# 带参数的decorator@decorator(arg1, arg2)def func(): pass # func = decorator(arg1,arg2)(func) # 这意味着decorator(arg1, arg2)这个函数需要返回一个\"真正的decorator\" 无参数装饰器-包装带参数函数123456789101112131415161718192021222324252627def decorator_func_args(func): def handle_args(*args, **kwargs): print(\"handle args start\") func(*args, **kwargs) print(\"handle args end\") return handle_args@decorator_func_argsdef foo2(a, b=2): print(a,b)if __name__ == '__main__': foo2(1) # handle args start # 1 2 # handle args end # 先传递函数名,再传递参数 foo2_text = decorator_func_args(foo2) print('--') foo2_text(1) # -- # handle args start # handle args start # 1 2 # handle args end # handle args end 带参数装饰器 – 包装无参数函数12345678910111213141516171819202122232425262728293031def decorator_with_params(arg_of_decorator): print(arg_of_decorator) def newDecorator(func): print(func) return func return newDecorator@decorator_with_params(\"deco_args\")def foo3(): passif __name__ == '__main__': foo3() # deco_args # &lt;function foo3 at 0x7fba7bfcf7b8&gt; # 先传递参数,再传递函数名 foo3_text = decorator_with_params(\"deco_args\") print('--') foo3 = foo3_text(foo3) # deco_args # &lt;function foo3 at 0x7fba7bfcf7b8&gt; # deco_args # -- # &lt;function foo3 at 0x7fba7bfcf7b8&gt; func = decorator_with_params('1')(foo3) # deco_args # &lt;function foo3 at 0x7ff913a6f730&gt; # 1 # &lt;function foo3 at 0x7ff913a6f730&gt; 带参数装饰器– 包装带参数函数1234567891011121314151617181920212223242526272829303132333435def decorator_with_params_and_func_args(arg_of_decorator): def handle_func(func): def handle_args(*args, **kwargs): print(\"begin\") func(*args, **kwargs) print(\"end\") print(arg_of_decorator, func, args, kwargs) return handle_args return handle_func@decorator_with_params_and_func_args(\"123\")def foo4(a, b=2): print(\"content\")if __name__ == '__main__': foo4(1, b=3) # begin # content # end # 123 &lt;function foo4 at 0x7f4f0f056730&gt; (1,) &#123;'b': 3&#125; foo4_dec = decorator_with_params_and_func_args(\"123\") print('**') foo4_func = foo4_dec(foo4) print('@@') foo4_text = foo4_func(1, b=3) # ** # @@ # begin # begin # content # end # 123 &lt;function foo4 at 0x7f663fd82730&gt; (1,) &#123;'b': 3&#125; # end # 123 &lt;function decorator_with_params_and_func_args.&lt;locals&gt;.handle_func. # &lt;locals&gt;.handle_args at 0x7f663fd827b8&gt; (1,) &#123;'b': 3&#125; 给decorator参数赋值,返回handle_func对象handle_func()函数接收foo4对象,返回handle_args对象handle_args()函数接收传递给foo4的参数.一个有点意义的例子 123456789101112131415161718192021def makeHtmlTag(tag, *args, **kwds): def real_decorator(fn): css_class = \" class='&#123;0&#125;'\".format(kwds[\"css_class\"]) \\ if \"css_class\" in kwds else \"\" def wrapped(*args, **kwds): return \"&lt;\" + tag + css_class + \"&gt;\" + fn(*args,**kwds) + \"&lt;/\" + tag + \"&gt;\" return wrapped return real_decorator@makeHtmlTag(tag=\"b\", css_class=\"bold_css\")@makeHtmlTag(tag=\"i\", css_class=\"italic_css\")def hello(name): return \"hello world &#123;0&#125;\".format(name)if __name__ == '__main__': print(hello('femn')) # &lt;b class='bold_css'&gt;&lt;i class='italic_css'&gt;hello world femn&lt;/i&gt;&lt;/b&gt; makeHtmlTag有两个参数.所以,为了让 hello = makeHtmlTag(arg1, arg2)(hello) 成功,makeHtmlTag 必需返回一个decorator(这就是为什么我们在makeHtmlTag中加入了real_decorator()的原因),这样一来,我们就可以进入到 decorator 的逻辑中去了——decorator得返回一个wrapper,wrapper里回调hello. “ 函数的元数据函数的一些属性: name(函数名), doc(描述)和 module(模块位置)在使用装饰器的时候,函数会丢失这些元数据.12345678910111213141516def greeting(func): def function_wrapper(x): \"\"\"function_wrapper of greeting\"\"\" print(\"Hi, \" + func.__name__ + \" returns:\") return func(x) return function_wrapper@greetingdef f(x): \"\"\"just some silly function\"\"\" return x + 4if __name__ == '__main__': f(10) print(\"function name: \" + f.__name__) print(\"docstring: \" + f.__doc__) print(\"module name:\" + f.__module__) \") 运行结果如下1234Hi, f returns:function name: function_wrapperdocstring: function_wrapper of greetingmodule name:__main__ 在正常情况下,f.name应该为f,而通过装饰器之后,由于没有保存函数的元数据,所以变成了function_wrapper.每当定义一个装饰器时,应该总是记得为底层的包装函数添加functools库中的@wraps装饰器 12345678910111213141516171819from functools import wrapsdef greeting(func): @wraps(func) def function_wrapper(x): \"\"\"function_wrapper of greeting\"\"\" print(\"Hi, \" + func.__name__ + \" returns:\") return func(x) return function_wrapper@greetingdef f(x): \"\"\"just some silly function\"\"\" return x + 4if __name__ == '__main__': f(10) print(\"function name: \" + f.__name__) print(\"docstring: \" + f.__doc__) print(\"module name:\" + f.__module__) \") 运行结果如下1234Hi, f returns:function name: fdocstring: just some silly functionmodule name:__main__ 类装饰器12345678910111213141516171819202122232425class myDecorator(object): def __init__(self, fn): print( \"inside myDecorator.__init__()\") # 在我们给某个函数decorator时被调用,所以 # 需要有一个fn的参数,也就是被decorator的函数 self.fn = fn # 调用被decorator函数时被调用的 # 也可以在这个传入fn __call__(self.fn) def __call__(self): self.fn() print( \"inside myDecorator.__call__()\")@myDecoratordef aFunction(): print( \"inside aFunction()\")print( \"Finished decorating aFunction()\")if __name__ == '__main__': aFunction() # inside myDecorator.__init__() # Finished decorating aFunction() # inside aFunction() # inside myDecorator.__call__() 下面这个示例展示了通过URL的路由来调用相关注册的函数示例1234567891011121314151617181920212223242526272829303132class MyApp(): def __init__(self): self.func_map = &#123;&#125; # decorator类中没有__call__(),但是wrapper返回了原函数 def register(self, name): def func_wrapper(func): self.func_map[name] = func return func return func_wrapper def call_method(self, name=None): func = self.func_map.get(name, None) if func is None: raise Exception(\"No function registered against - \" + str(name)) return func()app = MyApp()@app.register('/')def main_page_func(): return \"This is the main page.\"@app.register('/next_page')def next_page_func(): return \"This is the next page.\"print(app.call_method('/'))print(app.call_method('/next_page'))# This is the main page.# This is the next page.","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"linux 常用命令","slug":"linux-common-commands","date":"2017-08-08T16:05:43.000Z","updated":"2017-09-23T11:10:15.696Z","comments":true,"path":"2017/08/08/linux-common-commands/","link":"","permalink":"https://www.femn.me/2017/08/08/linux-common-commands/","excerpt":"","text":"###不需要记住所有的命令,使用man info查看帮助文档:123456ls --help man ls # 帮助手册man -k passwd man -k nautilus # 可以用来查询包含该关键字命令的文档info ls # 帮助文档(书)# 所有程序的文档 都会以TXT,HTML,PDF等方式保存在/usr/share/doc目录下 用户与权限用户:是限制使用者或进程可以使用,不可以使用哪些资源.用户组:用来方便组织管理用户GIDUID:每个用户拥有一个,操作系统实际使用的是UID,而不是用户名.每个用户属于一个主组,属于一个或多个附属组(最多有31个),每个可登陆用户拥有一个指定的shell.特别注意:每个进程以一个用户身份运行,并受到该用户可访问的资源限制.所以进程的权限与该用户的权限一样.UID:用32位的二进制,用十进制查看,但系统为了兼容老式系统,用户ID限制在16位(65535个用户上限).root用户:ID为0,系统用户(1~499):没有一个登陆的shell,为某些服务创建的,比如说WEB服务,共享服务,ftp服务打印服务,这些用户仅仅是做为 这些进程去使用的,普通用户(500以上) Linux权限基于UGO模型进行控制,权限rwx对目录的影响:r:可列出目录内容,w:可在目录中创建删除文件,x:可访问目录内容(进入目录),目录必须拥有X权限,否则无法进入目录rwx(4+2+1) 默认权限:umask的值会从对象的全权限值中减掉普通用户的umask:0002,root用户的为0022目录的全权限 777-002文件的全权限 666-002umask: 显示 12位长的权限 UGO占用9biteumask 0022 : 去设置默认权限 但一个目录,只能属于一个组,当多个组需要共同使用这个目录时,UGO模型的权限就不行了.ACL(Access Control List)是一种高级权限机制,允许我们对一个文件或目录进行灵活的复杂的权限设置.允许针对不同用户,不同组对一个目标文件或目录进行权限设置,不受UGO模型限制.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051who # 显示哪些用户已经登陆系统whoami # 显示当前用户id # 查看当前用户信息passwd username # 修改用户密码,默认是修改当前用户# 用户组 /etc/groupgroupadd femnGroupgroupdel femnGroup# 用户 /etc/shadowuseradd -G femnGroup femn1 # 此femn1用户主属组是femn1,附属组是femnGroupuseradd -d /home/femn1 -u 1000 femn1 # femn1是用户名 -u用户IDsudo usermod -d /home/femn1 -s /bin/bash femn1 # -s默认bashuserdel femn1userdel -r femn1 # 同时删除用户的家目录# 改文件的UGO权限chmod -R 777 文件名 chmod u+rw,g+ochmod go+rwchmod a-x # a代指ugo# chown改所属用户 -R chown -R name:name 文件chown femn(用户名)learn.txt(文件名,如果是目录,则加上 -R参数)# chgrp改所属组 -R递归修改目录下的所有文件的所属组chgrp -R femnGroup learn.txt# umask的最前面的那位,是用来保留特殊权限的.chmod u+s 文件:# 特殊权限一般是给可执行文件去用的.1770chmod g+s 目录:# 在此目录下生成的文件或目录,都会继承此目录的用户组 2770chmod o+t 目录:# 只能是本人可以删除自己的文件,即使是本组中的人员也不能删除别人的文件.4770# ACL需要在挂载文件的时候打开ACL功能:mount -o acl /dev/sda5 /mnt# 针对一个用户对文件进行ACL设置:setfacl -m u:name:rwx linuxsetfacl -m g:name:rw linuxsetfacl -x u:name linux# 只要我们的文件系统打开了ACL功能,就可以查看一个文件或目录的ACL设置:getfacl linux 磁盘和挂载12345678910111213141516171819202122232425262728293031323334df -h # 设备文件名称,本系统中的磁盘的使用大小情况df -at # 文件系统, 磁盘的状态du -sh # 显示此目录总所占空间du -sh ~/* | sort -nr # 参数让结果按降序输出 管道命令将du命令的输出重定向到sort命令fdisk -l # 查看本机的所有磁盘,以及磁盘的分区情况fdisk /dev/sda # 查看,创建,删除某个磁盘 分区dumpe2fs -h /dev/sdb3 # 得到这个磁盘分区的所有信息# 格式化之前先不要挂载 mkfs -t ext4 /dev/sda4 mkfs.ext4 /dev/sda4# 将这个分区(或硬盘)格式化为ext4文件系统,格式化磁盘mke2fs -j -L \"partition-label-name\" -b 4096 -i -c 128 /dev/sda4 # 这样就可以传4.3G的大文件到U盘上了,只是这样格式,在Win不能用# 挂载mount /dev/sdc1 /home/name/usb mount -o remount,rw,auto /dev/sdc1 # 将/dev/sdc1重新挂载,并加入参数rw,autoumount /home/name/usb or /dev/sdc1 挂载点或设备文件名 # -l参数是强制lsof |grep /dev/sdc1# 当挂载不掉时,用下面的命令 ,会得到进程号# 特殊设备loop挂载(镜像文件不刻录就挂载使用)mount -o loop /home/name/ubuntu-16.04-desktop-amd64.iso \\ /hame/name/usb #使用 dd 命令写入下载好的 ISO 镜像到 U 盘中sudo dd if=xxxxx.iso of=/dev/sdc &amp;&amp; syncnautilus . # 默认是打开home目录 传统的磁盘管理问题:当分区大小不够用时无法扩展其大小,只能通过添加硬盘,创建新分区来扩充空间,但是新添加进来的硬盘是作为独立文件系统存在的,原有的文件系统并未得到扩充,上层应用很多时候只能访问一个文件系统,只能让现有磁盘下线,换上新的磁盘之后,再将原始数据导入. LVM逻辑卷管理(Logical volume Manager)PE(physical extend)物理扩展:逻辑卷空间管理的最基本单位,默认是4MPV(physica volume)物理卷:将底层磁盘格式化成物理卷,可以是物理硬盘上的分区,也可以是整块物理硬盘VG(volume group)卷组:空间池是给来装PE的,我们可以将一个或多个PV,加入到VG当中,当创建好了VG会有/dev/vgname的目录LV(logical volume)逻辑卷(操作系统最终使用的是逻辑卷格式化之后的数据)/dev/vgname/lvname的目录,每个的逻辑卷空间有可以来自不同的物理磁盘1234567891011121314151617181920212223242526272829303132333435363738391. 创建PV# 整块物理硬盘创建PVsudo pvcreate /dev/sd[b-c]# 物理硬盘上的分区创建PVfdisk /dev/sdb1 使用t将分区类型改成8e(LVM)partprobe # 刷新分区表sudo pvcreate /dev/sdb1sudo pvs # 查看创建好的PV2. PV创建好了就可以创建VG了sudo vgcreate vg0 /dev/sdb1sudo vgs # 查看创建好的VGsudo pvs # sdb1这个PV就属于vg0这个卷组池了3. 创建好卷组池就能从池中划分容量给逻辑卷(LV)了sudo lvcreate -n lv0 -L 10G vg0# 从卷组vg0中拿出10G,分配给lv0,其中-n后面是lv自定义名称,# -L后面跟需要从vg0中分配给lv0的大小以及从哪个VG分配4. 创建好lv后就可以格式化它,成为文件系统使用sudo mkfs.ext4 /dev/vg0/lv0# 创建好的lv所在目录是\"/dev/卷组名称/逻辑卷名称\",# 所以本例就是/dev/vg0/lv0,将它格式化成ext4文件系统5. 挂载和使用sudo mount /dev/vg0/lv0 /mnt6. 扩充VGsudo pvcreate /dev/sdd#新增加一块硬盘sdd(20G),将它创建成PV后划分到vg0下,# 此时vg0的容量将增加sdd硬盘的大小sudo vgextend vg0 /dev/sdd7. 扩充LVsudo vgs # 先确保VG池中有足够的VFree空间可供使用sudo lvextend -L +5G /dev/vg0/lv0sudo resize2fs /dev/vg0/lv0 # 更新 安装和下载12345678910111213141516171819202122232425262728293031vim /proc/meminfo 文件来观察LINux系统上虚拟内存的当前状态.sudo dpkg -i **.deb # 安装 查看-ldpkg -l |grep minitubesudo dpkg --purge minitubesudo apt install **curl https://wordpress.org/latest.tar.gz | tar -zxvf -curl url/install.sh | shwget -O redis.tar.gz \\ http://download.redis.io/releases/redis-3.2.0.tar.gztar -zxvf redis.tar.gz -C /usr/srcmake -C /usr/src/redis \\ &amp;&amp; make -C /usr/src/redis/src install # tar解压重命名mkdir ./jdk8 &amp;&amp; tar -xzvf jdk8.tar.gz -C ./jdk8 --strip-components 1wget https://ghost.org/zip/ghost-latest.zipunzip -uo ghost-latest.zip -d /var/www/ghost wget -qO- url/install.sh | shwget --no-check-certificate url/install.sh -O ./install.shcurl -LOk https://ghost.org/zip/ghost-latest.zipunzip ghost-latest.zip -d ghost-tempcurl http://localhost:8000/wrap?name=femn&amp; get()http://localhost:8000/wrap -d name=femn post()方法请求# Siege对我们的应用在10秒内执行大约10个并发请求siege http://localhost:8000/?q=pants -c10 -t10s 文件和目录操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 ll linux.md # ll 查看的信息 第二列是链接数量 ll |grep -v linux.md # 取反 history | grep -c rar # 计算匹配的数量 touch file1 # 创建文件 file file1 # 查看文件类型 cp -Rf source destination # -R 允许你通过命令递归地复制整个目录的内容. # -f 强制覆盖已经存在的目标文件,不提示 # -l 硬链接,它们是同一个文件,索引节点是相同的 \\cp -R dir1 dir2 # 同上 \\cp -R content/themes/casper ../ghost/content/themes rm -rf file1 tail -f -n 20 /etc/passwd # 软连接可以不用事先创建目录,硬连接必须先创建目录 sudo ln -s /home/femn/file /usr/share/nginx/html/file mkdir ~/file # mv排除文件 # 将本路径下所有的文件移动到本路径下vimrc_config目录下, # 但vimrc_config本身不动 mv !(vimrc_config) vimrc_config # 但此命令不包括mv 隐藏文件 rm命令类似 sort -t ':' -k 3 -n /etc/passwd # 按字段分隔数据,按分隔后的第几个进行排序 scp -r -P 22 root@ip:/server/app/main/handlers \\ ./main/handlers/ scp -P 22 ./1.txt python@ip:/usr/share/nginx/html/file/ # 只需要file目录有写权限,普通用户就可以用了 rsync -av -e \"ssh -p 22\" /home/python/app1.6/main/ \\ root@ip:/server/app1.6/main/ rsync -av -e \"ssh -p 22\" /home/python/oldapp_8000/ \\ root@ip:/server/app/main/# 截图 #你将可以使用鼠标选取一个矩形框.在你放下鼠标左键的那一刻, # 一个该矩形框的截屏会以import后面跟的文件名保存在当前目录下 import screenshot.jpg gnome-screenshot -a# 改变视频文件大小(分辨率)http://blog.topspeedsnail.com/archives/1699 ffmpeg -i source.mpg -s 960x540 -c:a copy destination.mp4# Linux系统将每个对象当作文件来处理,这包括输入和输入的过程.Linux用文件描述符来标识每个文件对象. 解压缩1234567891011# tartar -zcvf /home/name/conclusion.tar.gz ./conclusion tar -zxvf ./conclusion.tar.gz tar -cvf /tmp/etc.tar /etc &lt;==仅打包,不压缩# rar rar x file.rar # 解压# zipzip test.zip test unzip test.zip 环境变量12345678910111213printenv # 查看所有全局环境变量set # 会显示为某个特定进程设置的所有环境变量# 设置PATH环境变量vim ~/.profile export JAVA_HOME=/home/name/jdk1.8.0_92 export ANT_HOME=/home/name/apache-ant-1.9.7 PATH=$&#123;PATH&#125;:/home/name/jdk1.8.0_92/bin:/home/name/apache/bin# 设置局部变量(只能在定义的进程可见)femn='hello,my name is femn'# 设置全局变量export femn # 记住不要再用美元符($) # 删除环境变量unset femn ubuntu ip123456789101112131415161718192021222324252627282930313233# 禁用IPV6vim /etc/modprobe.d/blacklist.conf #在文档最后添加 blacklist ipv6# 设置一ipsudo ifconfig enp0s3 192.168.1.101 netmask 255.255.255.0sudo route add default gw 192.168.1.254# 设置二ipsudo vim /etc/network/interfaces auto enp0s3 iface enp0s3 inet static # dhcp address 192.168.1.101 gateway 192.168.1.254 netmask 255.255.255.0 #network 192.168.1.0 #broadcast 192.168.1.255 # 配置DNSsudo vim/etc/resolv.conf nameserver 127.0.1.1 # nameserver 8.8.8.8 search DHCP HOST # 手动重启网络服务sudo /etc/init.d/networking restart#实在没有生效 reboot# /etc/hosts:ip与域名的对应关系,DNS记录信息,# /etc/hostname:存放的是主机名.域名与主机名没有任何关系sudo hostname python-Vostro-3901 # 修改主机名 ubuntusudo hostnamectl set-hostname intl.aliyun.centos7 # 修改主机名 centos# 永久修改主机名vim /etc/hostname # ubuntu centos centos7 ip1234567vim /etc/sysconfig/network-scripts/ifcfg-网卡名字 BOOTPROTO=static #dhcp改为static ONBOOT=yes #开机启用本配置 IPADDR=192.168.1.107 #静态IP GATEWAY=192.168.1.254 # 默认网关 NETMASK=255.255.255.0 #子网掩码 service network restart 查看开启端口 123456# 查看本机的端口开启情况 sudo nmap -sTU localhost# 查看局域网的端口开启情况sudo nmap -PS 192.168.1.222# 查看远程服务器的端口开启情况nc -zv 45.76.0.178 22 22334","categories":[{"name":"linux","slug":"linux","permalink":"https://www.femn.me/categories/linux/"}],"tags":[]},{"title":"linux 基本","slug":"linux_basic","date":"2017-08-08T16:05:43.000Z","updated":"2017-09-23T11:10:15.692Z","comments":true,"path":"2017/08/08/linux_basic/","link":"","permalink":"https://www.femn.me/2017/08/08/linux_basic/","excerpt":"","text":"shell:是用户与kernal 通信的桥梁.它分为GUI:GNOME CLI:BASH,一种是图形界面的终端.是多任务,多进程的终端.firefox &amp;hostnameuname -r or -a参数 –all /bin:常用的可执行的二进制文件,终端命令,所有用户都有权限去执行/sbin:只有root才能运行.比较危险的命令,fdisk/boot:引导启动目录,操作系统内核(vmlinux-4.4.0)/dev:硬件设备:硬盘sda1分区,终端tty1,网卡,声卡.所有的设备都被抽象成一个文件./dev/sd:SATA,SCSI(服务器硬盘),SAS,USB,a:是第几块硬盘,1:分区情况.有一个磁盘文件/dev/sda 每个分区也有个文件:/dev/sda1/etc:配置文件,基本上是纯文本的 xx.conf/home:除了root的,其它用户的私有目录.此目录与用户名同名./libabry:Liunx运行需要的库文件,.sh,所有用户都有权限. /opt:安装一些大的软件/proc:不存在在硬盘上,系统运行时 的实时信息,保存在内存中,是一个虚拟的一个文件系统.meminfo cpuinfo,interrupts终端信息,iomem,uptime启动时间,vmstat虚存信息.acpi电源信息,每个进程,会对应一个数字的目录.echo 1 &gt; /proc/sys/net/ipv4/ip_forward 为LVS服务器开通路由功能(打开两个网卡之间的路由通道) 网卡充当路由器,也可以充当主机./sys:底层硬件信息./usr:应用软件 /usr/local/包.bin or /usr/share/包 .Sbin/var:经常变化的东西 email,log操作系统的所有log信息 /usr/share/doc:所有程序的文档 都会以TXT,HTML,PDF等方式保存在/usr/share/doc目录下 /etc/skel/:当创建新用户时,这里面的文件会复制到新用户的家目录中.bash_logout当用户关机时,执行的文件","categories":[{"name":"linux","slug":"linux","permalink":"https://www.femn.me/categories/linux/"}],"tags":[]},{"title":"python 对象","slug":"python-object","date":"2017-08-06T09:26:18.000Z","updated":"2017-09-23T11:10:15.704Z","comments":true,"path":"2017/08/06/python-object/","link":"","permalink":"https://www.femn.me/2017/08/06/python-object/","excerpt":"","text":"面向对象编程:Object Oriented Programming,简称OOP把一组数据结构和处理它们的方法组成对象(object),把相同行为的对象归纳为类(class),通过类的封装(encapsulation)隐藏内部细节通过继承(inheritance)实现类的特化(specialization)(重写)/泛化(generalization)通过多态(polymorphism)实现基于对象类型的动态分派(dynamic dispatch) 多态:不同对象的相同方法的不同行为 在JAVA在继承-重写才能体现多态,在python中,不知道对象到底是什么类型,但是又要对对象做点什么的时候,都会用到多态.很多的函数和运算符都是多态.唯一能毁掉多态的就是显式的检查类型123451+2 # 3'fe'+'mn' # femn'abc'.count('a') # 1[1,2,'a'].count('a') # 1 继承1234567891011121314151617181920212223242526272829303132class A(object): def __init__(self): print( \"A.__init__\" )class B(A): def __init__(self): super().__init__() print(\"B.__init__\" )class C(B): def __init__(self): super().__init__() print(\"C.__init__\" )class D(A): def __init__(self): super().__init__() print(\"D.__init__\" )class E(D): def __init__(self): super().__init__() print(\"E.__init__\" )class F(C,E):# C,E 相当于是子 父关系 def __init__(self): super().__init__() print(\"F.__init__\" )if __name__ == '__main__': f = F() # A.__init__ # D.__init__ # E.__init__ # B.__init__ # C.__init__ # F.__init__ 对于你定义的每一个类,Python会计算出一个所谓的方法解析顺序(MRO)列表. 这个MRO列表就是一个简单的所有基类的线性顺序表.例如 12345&gt;&gt;&gt; F.__mro__(class'__main__.F'&gt;,&lt;class'__main__.C'&gt;,&lt;class'__main__.B'&gt;,&lt;class'__main__.E'&gt;,&lt;class'__main__.D'&gt;,&lt;class'__main__.A'&gt;,&lt;class'object'&gt;) 为了实现继承,Python会在MRO列表上从左到右开始查找基类,直到找到第一个匹配这个属性的类为止而这个MRO列表的构造是通过一个C3线性化算法来实现的,它实际上就是合并所有父类的MRO列表并遵循如下三条准则: 子类会先于父类被检查 多个父类会根据它们在列表中的顺序被检查 如果对下一个类存在两个合法的选择,选择第一个父类 C3算法特点 本地优先级:指声明时父类的顺序,比如F(C,E),如果访问F类对象属性时,应该根据声明顺序,优先查找C类,然后再查找E类. 单调性:如果在F的解析顺序中,C排在E的前面,那么在F的所有子类里,也必须满足这个顺序 类(Class):用来描述具有相同的属性和方法的对象的集合.它定义了该集合中每个对象所共有的属性和方法.类创建后,类命名空间中所有的命名都是有效属性名 对象:类的实例化通过类定义的数据结构实例.对象包括两个数据成员(类变量和实例变量)和方法.对象基本上可以看作数据(特征)以及由一系列可以存取,操作这些数据的方法所组成的集合.使用对象替代全局变量和函数的原因可以有很多.多态(鸭子类型),封装,继承封装和继承是被用作现实世界中对象的模型 123456789101112class Person(dict): def __init__(self,name): super(Person,self).__init__() self.name = name def get_name(self): return self.nameif __name__ == '__main__': p = Person('femn') print(p) # &#123;&#125; self本身为空 &#123;&#125; ,但其属性不为空 print(p.get_name()) # femn# 如果知道p是Person类的实例的话,# 就可以把p.get_name()看作是Person.get_name(p)的简写. 属性:域,字段,成员变量,全局变量,数据成员(数据),私有成员,成员对象属性:这个词来称呼任何点后面跟的名称 — 比如,在表达式z.real中,real就是对象z的属性.更直接的说,对模块中名称的引用就是属性引用:在表达式 modname.funcname 中,modname是模块对象而funcname是它的一个属性.在这种情况下模块的属性和它里面所定义的全局名称之间就刚好有一个直接的映射关系:他们共享同一个命名空间 类变量:在整个实例化的对象中是公用的.定义在类中且在函数体之外,通常不作为实例变量使用.实例变量:定义在方法中的变量,只作用于当前实例的类property()方法实例123456789101112131415161718class Rectangle: def __init__(self): self.width = 0 self.height = 0 def setSize(self, size): \"\"\"访问器方法,把所有的属性都放到访问器方法中\"\"\" self.width, self.height = size def getSize(self): return self.width, self.height size = property(getSize, setSize) # 类属性,其中的访问器方法被用作参数(先取值,然后是赋值)r = Rectangle()r.width = 10r.height = 5r.size # (10, 5)r.size = 150, 100r.width # 150 @property 装饰器实例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Person(object): def __init__(self,name,age): \"\"\"Constructor\"\"\" self.name = '' self.age = 0 # 修改属性的值 一 def getName(self): print('property()') return self._name def setName(self,name): \"\"\" 要使用_name 将实例属性name标记成protected变量 不然就将name类属性,改个名字, 只要满足类属性和实例属性不同名,否则会进入无限的递归\"\"\" self._name = name # protected实例变量:_name name = property(getName,setName) # publie类变量:name __aim = 'become stronger' # private 类变量:__aim # @property装饰器:# 将方法变成了属性,我们可以使用正常的点符号访问它,但无法对属性值直接修改 @property def info(self): \"\"\" Return my info \"\"\" return \"my name is %s, age is %s\" % (self.name, self.age) # 修改属性的值 二#一个property其实是 getter、setter 和 deleter 方法的集合,而不是单个方法# 访问它的时候会自动触发 getter 、setter 和 deleter 方法 @property def age(self): print('@property装饰器') return self._age @age.setter def age(self,age): self._age = age @age.deleter def age(self): raise AttributeError(\"Can't delete attribute\")if __name__ == '__main__': p = Person('leipengkai',25) # 方法一 p.set_name = 'femn1' p.name = 'femn1.1' print(p.name) # 方法二 p.age = 18 print(p.age) # 输出如下# property()# femn1.1# @property生成器# 18 方法(绑定方法,动作) 绑定方法:将它们的第一参数绑定到所属的实例上,因此您无须显示提供该参数.当然也可以将特征绑定到一个普通的函数上,这样就不会有特殊的self参数了 函数:self参数是对象自身的引用.它正是方法和函数的区别.在java中,方法和函数是一样的.在python中,方法(self)必须在类中,而函数可以在任意位置定义 静态方法:无法访问类属性、实例属性,没有self参数.相当于一个相对独立的方法,跟类其实没什么关系,换个角度来讲,其实就是放在一个类的作用域里的函数而已.被装入staticmethod类型的对象中. 类成员方法:可以访问类属性,无法访问实例属性.需要名为cls的类似于self的参数,可以用类的具体对象调用.cls自动被绑定到类中被装入classmethod类型的对象中 12345class A(): a =1 #类属性 def __init__(self,b,c) self.b=b self.c=c#实例属性 参数123456789101112def print_params(x, y, z=3, *pospar, **keypar): #**代表命名参数 print(x,y,z) print(pospar) print(keypar)print_params(1,2,3,5,6,7,foo=1, bar=2)1 2 3(5, 6, 7)&#123;'foo': 1, 'bar': 2&#125;print_params(1,2,foo=1, bar=2)1 2 3()&#123;'foo': 1, 'bar': 2&#125; Python 的作用域和命名空间命名空间(namespace)是从名称(标识符)到对象的映射,可以将其理解为字典,各个命名空间是独立的,没有任何关系的,所以一个命名空间中不能有重名,但不同的命名空间是可以重名而没有任何影响 如果狭义点的话,可以将命名空间简单的理解为是变量(包括类和内置类型等)的引用. 四个namespace:一个函数的所有local,一个类对象的所有属性(数据成员,成员函数),一个模块的global(这个模块定义的函数,类,变量)和built-in(包括内置函数,内置常量,内置类型) 命名空间都是有创建时间和生存期的: 对于Python built-in names组成的命名空间,它在Python解释器启动的时候被创建,在解释器退出的时候才被删除.内置名称实际上也存在于一个模块中; 这个模块叫 builtins. 对于一个Python模块的global namespace,它在这个module被import的时候创建,在解释器退出的时候退出.被最高级别的解释器调用的语句,不论是从脚本还是从交互读取的,都被认为是一个名叫main的模块的一部分,所以它们有自己的全局命名空间. 对于一个函数的local namespace,它在函数每次被调用的时候创建,函数返回的时候被删除.当然,递归调用会有它们自己的局部命名空间 总结来说:一个模块的引入,类的定义,函数的调用都会引入命名空间 在执行过程中遇到了某个标识符(名称)时,Python首先尝试在local命名空间中查找它,如果没有找到,再在global命名空间中查找,如果还是没有找到,接着在built-in命名空间中查找.如果都不存在,则被认为是一个错误,会抛出一个”NameError”异常 变量的作用域(scope):是Python程序的文本区域,在该区域某个命名空间中的名字可以被直接引用.你所申明的变量(包括类和内置变量等)可以在哪些地方使用. 一个Python程序的几个作用域: 最里面的局部作用域,基本类型的作用域:(从变量定义处开始,以到结束此方法时截止) 外层函数的局部作用域:对象的作用域:(对象出了方法外后,只是引用消失了,但是对象本身还在堆中.资源回收站会定期回收垃圾对象) 模块的全局作用域 包含Python内置对象的最外层作用域 赋值(assignment):赋值操作不会拷贝,只是把标识符和对象做一个绑定,也就是说赋值操作就是名字和对象的绑定或重绑定,也可以说赋值是把原来对象的引用传递给另一个引用！ global声明的变量会引用到当前模块的全局命名空间的变量nonlocal:用于声明非全局的外层变量.这个声明会从声明处从里到外的namespace去搜寻这个变量,直到模块的全局域(不包括全局域)找到了则引用这个命名空间的这个名字和对象,若作赋值操作,则直接改变外层域中的这个名字的绑定.如果在外层域中没有找到,则会报错 这是一个例子用于说明如何引用不同的作用域和命名空间, global 和 nonlocal 如何影响变量绑定:123456789101112131415161718192021222324def scope_test(): def do_local(): spam = \"local spam\" def do_nonlocal(): nonlocal spam spam = \"nonlocal spam\" def do_global(): global spam spam = \"global spam\" spam = \"test spam\" do_local() print(\"After local assignment:\", spam) # test spam do_nonlocal() print(\"After nonlocal assignment:\", spam) # nonlocal spam do_global() print(\"After global assignment:\", spam) # nonlocal spamif __name__ == '__main__': scope_test() print(\"In global scope:\", spam) # global spam 注意局部的赋值(默认)并没有改变scope_test绑定的spam.而nonlocal则改变了scope_test中的spam,而global则改变了模块级别的绑定. 你可以看到在global赋值之前并没有绑定spam的值 12345678910111213141516def test(): def do_nonlocal(): nonlocal spam print(\"asssignment:\", spam) def do_nonlocal2(): nonlocal spam spam = \"nonlocal2 spam\" #修改了test()中spam的绑定 do_nonlocal2() spam = \"test spam\" do_nonlocal() print(\"after nonlocal2 asssignment:\", spam) if __name__ == '__main__': test() # asssignment: test spam # after nonlocal2 asssignment: nonlocal2 spam # do_nonlocal2()中的spam引用的是其外面的二层,也就是test()函数域中的spam 总结:Python会按照从内层到外层的顺序逐个寻找作用域中的变量(局部到全局),在函数内引用全局变量不需要global,函数内修改全局变量要加global,nonlocal也是一样","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[{"name":"面向对象","slug":"面向对象","permalink":"https://www.femn.me/tags/面向对象/"}]},{"title":"python_threads","slug":"python-threads","date":"2017-08-05T14:46:15.000Z","updated":"2017-09-23T11:10:15.708Z","comments":true,"path":"2017/08/05/python-threads/","link":"","permalink":"https://www.femn.me/2017/08/05/python-threads/","excerpt":"","text":"线程例子112345678910111213141516171819202122232425262728293031 import threading from time import ctime,sleep def music(func): for i in range(2): print( \"I was listening to %s. %s\" %(func,ctime())) sleep(1) def move(func): for i in range(2): print( \"I was at the %s! %s\" %(func,ctime())) sleep(5) # 主线程中 加两个子线程 threads = [] # 装载多个线程的数组 看着像是同时进行的 t1 = threading.Thread(target=music,args=(u'爱情买卖',)) threads.append(t1) t2 = threading.Thread(target=move,args=(u'阿凡达',)) threads.append(t2) if __name__ == '__main__': for t in threads:# 子线程 t.setDaemon(True) \"\"\" 线程声明为守护线程,必须在start() 方法调用之前设置 如果不设置为守护线程程序会被无限挂起. 子线程启动后,父线程也继续执行下去,当父线程执行完最后一条语句print \"all over %s\" %ctime()后没有等待子线程,直接就退出了,同时子线程也一同结束\"\"\" t.start()#开始线程活动 t.join()\"\"\" 在子线程完成运行之前,这个子线程的父线程将一直被阻塞.join()实际上意味着等到队列为空,再执行别的操作join()方法的位置是在for循环外的,也就是说必须等待for循环里的两个进程都结束后,才去执行主进程 \"\"\" print( \"all over %s\" %ctime()) #主线程 线程例子212345678910111213141516171819202122232425262728293031323334import _threadimport threadingimport timeexitFlag = 0class myThread (threading.Thread): #继承父类threading.Thread def __init__(self, name, delay): threading.Thread.__init__(self) self.name = name self.delay = delay def run(self): #把要执行的代码写到run函数里面 线程在创建后会直接运行run函数 print( \"Starting \" + self.name) print_time(threadName=self.name,delay=self.delay,counter=5) print( \"Exiting \" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: _thread.exit() time.sleep(delay) print( \"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1thread1 = myThread(name=\"Thread-1\", delay=1)thread2 = myThread(name=\"Thread-2\", delay=2)# 开启线程thread1.start()thread2.start()print( \"Exiting Main Thread\") 同步线程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 import threading from datetime import datetime import time import _thread exitFlag = 0 class myThread (threading.Thread): def __init__(self, name, delay): threading.Thread.__init__(self) # self.threadID = threadID self.name = name self.delay = delay def run(self): print( \"Starting \" + self.name)# 如果多个线程共同对某个数据修改,则可能出现不可预料的结果,# 为了保证数据的正确性,需要对多个线程进行同步.# 线程同步(为了确保数据的完整没有被其它的线程修改,必须要得锁和解锁# 所以也导致了要一个线程全部结束之后,才能执行下一个的线程)# 这会导致同步阻塞,也就是只有一个线程工作完之后,才能进行下一个线程 # 获得锁,成功获得锁定后返回True # 可选的timeout参数不填时将一直阻塞直到获得锁定 # 否则超时后将返回False threadLock.acquire() print_time(threadName=self.name, delay=self.delay, counter=5) # 释放锁 threadLock.release() print( \"Exiting \" + self.name) def print_time(threadName, delay, counter): while counter: if exitFlag: _thread.exit() time.sleep(delay) print( \"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1 # 线程同步 threadLock = threading.Lock() threads = [] thread1 = myThread(name=\"Thread-1\", delay=1) thread2 = myThread(name=\"Thread-2\", delay=2) # 开启线程 n = datetime.now() thread1.start() thread1.join()#因为没有queue可继续执行下面的线程 thread2.start() # # 添加线程到线程列表 threads.append(thread1) threads.append(thread2) # 等待所有线程完成 for t in threads: t.join() print(\"Exiting Main Thread\") print(datetime.now()-n) quere1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 import queue, time, threading, datetime class Job: def __init__(self, name): self.name = name def do(self): time.sleep(2) print(\"\\t[Info] Job(&#123;0&#125;) is done!\".format(self.name)) que = queue.Queue()#FIFO即First in First Out,先进先出 a[len(a):1]=[queue] 加在后面的# lifoqueue = queue.LifoQueue()#LIFO即Last in First Out# 后进先出 a[0:0]=[queue] 加在最前面的 入栈 出栈 for i in range(20): # 保存要去工作的信息 在queue中 que.put(Job(str(i + 1)))#调用队列对象的put()方法在队尾插入一个项目# put()有两个参数,第一个item为必需的,为插入项目的值;第二个block为可选参数,默认为1# 如果队列当前满且block为1,put()方法就使调用线程暂停,直到空出一个数据单元.# 如果block为0,put方法将引发Queue.Full异常 print(\"\\t[Info] Queue size=&#123;0&#125;...\".format(que.qsize()))#返回队列的大小 # # Start activity to digest queue. st = datetime.datetime.now() #需要40秒 while que.qsize() &gt; 0: job = que.get() job.do() td = datetime.datetime.now() - st print(\"\\t[Info] Spending time=&#123;0&#125;!\".format(td))#q.qsize() 返回队列的大小# q.empty() 如果队列为空,返回True,反之False# q.full() 如果队列满了,返回True,反之False# q.full 与 maxsize 大小对应# q.get([block[, timeout]]) 获取队列,timeout等待时间# q.get_nowait() 相当q.get(False)# 非阻塞 q.put(item) 写入队列,timeout等待时间# q.put_nowait(item) 相当q.put(item, False)# q.task_done() 在完成一项工作之后,q.task_done()函数向任务已经完成的队列发送一个信号# q.join() 实际上意味着等到队列为空,再执行别的操作 线程quere123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import queue, time, threading, datetimeclass Job: def __init__(self, name): self.name = name def do(self): time.sleep(2) print(\"\\t[Info] Job(&#123;0&#125;) is done!\".format(self.name))que = queue.Queue()for i in range(20): que.put(Job(str(i + 1)))print(\"\\t[Info] Queue size=&#123;0&#125;...\".format(que.qsize()))def doJob(*args): queue = args[0] while queue.qsize() &gt; 0: job = queue.get()#调用队列对象的get()方法从队头删除并返回一个项目.可选参数为block,默认为True.# 如果队列为空且block为True,get()就使调用线程暂停,直至有项目可用.# 如果队列为空且block为False,队列将引发Queue.Empty异常 job.do() # Open three threadsthd1 = threading.Thread(target=doJob, name='Thd1', args=(que,))thd2 = threading.Thread(target=doJob, name='Thd2', args=(que,))thd3 = threading.Thread(target=doJob, name='Thd3', args=(que,))# thd4 = threading.Thread(target=doJob, name='Thd3', args=(que,))# thd5 = threading.Thread(target=doJob, name='Thd3', args=(que,))# # Start activity to digest queue.st = datetime.datetime.now()thd1.start()thd2.start()thd3.start()# thd1.join()#在子线程完成运行之前,这个子线程的父线程将一直被阻塞.# join() 实际上意味着等到队列为空,再执行别的操作#這會讓呼叫 join() 方法的線程被 blocked, 一直到被呼叫 join() 的線程結束為止#不会再进行下面的线程了# thd4.start()# thd5.start()#首先當 Thread 類別被實例化, 你可以呼叫物件上面的方法 start() 來啟動該線程,# 一旦線程啟動, 它的狀態會變成 \"alive\" ;# Wait for all threads to terminate.while thd1.is_alive() or thd2.is_alive() or thd3.is_alive(): time.sleep(1)# 當執行完畢 run() 後狀態便不在是 \"alive\".td = datetime.datetime.now() - stprint(\"\\t[Info] Spending time=&#123;0&#125;!\".format(td)) 推荐使用1234567891011121314151617181920212223242526272829303132333435import queueimport threadingfrom datetime import datetimeSHARE_Q = queue.Queue() # 构造一个不限制大小的的队列_WORKER_THREAD_NUM = 4 # 设置线程的个数def worker(): global SHARE_Q while not SHARE_Q.empty(): one_dict = SHARE_Q.get() # 获得任务 # to worker ... SHARE_Q.task_done()def main(): a= datetime.now() threads = [] global SHARE_Q library_list =['9787550215184','9787550206267'] for i in library_list: SHARE_Q.put(i) for i in range(_WORKER_THREAD_NUM): thr = threading.Thread(target=worker) # 必须要有 target去指定函数 thr.start() threads.append(thr) for thread in threads: thread.join() SHARE_Q.join() print(datetime.now() -a)#0:00:00.376745 print('success')if __name__ == '__main__': main()","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"进程与线程","slug":"threads","date":"2017-08-05T11:16:14.000Z","updated":"2017-09-23T11:10:15.712Z","comments":true,"path":"2017/08/05/threads/","link":"","permalink":"https://www.femn.me/2017/08/05/threads/","excerpt":"","text":"性能:在其他同等条件下,高性能的程序应该可以等同于CPU的利用率,CPU的利用率越高(一直在工作,没有闲下来的时候),程序的性能越高. 体验:这里的体验不只是界面多么漂亮,功能多么顺手,这里的体验指程序的响应速度,响应速度越快,用户体验越好. 由于我们要解决的问题是CPU高速执行能力和IO设备的龟速严重不匹配,多线程和多进程只是解决这一问题的一种方法. 另一种解决IO问题的方法是异步IO.当代码需要执行一个耗时的IO操作时,它只发出IO指令,并不等待IO结果,然后就去执行其他代码了.一段时间后,当IO返回结果时,再通知CPU进行处理,在处理 IO 的时候,阻塞和非阻塞都是同步 IO. 只有使用了特殊的 API 才是异步 IO. 首先对一些名词的理解 被调用方:同步与异步关乎做事情的方式.同步:做完一件事再去做另一件. 异步:同时做多件事情,某个事情有结果了再去处理(又一个新事情)我的理解: 被调用方有没有能力同时处理问题的能力以及回调的功能同步和异步关注的是消息通信机制(synchronous communication/ asynchronous communication):所谓同步,就是在发出一个调用时,在没有得到结果之前,该调用就不返回,但是一旦调用返回,就得到返回值了换句话说,就是由调用者主动等待这个调用的结果 而异步则是相反,调用在发出之后,这个调用就直接返回了,所以没有返回结果.换句话说,当一个异步过程调用发出后,调用者不会立刻得到结果.而是在调用发出后,被调用者通过状态、通知来通知调用者,或通过回调函数处理这个调用 典型的异步编程模型比如Node.js1234567举个通俗的例子: 你打电话问书店老板有没有《分布式系统》这本书如果是同步通信机制,书店老板会说,你稍等,\"我查一下\",然后开始查啊查,等查好了(可能是5秒,也可能是一天)告诉你结果(返回结果).而异步通信机制,书店老板直接告诉你我查一下啊,查好了打电话给你,然后直接挂电话了(不返回结果).然后查好了,他会主动打电话给你.在这里老板通过\"回电\"这种方式来回调. 调用方:阻塞与非阻塞关乎如何对待事情产生的结果.关注的是程序在等待调用结果(消息,返回值)时的状态.阻塞调用是指调用结果返回之前,当前线程会被挂起.调用线程只有在得到结果之后才会返回. 非阻塞调用指在不能立刻得到结果之前,该调用不会阻塞当前线程 阻塞:不等到想要的结果我就不走了. 非阻塞:有结果我就带走,没结果我就空手而回,总之一句话:爷等不起 1234你打电话问书店老板有没有《分布式系统》这本书,你如果是阻塞式调用,你会一直把自己\"挂起\"直到得到这本书有没有的结果,如果是非阻塞式调用你不管老板有没有告诉你,你自己先一边去玩了当然你也要偶尔过几分钟check一下老板有没有返回结果 1234567891011老张爱喝茶,废话不说,煮开水. 出场人物:老张,水壶两把(普通水壶,简称水壶;会响的水壶,简称响水壶).1 老张把水壶放到火上,立等水开.(同步阻塞) 老张觉得自己有点傻 2 老张把水壶放到火上,去客厅看电视,时不时去厨房看看水开没有.(同步非阻塞)老张还是觉得自己有点傻,于是买了把会响笛的那种水壶.水开之后,能大声发出嘀~~~~的噪音.3 老张把响水壶放到火上,立等水开.(异步阻塞) 老张觉得这样傻等意义不大4 老张把响水壶放到火上,去客厅看电视,水壶响之前不再去看它了,响了再去拿壶.(异步非阻塞) 并发与并行并发指在同一时刻,只能有一条指令执行,但多个进程指令被快速轮换执行(纳秒级),使得在宏观上具有多个进程同时执行的效果.只能运行一个进程,CPU不断地在这些进程之间轮换执行, 并行指在同一时刻,有多条指令在多个处理器上同时执行;多个CPU处理器 进程(拥有独立的内存单元,chrome使用多进程)与线程(也被称作轻量级进程)进程:程序的一次执行. 线程:CPU的基本调度单位 ,而在Linux系统里面,在最底层,线程和进程确实是不区分的. 进程是系统进行资源分配和调度的一个独立单位,线程是进程的执行单元,在进程中是独立的、并发的执行流线程的调度和管理,由进程本身负责完成. 当一个程序运行时,内部可能包含了多个顺序执行流,每个顺序执行流就是一个线程.当一个程序进入内存,运行后,即变成一个进程. 进程的三个特性 独立性:进程是系统中独立存在的实体,它可以拥有自己独立的资源,每一个进程都拥有自己私有的地址空间.在没有经过进程本身允许的情况下,一个用户进程不可以直接就访问其他进程的地址空间. 动态性:进程与程序的区别在于,程序只是一个静态的指令集合,而进程是一个正在系统中活动的指令集合.在进程中加入了时间的概念.进程具有自己的生命周期和各种不同的状态,这些概念在程序中都是不具备的. 并发性:多个进程可以在单个处理器上并发执行,多个进程之间不会互相影响 车间: 一个进程与线程的一个简单解释 程序(车间,有独立的内存空间)之间进行内存数据交换(通信)比较麻烦:每个程序的内存空间都是被保护的,不能被别的程序直接访问,所以要通过某种介质,管道或第三方工具,去通信. nosql(第三方):将内存的数据缓存进来,供其它的程序调用,所有的程序都可以往里存数据,所有的程序都可以取数据.相当于实现了一个共享的内存空间 餐桌: 一群人(多个线程)在一个桌子(进程)上吃饭,他们会涉及到一些问题,比如多个人可能会夹一个菜(竞争)A和B同时看到盘子里面有一块肉,同时伸出筷子去夹,A先夹走,B迟了一点伸到盘子的时候已经没了,只能缩回来(临界资源,互斥)有一个点心需要用馍夹肉一起吃.A夹了肉,B夹了馍,A需要B的馍,B需要A的肉,他们僵持不下谁都不让步(死锁).多线程之间的资源共享是非常方便的,因为他们共用进程的资源空间(在一个桌子上),但是需要注意一系列的问题,竞争,死锁,同步等 如果在旁边再开一个桌子(进程). 那么桌子之间讲话,递东西又不方便(进程间通信),而开一个桌子的开销比在一个桌子上多加一个人的开销要大.另外一个桌子上的人数不可能无限制增加,桌子的容量有限也坐不下这么多人(进程的线程句柄是有限制的).一个桌子坏了不会影响到另一个桌子上面人的就餐情况(进程间相互独立,一个进程崩溃不会影响另一个),而一个桌子上的某人喝挂了需要送医院,估计这一桌人都要散了(线程挂掉会导致整个进程也挂掉).所以多线程与多进程是各有优缺点,不能一概而论 对于 Windows系统来说,【开桌子】的开销很大,因此Windows鼓励大家在一个桌子上吃菜.因此Windows多线程学习重点是要大量面对资源争抢与同步方面的问题. 对于Linux系统来说,【开桌子】的开销很小,因此Linux鼓励大家尽量每个人都开自己的桌子吃菜.这带来新的问题是:坐在两张不同的桌子上,说话不方便.因此,Linux下的学习重点大家要学习进程间通讯的方法. 单线程(单任务,按顺序去完成)和多线程 多线程则扩展了多进程的概念,使得同一个进程可以同时并发(轮换执行)处理多个任务.线程(Thread)也被称作轻量级进程(LightweightProcess),线程是进程的执行单元. 就像进程在操作系统中的地位一样,线程在进程中是独立的、并发的执行流.进程操作系统–线程进程,当线程被初始化后,主线程就被创建了对于应用程序而言, 通常至少有一个主线程,可以在该进程内创建多条顺序执行流,这些顺序执行流就是线程,每条线程也是相互独立的; 线程是进程的的组成部分,一个进程可以拥有多个线程,一个线程必须有一个父进程,线程可以拥有自己的堆栈、自己的程序计数器和自己的局部变量,但是不再拥有系统资源,它与父进程的其他线程共享该进程所拥有的全部资源. 因为多个线程共享父进程里的全部资源,因此编程更加方便;但必须更加小心,必须确保线程不会妨碍同一进程里的其他线程.线程的调度和管理由进程本身负责完成. 进程在执行过程中拥有独立的内存单元,而多个线程共享内存,从而极大地提高了程序的运行效率 车间: 当要完成一项工作或多项工作时(但还是在一个主线程中),单线程就好比一个工人,而多线程就是招了多个工人一起干活,效率当然快了！但管理就费劲了(死锁,竟争),允许单个任务分成不同的部分运行 餐桌: 单线程就是整个餐厅只有一个单人桌,这个人吃完了,下一个人轮上.但大餐馆用的可能是八仙桌,同时能容纳八个人吃饭,这就是多线程:从一次一个变成了一次多个或者多次多个 多线程的作用1.把程序细分成几个功能相对独立的模块,防止其中一个功能模块阻塞导致整个程序假死(GUI程序是典型).一个线程一件事,多线程做多件事 2.提高运行效率,比如多个核同时跑,或者单核里面,某个线程进行IO操作时,另一个线程可以同时执行这样一条主线程,处理整个程序任务的主方向的链,而其链上又有许许多多的分支,就像树枝那样, 这样,既有了主线程去处理那些主要任务,又有了那些细小线程去处理耗时费力任务,从而让界面看起来更加流畅 多线程做同一件事多线程使得程序内部可以分出多个线程来做多件事情,而不会造成程序界面卡死.比如迅雷等多线程下载工具就是典型的多线程.一个下载任务进来,迅雷把文件平分成10份,然后开10个线程分别下载.这时主界面是一个单独的线程,并不会因为下载文件而卡死.而且主线程可以控制下属线程,比如某个线程下载缓慢甚至停止,主线程可以把它强行关掉并重启另外一个线程. 多线程因为在同一个进程里,所以可以共享内存和其他资源,比如迅雷里10个线程一齐下载一个文件,这个文件是由进程打开的,然后10个线程都可以往里写入东西.如果是10个进程就不行了,操作系统不允许一个文件由两个进程同时写入 python中使用 GIL(global interpreter lock)保证了线程安全(保证数据被安全读取),即同时只能有一个线程在CPU上运行,这个线程也不能扩散到其它CPU上,GIL是以CPU为单位去控制这个锁,对于python的多线程,多核也没有实际的提速作用, 所以多线程在Python中只能跑在一个CPU上.如果想利用多CPU的话,就使用多进程(需要给独立的内存空间,所以比较占内存资源).当每个CPU核心运行一个进程的时候,由于每个进程的资源都独立,所以CPU核心之间切换的时候无需考虑上下文. 当每个CPU核心运行一个线程的时候,由于每个线程需要共享资源,所以这些资源必须从CPU的一个核心被复制到另外一个核心,才能继续运算,这占用了额外的开销.换句话说,在CPU为多核的情况下,多线程在性能上不如多进程. (1)以多进程形式,允许多个任务同时运行;(2)以多线程形式,允许单个任务分成不同的部分运行;(3)提供协调机制,一方面防止进程之间和线程之间产生冲突,另一方面允许进程之间和线程之间共享资源.进程与线程的区别每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口.但是线程不能够独立执行,必须依存在应用程序中,由应用程序提供多个线程执行控制,但操作系统并没有将多个线程看做多个独立的应用,来实现进程的调度和管理以及资源分配 进程和线程的主要差别在于它们是不同的操作系统资源管理方式.进程有独立的地址空间,一个进程崩溃后,在保护模式下不会对其它进程产生影响,而线程只是一个进程中的不同执行路径.线程有自己的堆栈和局部变量,但线程之间没有单独的地址空间,一个线程死掉就等于整个进程死掉,所以多进程的程序要比多线程的程序健壮 协程(又称微线程(coroutine),相当于单线程的能力)与子程序(函数调用是通过栈实现的,一个线程就是执行一个子程序,子程序就是协程的一种特例) 子程序,或者称为函数,在所有语言中都是层级调用,比如A调用B,B在执行过程中又调用了C,C执行完毕返回,B执行完毕返回,最后是A执行完毕. 协程(协作完成任务),tornado好像就是用协程来实现异步的协程,协程看上去也是子程序,但执行过程中,在子程序内部可中断,然后转而执行别的子程序,在适当的时候再返回来接着执行. 协程的特点在于是一个线程执行,所有协程有如下优势 最大的优势就是协程极高的执行效率.因为子程序切换不是线程切换,而是由程序自身控制,因此,没有线程切换的开销,和多线程比,线程数量越多,协程的性能优势就越明显. 第二大优势就是不需要多线程的锁机制,因为只有一个线程,也不存在同时写变量冲突,在协程中控制共享资源不加锁,只需要判断状态就好了,所以执行效率比多线程高很多.1234567891011121314151617181920212223242526272829303132# 传统的生产者-消费者模型是一个线程写消息,一个线程取消息,# 通过锁机制控制队列和等待,但一不小心就可能死锁.# 如果改用协程,生产者生产消息后,直接通过yield跳转到消费者开始执行# 待消费者执行完毕后,切换回生产者继续生产,效率极高import timedef consumer(): r = '' while True: n = yield r # 3.consumer通过yield拿到消息,处理完又通过yield把结果传回 if not n: return print('[CONSUMER] Consuming %s...' % n) print(n) time.sleep(1) r = '200 OK'def produce(c): next(c) # 不是值 1. 启用生成器 n = 0 while n &lt; 5: n = n + 1 print('[PRODUCER] Producing %s...' % n) r = c.send(n) # 这里才是迭代器中的值 2. 一旦生产了东西,通过c.send(n)切换到consumer执行 print('[PRODUCER] Consumer return: %s' % r) # 4. produce拿到consumer处理的结果,继续生产下一条消息 c.close() # 5. produce决定不生产了,通过c.close()关闭consumer,整个过程结束if __name__ == '__main__': c = consumer() produce(c) 整个流程无锁,由一个线程执行,produce和consumer协作完成任务,所以称为”协程”,而非线程的抢占式多任务. 子程序就是协程的一种特例.线程确实比协程性能更好.因为线程能利用多核达到真正的并行计算,如果任务设计的好,线程能几乎成倍的提高你的计算能力,说线程性能不好的很多 是因为没有设计好导致大量的锁,切换,等待,这些很多都是应用层的问题.而协程因为是非抢占式,所以需要用户自己释放使用权来切换到其它协程,因此 同一时间其实只有一个协程拥有运行权,相当于单线程的能力 参考于此","categories":[{"name":"linux","slug":"linux","permalink":"https://www.femn.me/categories/linux/"}],"tags":[]},{"title":"迭代器与生成器","slug":"iterable-iterator-generator","date":"2017-08-05T09:46:55.000Z","updated":"2017-09-23T11:10:15.692Z","comments":true,"path":"2017/08/05/iterable-iterator-generator/","link":"","permalink":"https://www.femn.me/2017/08/05/iterable-iterator-generator/","excerpt":"","text":"为什么使用迭代1for i in range(1000): pass 会导致生成一个 1000 个元素的 List 1for i in xrange(1000): pass 则不会生成一个 1000 个元素的 List,而是在每次迭代中返回下一个数值,内存空间占用很小. 因为 xrange 不返回 List,而是返回一个 iterable 对象 迭代迭代的意思是重复做一些事情很多次,记得在for循环中对序列和字典进行过迭代,for .. in .. 语法的叫做一个迭代器 迭代是一个实现可迭代对象(实现的是 iter() 方法)和迭代器(实现的是 next() 方法)的过程. 可迭代对象(iterable)一个实现了 iter方法的对象是可迭代的对象,该方法返回一个迭代器对象 iterable包括list,set,dict等一般的对象,处于打开状态的files,sockets 也是可迭代对象 迭代器(iterator)一个实现了next方法的对象则是迭代器,迭代器是一个带状态的对象,返回容器中的下一个值,并为下一次调用next()方法修改状态 可迭代对象是你可以从其获取到一个迭代器的任一对象.迭代器是那些允许你迭代可迭代对象的对象我们自定义一个迭代器,以斐波那契数列为例:1234567891011121314151617class Fab(object):def __init__(self, max): self.max = max self.n, self.a, self.b = 0, 0, 1def __iter__(self): return selfdef next(self): # python3使用__next__() if self.n &lt; self.max: r = self.b self.a, self.b = self.b, self.a + self.b self.n = self.n + 1 return r raise StopIteration()&gt;&gt;&gt; for n in Fab(5): print n 迭代器就像一个懒加载的工厂,等到有人需要的时候才给它生成值返回,没调用的时候就处于休眠状态等待下一次调用. 有很多关于迭代器的例子12345678910it=iter([1,2,3]) iterkeys(&#123;1:\"1\",2:\"2\"&#125;) iteritems(&#123;&#125;) # 可迭代对象it.next() # python3.0之前 迭代器next(it) # 之后# itertools函数返回的都是迭代器对象from itertools import cycle , islicecolors = cycle(['red', 'white', 'blue'])next(colors)limited = islice(colors, 0, 4)for x in limited:print x 生成器(generator)是一种用普通函数语法定义的迭代器.生成器一定是迭代器(反之不成立) yield 保持简洁性的同时获得了 iterable 的效果.把一个函数改写为一个 generator 就获得了迭代能力 yield 是一个类似 return 的关键字,只是这个函数返回的是个生成器 yield 进程挂起 保持连接 使用生成器,定义斐波那契数列12345678910def fab(max): n, a, b = 0, 0, 1 while n &lt; max: yield b # # yield 的作用就是把一个函数变成一个 generator # 调用 fab(5)不会执行fab函数,而是返回一个iterable对象 a, b = b, a + b n = n + 1 # 如果没有return,则默认执行至函数完毕,如果在执行过程中return #则直接抛出StopIteration终止迭代 1for n in fab(5): print n 在 for 循环执行时,每次循环都会执行 fab 函数内部的代码,执行到 yield b 时fab 函数就返回一个迭代值,下次迭代时,代码从 yield b 的下一条语句继续执行而函数的本地变量看起来和上次中断执行前是完全一样的,于是函数继续执行,直到再次遇到 yield看起来就好像一个函数在正常执行的过程中被 yield 中断了数次,每次中断都会通过 yield 返回当前的迭代值. 12f = fab(5)print f.next() 手动调用 fab(5) 的 next() 方法(因为 fab(5) 是一个 generator 对象,该对象具有 next() 方法),这样我们就可以更清楚地看到 fab 的执行流程 12f1 = fab(5)print f1.next() 每次调用 fab 函数都会生成一个新的 generator 实例,各实例互不影响 使用生成器,定义斐波那契数列 123456789def fib(): prev, curr = 0, 1 while True: yield curr prev, curr = curr, curr + prevfrom itertools import islice&gt;&gt;&gt; f = fib()&gt;&gt;&gt; list(islice(f, 0, 10))[1, 1, 2, 3, 5, 8, 13, 21, 34, 55] 生成器推导式1234d=(x*x for x in range(10))sum(d)# 285d.next() # StopIteration sum(d)已经迭代完了","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"docker RUN ENTRYPOINT CMD命令","slug":"docker-RUN-ENTRYPOINT-CMD","date":"2017-08-04T20:19:31.000Z","updated":"2017-09-23T11:10:15.668Z","comments":true,"path":"2017/08/04/docker-RUN-ENTRYPOINT-CMD/","link":"","permalink":"https://www.femn.me/2017/08/04/docker-RUN-ENTRYPOINT-CMD/","excerpt":"","text":"运行时机RUN在Dockerfile构建镜像的过程(Build)中运行,最终被commit的到镜像. ENTRYPOINT和CMD在容器运行(run、start)时运行 都有shell和exec形式shell形式1234567891011121314RUN command param1 param2CMD command param1 param2ENTRYPOINT command param1 param2# ENTRYPOINT的Shell格式会忽略任何CMD或docker run提供的参数#egRUN apt-get install python3 ENTRYPOINT echo \"Hello world\" CMD echo \"Hello world\" ENV name Cloud Man ENTRYPOINT echo \"Hello, $name\" # shell 格式底层会调用 /bin/sh -c &lt;command&gt;# 所以执行 docker run &lt;image&gt; 将输出# Hello, Cloud Man shell形式还有一个严重的问题:由于其默认使用/bin/sh来运行命令,如果镜像中不包含/bin/sh,容器会无法启动.exec形式1234567891011121314RUN [\"executable\", \"param1\", \"param2\"]ENTRYPOINT [\"executable\", \"param1\", \"param2\"]CMD [\"executable\", \"param1\", \"param2\"]#egRUN [\"apt-get\", \"install\", \"python3\"] ENTRYPOINT [\"/bin/echo\", \"Hello world\"]CMD [\"/bin/echo\", \"Hello world\"] ENV name Cloud Man ENTRYPOINT [\"/bin/echo\", \"Hello, $name\"]# Hello, $nameENV name Cloud Man ENTRYPOINT [\"/bin/sh\", \"-c\", \"echo Hello, $name\"]# Hello, Cloud Man CMD还多了一种用于为ENTRYPOINT提供参数的形式:此时 ENTRYPOINT 必须使用 Exec 格式参数格式1CMD [\"param1\",\"param2\"] shell形式和exec的形式的本质区别在于shell形式提供了默认的指令/bin/sh -c,所以其指定的command将在shell的环境下运行.因此指定command的pid将不会是1,因为pid为1的是shell,command进程是shell的子进程. exec形式则不然,但由于exec指定的命令不由shell启动,因此也就无法使用shell中的环境变量,如$HOME.如果希望能够使用环境变量,可以指定命令为sh:CMD [ “sh”, “-c”, “echo”, “$HOME” ]重载问题Dockerfile中只有最后一个ENTRYPOINT指令会生效,其他会被重载. Dockerfile中只有最后一个CMD指令会生效,其他会被重载. CMD指定的命令可以被docker run传递的命令覆盖.123456CMD echo \"Hello world\"# 运行容器 docker run -it [image] 将输出:# Hello worlddocker run -it [image] /bin/bash# CMD 会被忽略掉,命令 bash 将被执行# root@10a32dc7d3d3:/# ENTRYPOINT指定的命令不会被docker run传递的命令覆盖.容器名后面的所有内容都当成参数传递给其指定的命令.12345678ENTRYPOINT [\"/bin/echo\", \"Hello\"] CMD [\"echo\",\"world\"]# 当容器通过 docker run -it [image] 启动时,输出为:# Hello echo world# 而如果通过 docker run -it [image] CloudMan 启动,则输出为:# Hello CloudMan 当然,ENTRYPOINT指定的命令并不是不能重载的,只需指定–entrypoint来重载即可. 最佳实践 使用 RUN 指令安装应用和软件包,构建镜像. 如果 Docker 镜像的用途是运行应用程序或服务,比如运行一个 MySQL,应该优先使用 Exec 格式的 ENTRYPOINT 指令.CMD 可为 ENTRYPOINT 提供额外的默认参数,同时可利用 docker run 命令行替换默认参数. 如果想为容器设置默认的启动命令,可使用 CMD 指令.用户可在 docker run 命令行中替换此默认命令. ENTRYPOINT和CMD进行组合,运行shell脚本1234567FROM busyboxMAINTAINER femnCOPY ./entrypoint.sh /RUN chmod +x /entrypoint.shENTRYPOINT [\"/entrypoint.sh\"]CMD [\"echo\",\"CMD\"] entrypoint.sh如下:12345#!/bin/shset -eecho \"ENTRYPOINT\"exec \"$@\"# 脚本中使用exec \"$@\"来运行CMD中的命令 运行时则输出 ENTRYPOINT CMD,而运行的参数 都是传递给entrypoint.sh的.","categories":[{"name":"docker","slug":"docker","permalink":"https://www.femn.me/categories/docker/"}],"tags":[]},{"title":"Dockerfile docker-compose","slug":"Dockerfile_compose","date":"2017-08-04T15:24:48.000Z","updated":"2017-09-23T11:10:15.664Z","comments":true,"path":"2017/08/04/Dockerfile_compose/","link":"","permalink":"https://www.femn.me/2017/08/04/Dockerfile_compose/","excerpt":"","text":"Dockerfile定制镜像命令,docker镜像:业务代码和运行环境进行整体的打包:一个Dockerfile的文件:系统基本所需要的环境和软件 1234567891011vim Dockerfile FROM centos7 RUN # 对原镜像进行命令操作 ADD . /opt/ # 将宿主机此目录下的文件原copy到容器的/opt/下 EXPOSE 80 8000 # 容器可映射的端口 VOLUME [\"/home/python\",\"\"] WORKDIR '/home/xx' # 相当于宿主机的cd /home/xx CMD [\"nginx\", \"-g\", \"daemon off;\"] #一开始运行这个容器所执行的命令# 所有的文件复制均使用 COPY 指令,仅在需要自动解压缩的场合使用 ADD# 用Dockerfile 生成镜像appdocker build -t app . Dockerfile 模板文件,可以很方便的定义一个单独的应用容器,记录了(单)一个镜像的制作过程如果 dockerhub 的镜像不能满足我的需求就 dockerfile 自己 build 镜像 为什么还要docker-compose,是因为Dockerfile要去执行CMD [“bash”]之后,再去启动nginx,node等其它的服务,不能直观的看到端口之间的映射,以及服务之间的link的原因吗？ 但是很多时候,需要多个镜像合作才能启动一个服务,比如前端要有nginx,数据库mysql,邮件服务等等,当然你可以把所有这些都弄到一个镜像里去,但这样做就无法复用了.更常见的是,nginx,mysql,smtp都分别是个镜像,然后这些镜像合作,共同服务一个项目.docker-compose就是解决这个问题的.你的项目需要哪些镜像,每个镜像怎么配置,要挂载哪些volume,等等信息都包含在docker-compose.yml里.要启动服务,只需要docker-compose up就行,停止也只需要docker-compse stop/down dockerfile+docker-compose, 是因为docker-compose.yml本身没有镜像构建的信息,如果镜像是从docker registry拉取下来的,那么Dockerfile就不需要;如果镜像是需要build的,那就需要提供Dockerfile. docker-compost:定义和运行多个Docker容器的应用编排工具,定义并运行基于Docker的分布式应用,简化部署复杂应用的流程,管理容器化应用的完整开发周期 1.允许用户通过一个单独的docker-compose.yml模板文件(YAML格式)来定义一组相关联的应用容器为一个项目:project,包括注明需要哪些服务,服务之间的关联,开放的port,对外连结的路径volumes 2.以启动container为目的的、先build image再以此启动container 3.定义好了管理起来轻松,你如果喜欢用docker run带一大串parameters也是可以的 install compose12345678910curl -L https://github.com/docker/compose/releases/download/1.8.0/docker-compose-`uname -s`-`uname -m` \\ &gt; /usr/local/bin/docker-compose# 如果命令行下载超时 https://github.com/docker/compose/releases/download/1.8.0/docker-compose-Linux-x86_64cd Downloadcp docker-compose-Linux-x86_64 /usr/local/bin/docker-composechmod a+x /usr/local/bin/docker-composedocker-compose -hdocker-compose up/down/stop 管理server(contient)执行的顺序,但其实这只是希望是这样执行(docker run),但其实真正的启动时的, 还需要其它的工具去控制.123456789101112131415161718192021222324252627282930313233343536 mkdir 1 cd 1 vim docker-compose.yml nginx: image: nginx# 1. 只定义 image :先找本地、本地没有找 docker hub 、再没有就报错 # 2.只定义build:跑Dockerfile做image,有image直接用,image没有name和tag # 3.同时定义image和build:没有image就先跑build,name和tag用image定义的那个# 有了image就直接跑container # build: ./nginx ##nginx目录下有Dockerfile文件 ports: - \"80:80\" volumes: - $PWD/nginx/nginx.conf:/etc/nginx/nginx.conf - ./nginx/sites-enabled:/etc/nginx/sites-enabled restart: always node: image: node ports: -\"8000:8000\" volumes: - $PWD/node:/src/app restart: always mkdir node mkdir nginx cd nginx mkdir sites-enabled vim nginx.conf daemon off; 还要去配置node cd ../ docker-compose up docker-compose down docker ps -l 用docker-compose 自动一个一个的安装软件(client)12345678910111213141516171819202122vim docker-compose.yml version: '2' services: mongodb: image: tutum/mongodb ports: - \"27017:27017\" - \"28017:28017\" environment: - AUTH=no container_name: mongodb restart: always memcached: image: memcached ports: - \"11211:11211\" container_name: memcached restart: always# 效果:只要运行docker-compose up,就会自动安装mongodb和memcached# 并且会在机器重启的时候自启动 一个项目的例子","categories":[{"name":"docker","slug":"docker","permalink":"https://www.femn.me/categories/docker/"}],"tags":[]},{"title":"docker-hub","slug":"docker-hub","date":"2017-08-04T15:24:48.000Z","updated":"2017-09-23T11:10:15.668Z","comments":true,"path":"2017/08/04/docker-hub/","link":"","permalink":"https://www.femn.me/2017/08/04/docker-hub/","excerpt":"","text":"新建私有镜像仓库,只有registry:2这个镜像运行时,才能push,pull私有镜像库私有镜像仓库的好处: 1.上传下载速度快 2.企业可自行维护镜像仓库 3.需要维护镜像仓库服务器 4.同步docker官方镜像到企业私有镜像仓库 12345678910111213141516171819202122232425262728293031323334docker pull registry:2# 使用官方的 registry 镜像来启动本地的私有仓库 # 仓库会被创建在容器下/var/lib/registry下# 将镜像文件存放在本机的指定路径/data/registrydocker run -d -p 5000:5000 --restart=always --name registry \\ -v /data/registry:/var/lib/registry registry:2# 将镜像运行为容器 -d 将这个进程后台运行 -p 映射端口主机端口:容器端口 # --restart=always当容器服务死掉之后自动重启 --name容器的名字 # -v 映射容器的目录到宿主机下# -m 128m 内存限制在128M# 查看主机端口在容器的映射情况docker port nostalgic_morse 5000 docker pull nginx#镜像的重命名 标记镜像docker tag nginx 47.52.94.126:5000/nginx:last docker tag nginx 192.168.1.116:5000/nginx:last # modify docker daemon启动参数vim /usr/lib/systemd/system/docker.service# centos ubuntu:/lib/systemd/system/docker.service ExecStart=之前的不要动加上 --insecure-registry=0.0.0.0/0systemctl daemon-reloadsystemctl restart docker# 看参数有没有正确的添加.ps aux |grep docker # 上传标记镜像到私有仓库docker push 192.168.1.116:5000/nginx:last # 本机测试的成功docker pull 192.168.1.116:5000/nginx:last # 只要能连接上私有仓库,就可以从私有仓库中pull# 因为本机做为私有仓库,已经有这image了,所以下载得很快# docker push 47.52.94.126:5000/nginx:last 上传public IP失败 镜像上传到Docker Hub123456789docker login #输入 hub.docker.com注册时的用户名和密码docker pull registrydocker tag registry femn/registry:last# 镜像名:femn/registry tag:last#上传到Docker Hub 镜像名必须是 username/imagesname,才能上传# 并且不需要提前去Docker Hub创建仓库docker push femn/registry # 将本地镜像上传到https://hub.docker.com的个人仓库中了. Docker HubDocker通过docer search、pull、login和push等命令提供了连接Docker Hub服务的功能. Docker Hub是一个由Docker公司负责维护的公共注册中心,它包含了超过15,000个可用来下载和构建容器的镜像,并且还提供认证、工作组结构、工作流工具(比如webhooks)构建触发器以及私有工具(比如私有仓库可用于存储你并不想公开分享的镜像) 自动构建自动构建功能会自动从Github或BitBucket直接将镜像构建或更新至Docker Hub,通过为Github或Bitbucket的仓库添加一个提交的hook来实现,当你推送提交的时候就会触发构建和更新,但是,你不能通过docker push推送一个自动化构建,而只能通过在Github或者BitBucket提交你的代码来管理它.你可以在一个Docker的仓库中创建多个自动构建,配置它们只指定的Dockerfile或Git 分支 Automated Builds的一个实例建Dockerfile的目的,就是为了使用dockerfile里面的from语法的作用,来借用github服务器新建我需要的镜像 由于不能从google container上直接pull镜像,所以这里通过docker hub的Automated Builds功能从项目的dockerfile中Build到docker的官方服务器上,然后再从它们上面拉取 123456789101112131415161718192021222324# 步骤2中 创建一个带有Dockerfile的Github项目mkdir docker_libcd docker_libgit initmkdir google-etcd-amd64cd google-etcd-amd64vim Dockerfile FROM gcr.io/google_containers/etcd:2.0.12 MAINTAINER femn2014git add .git commit -m '增加Dockerfile文件,解决镜像被墙的问题'# 在github 创建一个名为docker_lib的项目git remote add origin https://github.com/femn2014/docker_lib.gitgit push -u origin master# 当完成此实例的所有步骤之后,再测试下,推送提交的时候就会触发构建和更新vim Dockerfile FROM nginx MAINTAINER femn2014git add .git commit -m '当推送提交时触发构建和更新'git push -u origin master# 这时 docker pull femn/etcd 时下载的将会是nginx的镜像 总结来说 自动构建的步骤1.创建一个Docker Hub账户并且登陆2.通过create选择 create automated build创建一个项目,再选择连接一个包含Dockerfile的GitHub或者BitBucket.3.给自动构建创建一个名称:etcd(相当于也就是Docker Hub的项目的镜像名称)4.配置自动化构建 (click here to customize)5.选择你想用于构建的分支(默认是master分支)6.指定Dockerfile的路径,默认是/,也可以在github中建立个目录再创建Dockerfile文件,为了方便我们后面区分镜像包7.指定一个Docker标签来构建 设置头像国内docker_hub另一个镜像管理工具Quay","categories":[{"name":"docker","slug":"docker","permalink":"https://www.femn.me/categories/docker/"}],"tags":[]},{"title":"docker-swarm","slug":"docker-swarm","date":"2017-08-04T15:24:48.000Z","updated":"2017-09-23T11:10:15.688Z","comments":true,"path":"2017/08/04/docker-swarm/","link":"","permalink":"https://www.femn.me/2017/08/04/docker-swarm/","excerpt":"","text":"swarm集群install swarm123docker pull swarm# 查看swarm版本docker run --rm swarm -v Host_consul_ip的例子 基于 consel 服务发现后端来配置一个本地 Swarm 集群1.1 配置每个节点主机123456789# 我用的是virtualbox,ubuntu16,安装好docker并修改好如下的内容,# reboot之后clone,clone过后的虚拟机只需要修改一下ip就行vim /lib/systemd/system/docker.service ExecStart=xx 再这后面加上如下内容 -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock sudo systemctl daemon-reloadsudo systemctl restart dockerps -aux |grep docketdocker pull swarm 坑一123456# docker daemon on node is running with# -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sockalias docker=\"docker -H tcp://0.0.0.0:2375 \\ -H unix:///var/run/docker.sock\"type dockerunalias docker 坑二123456docker -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock \\ --daemon=true --pidfile=\"/var/run/docker_2375.pid\" \\ --graph=\"/var/lib/docker_2375\"docker -H tcp://0.0.0.0:2375 --daemon=true \\ --pidfile=\"/var/run/docker_2375.pid\" \\ --graph=\"/var/lib/docker_2375\" 坑三1234567vim /lib/systemd/system/docker.service # 成功的 DOCKER_OPTS=-g /usr/bin/docker -H tcp://0.0.0.0:2375 \\ -H unix:///var/run/docker.sock # 这个是失败的 OPTIONS=-g /usr/bin/docker -H tcp://0.0.0.0:2375 \\ -H unix:///var/run/docker.sock 1.2 启动集群1.2.1.启动 Consel 服务后端(consul_ip or token,本机ip:109)至少一个群集管理器12345678# -h ==--namedocker run -d -p 8500:8500 --name=consul progrium/consul -server \\ -bootstrap -ui-dir /ui# 输出一个id:4b80d44e61d4e00510# sudo docker restart id # 重新启动此容器docker ps -a# 在浏览器中打开192.168.1.109:8500 1.2.2.启动管理节点主机(manager0_ip,ip为100的虚拟主机,一个群组工作者) 1234567891011# docker run -d -p 4000:4000 swarm manage -H :4000 --replication \\ # --advertise &lt;manager0_ip&gt;:4000 consul://&lt;consul_ip&gt;:8500# 如果有4000端口占用的情况docker ps -adocker rm -f -v containter_iddocker run -d -p 4000:4000 swarm manage -H :4000 --replication \\ --advertise 192.168.1.100:4000 consul://192.168.1.109:8500# 输出一个id:b7a3c10f294f4718bcd0a516f# 用户也可以启动 从管理节点# docker run -d swarm manage -H :4000 --replication --advertise \\ # &lt;manager1_ip&gt;:4000 consul://&lt;consul_ip&gt;:8500 1.2.3.启动工作节点(node_ip,ip为101,102,103的虚拟主机) 12345678# docker run -d swarm join --advertise=&lt;node_ip&gt;:2375 \\ # consul://&lt;consul_ip&gt;:8500docker run -d swarm join --advertise=192.168.1.101:2375 \\ consul://192.168.1.109:8500docker run -d swarm join --advertise=192.168.1.102:2375 \\ consul://192.168.1.109:8500docker run -d swarm join --advertise=192.168.1.103:2375 \\ consul://192.168.1.109:8500 节点启动后,用户可以指定 Docker 服务地址为 :4000&gt; 来测试各种 Docker 命令,可以看到整个 Swarm 集群就像一个虚拟的 Docker 主机一样正常工作. 123sudo docker -H 192.168.1.100:4000 ps -a sudo docker -H tcp://192.168.1.100:4000 infosudo docker ps --no-trunc 由于 Swarm 实际上是通过 agent 调用了本地的 Docker daemon 来运行容器,当 Swarm 集群服务出现故障时,无法接受新的请求,但已经运行起来的容器将不会受到影响. 在集群上运行容器1sudo docker -H 192.168.1.100:2375 run -d --name web1 nginx 2. token的例子dockerHub 的服务发现后端,需要各个节点能通过公网访问到 DockerHub 的服务接口 在任意一台安装了 Swarm 的机器上执行 swarm create 命令来在 DockerHub 服务上进行注册 2.1 创建集群 idSwarm 会通过服务发现后端(此处为 DockerHub 提供)来获取一个唯一的由数字和字母组成的 token,用来标识要管理的集群12345# ip_109本机执行sudo docker ps -asudo docker run --rm swarm create # 只需要运行一次就行了,它会一直保存着,虽然在本机docker ps -a也查看不到token_id=ce2f14fa5ec481170d2bf62f40f832f7 2.2 配置集群节点添加节点A(101)、B(102)到集群,在所有要加入集群的普通节点上面执行 swarm join 命令,表示把这台机器加入指定集群当中123456789# ip_109本机执行sudo docker run --rm swarm join --addr=192.168.1.100:2375 \\ token://$token_idsudo docker run --rm swarm join --addr=192.168.1.101:2375 \\ token://$token_idsudo docker run --rm swarm join --addr=192.168.1.102:2375 \\ token://$token_id# 列出节点 只需要出现一条记录之后就ctrl+csudo docker run --rm swarm list token://$token_id 2.3配置管理节点在任何一台主机A(A:192.168.1.100)B或者C上开启管理程序 12345678910# ip_100上执行docker run -d -p 8888:2375 swarm manage token://$token_id# 可以通过 docker ps 命令来查看启动的 swarm manager 服务容器docker ps# ip_109本机上 管理集群sudo docker -H 192.168.1.100:8888 ps # 在集群上运行容器sudo docker -H 192.168.1.100:8888 run -d --name web1 nginx 几个命令就将多个单机版本的 Docker daemon 变成一个 cluster,还支持了 service 概念(多个容器实例副本的抽象) 3. docker-machine swarm -d virtualboxdocker daemon是root python此用户才能在virtualbox中看到创建的dev等虚拟机,docker-machine是普通用户的命令 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253docker run swarm -vsid=$(sudo docker run swarm create)echo $siddocker ps -a #有上面两个但状态都是Exiteddocker-machine create -d virtualbox --swarm --swarm-master \\ --swarm-discovery token://$sid swarm-master# The host-only adapter is corrupted. Let's stop the VM, fix the host-only adapter and restart the VM# 但我没有去做操作,它自动去改了？docker-machine lsdocker-machine create -d virtualbox --engine-label itype=frontend \\ --swarm --swarm-discovery token://$sid swarm-node-01docker-machine create -d virtualbox --engine-label itype=frontend \\ --swarm --swarm-discovery token://$sid swarm-node-02docker-machine create -d virtualbox --engine-label itype=frontend \\ --swarm --swarm-discovery token://$sid swarm-node-03docker-machine env swarm-masterdocker-machine env --swarm swarm-mastereval \"$(docker-machine env --swarm swarm-master)\"docker infodocker run swarm list token://$siddokcer ps -a docker-machine lseval \"$(docker-machine env swarm-master)\"docker ps -aeval \"$(docker-machine env --swarm swarm-master)\"docker-machine lsdocker ps # 进入环境了,docker runsudo docker run -itd --name engmgr ubuntusudo docker ps # 居然不是下在本机的 成功 有没有可能是主机的docker是什么权限,环境中的也是啊# swarm-node-02/engmgr 而我的是engmgrfor i in `seq 1 6`; do sudo docker run -itd -e \\ constraint:itype!=frontend --name eng$i ubuntu; donesudo docker ps# swarm-node-02/eng1 等还是没有前缀名# filtersudo docker run -itd --name engmgr-c -e \\ affinity:container==engmgr ubuntudocker-machine kill $(docker-machine ls -q)# 好像就回到了本机了sudo docker images # ubuntu的镜像也在下载过来了 注意:您会注意到命令不能与前缀sudo .这是因为它假设您正在使用的登录到服务器docker-machine ssh使用Docker窗机设置后命令 4. docker-machine swarm -d digital1234567891011121314151617181920212223242526272829303132333435363738394041424344DOTOKEN=DOTOKEN_ID# 生成节点for i in 1 2 3; do docker-machine create --driver digitalocean \\ --digitalocean-image ubuntu-16-04-x64 \\ --digitalocean-access-token $DOTOKEN node-$i; done# 该开的端口,也都开了# 命令成功完成后,您可以通过访问您的DigitalOcean仪表板或输入以下命令来验证是否已创建所有计算机:#更新docker-machine之后执行,就如此简单的创建了主机,在控制面板就可以看到新创建出来的实例了:docker-machine ls eval \"$(docker-machine env node-1)\"# 使节点成为集群成员,选择其中一个节点并将其作为Docker Swarm(Node-1)管理器docker-machine ssh node-1docker swarm init --advertise-addr 45.55.87.176# 会输出如下信息# docker swarm join --token SWMTKN-1-xx 45.55.87.176:2377# 并将其余部分配置为Docker Swarm工作线程. docker-machine ssh node-2docker swarm join --token SWMTKN-1-xx 45.55.87.176:2377docker-machine ssh node-3docker swarm join --token SWMTKN-1-xx 45.55.87.176:2377# Docker Swarm管理命令必须在管理器节点上执行docker-machine ssh node-1docker node ls docker node --help# 您可以随时从群集中添加或删除节点. 此外,工作节点可以升级为管理器,并且管理器可以转换为工作器docker info# 在Docker Swarm中运行服务 docker node命令一样, docker service命令只能在管理器节点上执行docker service create -p 80:80 --name webserver nginx# 要查看集群上运行的服务,请键入:docker service ls # 可以输入node-1IP到浏览器中,可以看到Nginx的默认页面.# 您可以通过使用docker service ps后跟服务名称来确定服务正在运行的节点docker service ps webserverdocker-machine stop node-1 node-2 node-3docker swarm --help 大坑: -driver virtualbox docker-machine version 0.12.0 是没有问题的 但 amazonec2 和 digitalocean ,都要是0.12.1版本才行,不然在创建时,会报如下错 Error creating machine: Error running provisioning: ssh command error:Unable to query docker version: Cannot connect to the docker engine endpoint 5. docker-machine 在AWS创建Docker主机(会创建一个新的实例,会有收费)1234567891011121314151617181920212223242526# http://usyiyi.cn/documents/docker/machine/examples/aws.html# 开放22,2376,2377,80 Docker machine的安全组docker-machine create --driver amazonec2 \\ --amazonec2-access-key you_access_key \\ --amazonec2-secret-key you_secret_key \\ --amazonec2-region=us-west-2 aws-01# /home/python/.docker/machine/machines/aws-01docker-machine ssh aws-01 # 虽然有下面的各种坑,但还是能进去,一直报错所以一直没有执行此命令 docker swarm init --advertise-addr 54.244.58.2# 不像digitalocean 一样顺利,还得vim /lib/systemd/system/docker.service 然后重启,再执行就和digitalocean一样了docker swarm join --token SWMTKN-1-xx 54.244.58.2:2377docker-machine create --driver amazonec2 \\ --amazonec2-access-key you_access_key \\ --amazonec2-secret-key you_secret_key \\ --amazonec2-region=us-west-2 aws02docker-machine ssh aws02 sudo docker swarm join --token SWMTKN-1-xx 54.244.58.2:2377docker-machine ssh aws-01docker service create -p 80:80 --name webserver nginxdocker service lsdocker service ps webserver# Docker Swarm的另一个功能是缩放服务的能力,即启动服务的其他实例.假设我们想将我们之前启动的webserver服务扩展为五个实例docker service scale webserver=5 #output: webserver scaled to 5docker service ps webserver # 可以看到这5个服务在都分布在哪些节点上 坑一: 创建实例时,先要在EC2控制面板创建一对密钥对,在创建实例时,选择此密钥对,并保存好,当你创建好实例之后,要连接实例时需要此.pem文件,才能连接上,不然就悲剧了. 坑二: IAM:不是你的用户名和密码(root) ,失败123456789101112131415161718192021docker-machine create --driver amazonec2 \\ --amazonec2-access-key username \\ --amazonec2-secret-key password \\ --amazonec2-vpc-id vpc-a24484c4 aws-sandbox# 你也可以创建其它的用户来管理aws,失败docker-machine create --driver amazonec2 \\ --amazonec2-access-key AKIAIDGRV7O6MZ2DOYDA \\ --amazonec2-secret-key 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 \\ --amazonec2-vpc-id vpc-978f4cf1 aws-sandbox# 但只能是root用户才能访问成功docker-machine create --driver amazonec2 \\ --amazonec2-access-key you_access_key \\ --amazonec2-secret-key you_secret_key \\ --amazonec2-vpc-id vpc-a24484c4 \\ --amazonec2-zone=b aws-sandbox# unable to find a subnet in the zone: us-east-1b to issuessh -i \"femn.pem\" ubuntu@ec2-34-212-39-188.us-west-2.compute.amazonaws.comsudo apt install awscliaws configure 坑三: 配置aws CLI ,IAM上面已得知了,Default region name:必须是这个实例的实际地址 一定要选自己的地区 us-west-2","categories":[{"name":"docker","slug":"docker","permalink":"https://www.femn.me/categories/docker/"}],"tags":[]},{"title":"docker网络代理设置","slug":"docker-set-net","date":"2017-08-04T15:24:48.000Z","updated":"2017-09-23T11:10:15.684Z","comments":true,"path":"2017/08/04/docker-set-net/","link":"","permalink":"https://www.femn.me/2017/08/04/docker-set-net/","excerpt":"","text":"背景在一些实验室环境,服务器没有直接连接外网的权限,需要通过网络代理.我们通常会将网络代理直接配置在/etc/environment、/etc/profile之类的配置文件中,这对于大部分操作都是可行的.然而,docker命令却使用不了这些代理.比如docker pull时需要从外网下载镜像,就会出现如下错误:1docker pull hello-world Unable to find image,hello-world:latest locallyPulling repository docker.io/library/hello-world docker: Network timed out while trying to connect to here. You may want to check your internet connection or if you are behind a proxy.. 解决方案一:停止docker服务,手动以使用2375端口监听所有网络接口的方式启动docker daemon. 12systemctl stop docker.servicenohup docker daemon -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock &amp; 详情参见 解决方案二:该方法是持久化的,修改后会一直生效.该方法覆盖了默认的docker.service文件. 为docker服务创建一个内嵌的systemd目录 1mkdir -p /etc/systemd/system/docker.service.d 创建/etc/systemd/system/docker.service.d/http-proxy.conf文件,并添加HTTP_PROXY环境变量.其中[proxy-addr]和[proxy-port]分别改成实际情况的代理地址和端口: 123vim /etc/systemd/system/docker.service.d/http-proxy.conf [Service] Environment=\"HTTP_PROXY=http://0.0.0.0:2375/\" 如果还有内部的不需要使用代理来访问的Docker registries,那么还需要制定NO_PROXY环境变量: 1234[Service]Environment=\"HTTP_PROXY=http://[proxy-addr]:[proxy-port]/\" \\ \"HTTPS_PROXY=https://[proxy-addr]:[proxy-port]/\" \\ \"NO_PROXY=localhost,127.0.0.1,docker-registry.somecorporation.com\" 更新配置: 1systemctl daemon-reload 重启Docker服务: 1systemctl restart docker","categories":[{"name":"docker","slug":"docker","permalink":"https://www.femn.me/categories/docker/"}],"tags":[]},{"title":"docker-machine","slug":"docker-machine","date":"2017-08-04T15:24:48.000Z","updated":"2017-09-23T11:10:15.668Z","comments":true,"path":"2017/08/04/docker-machine/","link":"","permalink":"https://www.femn.me/2017/08/04/docker-machine/","excerpt":"","text":"Docker Engine 主要用来接收和处理docker命令请求的(Docker Engine==Docker引擎==Docker Engine的客户端==docker)Docker我们一般理解的,都是C/S模型,用户通过docker client向docker daemon发送REST 请求. Docker Engine包括这么几个部分: 1.Docker Daemon — docker 的守护进程,属于C/S中的server 2.Docker REST API — docker daemon向外暴露的REST 接口 3.Docker CLI — docker向外暴露的命令行接口(Command Line API) 因此,客户端访问服务端的方式有两种,一种是使用命令行工具,比如docker run, docker ps…等等.另一种就是直接通过调用REST API,比如发送一个curl http请求 Docker Machine是一个工具,用来在虚拟主机上安装Docker Engine(Machine),并使用 docker-machine命令来管理这些虚拟主机(Machine).是一个可以帮助我们在电脑上、在云端、在数据中心内创建 Docker 主机的应用主要用来管理 docker化的 host (安装了Docker Engine的主机)使用 docker-machine命令,你可以启动、查看、停止以及重启一个主机,升级Docker client和daemon,配置Machine 的 Docker client与你的主机进行通信 无论是Mac,Windows或是Linux,你都可以在其上安装Docker Machine,使用docker-machine命令来创建和管理大量的Docker hosts.它会自动创建主机,在主机上安装Docker Engine,然后配置docker client.每个被管理的主机(“machine”)都是一个Docker 主机和一个配置过的client的组合. docker Machine的具体使用场景:1.你目前只有一个老版本的MacOSX(比如10.10.2)或者Windows系统,想在上边运行docker. 2.想在远程系统上创建Docker主机,比如想在网络上,云平台上,以及本地创建Docker host,你就需要Docker Machine. 3.docker在不同的linux上得安装方法不一样,通过这个工具可以提供统一的安装方法. 你可以使用Machine在一个或多个虚拟机上安装Docker Engine.这些虚拟机可以是在本地(当你使用Machine在VirtualBox安装和运行Docker Engine时)也可以是远程的(使用Machine在云平台上创建Docker化的主机时).这些虚拟化的主机可以被认为是”machine”Machine解决因操作系统异构导致的安装 Docker 困难的问题,所有系统部署 Docker 都变得非常方便. install machine 123456789curl -L https://github.com/docker/machine/releases/download/\\ v0.12.1/docker-machine-`uname -s`-`uname -m` \\ &gt;/tmp/docker-machine &amp;&amp;chmod a+x /tmp/docker-machine sudo cp /tmp/docker-machine /usr/local/bin/docker-machine#如果超时,直接从网页中下载https://github.com/docker/machine/releases/download/v0.12.1/docker-machine-Linux-x86_64chmod a+x docker-machine-Linux-x86_64sudo mv docker-machine-Linux-x86_64 /usr/local/bin/docker-machine use machine你也可以在VirtualBox等虚拟机上安装Docker engine到Docker中.在本地客户端,就好像所有的Docker 引擎运行在本地一样 需要先安装virtualbox这个软件 需要的是boot2docker.iso 只是一个普通的iso文件.Docker Machine使用boot2docker作为virtualbox的镜像 – boot2docker是一个运行Docker容器的轻量级Linux系统,完全在内存中运行不是下载此镜像:sudo docker pull boot2docker/boot2docker而是 将iso放到 /home/python/.docker/machine/cache/ 再运行12345678910111213141516docker-machine create -d virtualbox dev# -driver virtualbox 表示我们在VirtualBox 的虚拟机里面部署 docker,代表的是驱动类型# 最后的参数\"dev\" 是虚拟机(Machine)的名称# http://os1h5rv4q.bkt.clouddn.com/docker_dev.jpg#用这个Machine可以配置本地Docker客户端,用到env命令完成docker-machine env dev# 目前已經建立出來的 docker VMdocker-machine ls# Docker客户端将会使用设置的相同的环境变量通过Docker API与运行在上面的机器互相通信# 设置完成后,就可以在本地机器访问远程Dockereval $(docker-machine env dev)docker ps","categories":[{"name":"docker","slug":"docker","permalink":"https://www.femn.me/categories/docker/"}],"tags":[]},{"title":"docker容器与镜像","slug":"docker","date":"2017-08-04T15:24:48.000Z","updated":"2017-09-23T11:10:15.668Z","comments":true,"path":"2017/08/04/docker/","link":"","permalink":"https://www.femn.me/2017/08/04/docker/","excerpt":"","text":"docker镜像:业务代码和运行环境进行整体的打包.1.1快速创建环境(开发,测试,生产) 1.2整体交付(运行环境+代码(之前只是代码)) 1.3可保证环境(开发,测试,生产)的一致性 1.4更好的完成devops 镜像(Image)就是一堆只读层(read-only layer)的统一视角这些层是Docker内部的实现细节,并且能够在主机的文件系统上访问到,统一文件系统(union file system)技术能够将不同的层整合成一个文件系统,为这些层提供了一个统一的视角,这样就隐藏了多层的存在,在用户的角度看来,只存在一个文件系统,你可以在你的主机文件系统上找到有关这些层的文件.它们存在于/var/lib/docker/aufs目录下1sudo tree -L 1 /var/lib/docker/ 容器=镜像+读写层.并且容器的定义并没有提及是否要运行容器123456# 创建容器docker create &lt;image_id&gt;# 运行容器docker start &lt;image_id&gt;# 上两条命令组合下如下命令docker run &lt;image_id&gt; 所以容器(container)的定义和镜像(image)几乎一模一样,也是一堆层的统一视角,唯一区别在于容器的最上面那一层是可读可写的. 镜像分层技术:AUFS (Another UnionFS)支持将多个目录挂载到同一个虚拟目录下.已构建的镜像会设置成只读模式,read-write操作是在read-only上的一种增量操作.把一个镜像创造成一个容器才能往里写东西.所谓UnionFS就是把不同物理位置的目录合并mount到同一个目录中.UnionFS的一个最主要的应用是,把一张CD/DVD和一个硬盘目录给联合 mount在一起然后,你就可以对这个只读的CD/DVD上的文件进行修改(当然,修改的文件存于硬盘上的目录里) docker容器管理技术,是内核技术,容器本身是进程 其启动程序就是容器应用进程,容器就是为了主进程而存在的,主进程退出,容器就失去了存在的意义,从而退出,其它辅助进程不是它需要关心的东西它并不是虚拟技术(VM),docker最关键的点是提出了docker images标准化,image打包了应用:如nginx镜像,通过镜像启动一个nginx容器,其实就是在主机上启动了一个nignx进程.容器不等于微服务,推荐只运行一个服务,如果运行多个服务,需要结合进程管理工具(supervisor,S6),因为容器本身就是进程,所以数据库容器也可以运行,但需要对数据做好保护(volume). 既然是进程,那么在启动容器的时候,需要指定所运行的程序及参数.CMD 指令就是用于指定默认的容器主进程的启动命令的,在运行时可以指定新的命令来替代镜像设置中的这个默认命令,比如,ubuntu 镜像默认的 CMD 是 /bin/bash,如果我们直接 docker run -it ubuntu 的话,会直接进入 bash. 容器中的应用都应该以前台执行,而不是像虚拟机、物理机里面那样,用 upstart/systemd 去启动后台服务,容器内没有后台服务的概念. ubuntu install docker123456789101112sudo apt-get updatecurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \"deb [arch=amd64] \\ https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\"sudo apt-get updatesudo apt-cache policy docker-cesudo apt-get install -y docker-cesudo systemctl status dockersudo usermod -aG docker $(whoami)service docker startdocker images# 虚拟机是用此方法下载 当前用户就可以使用whoami debain install docker12345678910111213141516171819202122232425# 坑一sudo apt-get updatesudo apt-get install docker.ioapt-get purge docker.io* # 坑二apt-get dist-upgrade -yapt-key adv --keyserver hkp://pgp.mit.edu:80 --recv-keys \\ 58118E89F3A912897C070ADBF76221572C52609Decho \"deb https://apt.dockerproject.org/repo debian-jessie main\" | \\tee /etc/apt/sources.list.d/docker.listapt-get updateapt-get install docker-engine -yapt-get purge docker-engine -y # 成功apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 \\ --recv-keys 58118E89F3A912897C070ADBF76221572C52609Decho \"deb https://apt.dockerproject.org/repo ubuntu-trusty main \" &gt; \\ /etc/apt/sources.list.d/docker.listapt-get update apt-get install docker-engine=1.10.1-0~trustyapt install docker.iodocker -v# 本机是此方法下载docker 必须是root身份才能使用 启动docker服务docker官方镜像 类似AppStore 是由各自官方机构做的镜像认证后,上传到docker官方镜像的,这个仓库的地址是在国外,所以下载的速度会慢点利用镜像的分层技术,如果主机上已有layer(层)存在,那只会下载新增加的layer(类似git代码提交机制) 123456789service docker start docker port nostalgic_morse 5000 # 查看主机端口在容器的映射情况# modify docker daemon启动参数 Docker的配置文件 vim /usr/lib/systemd/system/docker.service # centos ubuntu:/lib/systemd/system/docker.serviceExecStart=之前的不要动加上 --insecure-registry=0.0.0.0/0systemctl daemon-reloadsystemctl restart dockerps aux |grep docker #看参数有没有正确的添加. 容器操作命令123456789101112131415161718192021222324252627282930313233343536373839docker run -dit -p 80:80 --name app nginx# -d后台运行 -it此时的容器就有了标准的输入和输出docker create -p 80:80 --name app nginx# 创建容器docker start app #运行容器docker commit &lt;container-id&gt;# 将容器的可读写层转换为一个只读层,这样就把一个容器转换成了不可变的镜像# 用Dockerfile 生成镜像,命名为appdocker build -t app .docker exec -it app bash # 在运行中的容器执行一个新进程# 以bash的方式登陆到容器里面 exit 从容器中退出docker exec -it app bash ls /tmpdocker rename app new_app #重命容器名docker stop/kill/pause/unpause/restart &lt;container_id&gt;# 对容器中的进程发信号docker inspect/stats/port/ps/top/dip/dpid &lt;container-id&gt;# 查看容器状态docker top app #查看当前容器跑了多少进程docker ps # 列出所有运行中的容器,这隐藏了非运行态容器的存在docker ps -a # 查看所有容器docker inspect nginx/app |grep -i memory # 查看指定镜像/容器# 会提取出容器或者镜像最顶层的元数据docker stats $(docker ps | awk 'NR&gt;1 &#123;print $NF&#125;')docker update -m 256m app #更新容器信息docker rm -f -v app # 移除构成容器的可读写层# -f 强制删除 -v 连同Volumes也一起删除# -v如果这个容器有Volume这个文件存在的话,也一起删除掉docker copy 本地文件 容器路径 docker copy app:/usr/share/ngxin/html/index.html .docker copy index.html app:/tmpdocker export app (把容器保存成tar文件)docker import app.tar (把tar文件导会到镜像列表) 镜像命令12345678910111213141516171819202122232425docker commit -a admin@femnyy.com -m 'app commit image' app app:2.0# -a作者 -m提交时的标记 app容器名 app:2.0镜像名# 用容器创建镜像 推荐用Dockerfiledocker save nginx &gt;nginx.tar# 镜像 --&gt;tar包docker rmi nginx# 删除镜像# 1.此镜像是其他镜像的父镜像 # 2.有容器使用镜像 镜像已经被创建为容器 不能删除本地镜像docker load &lt; nginx.tar# tar包--导入到镜像列表中docker images# 列出了所有顶层(top-level)镜像docker history &lt;image_id&gt;# 列出镜像的所有层docker pull nginx# 下载镜像docker tag nginx 192.168.1.116:5000/nginx:last # 镜像的重命名(标记镜像)docker push 192.168.1.116:5000/nginx:last # 本机测试的成功# 上传镜像docker search nginx# 查看镜像 容器与镜像镜像不能直接访问,只有启动成容器,才可以访问.镜像和容器的关系,就像是面向对象程序设计中的类和实例一样,镜像是静态的定义,容器是镜像运行时的实体.容器可以被创建、启动、停止、删除、暂停等.同一个 Images 可生成多个不同配置的 Container. 容器连接(相当于进程间的通信吧)123456sudo docker run -d --name db training/postgres# 指定了 training/webapp 镜像,并且这个镜像已经包含了简单的 Python Flask web 应用程序# 最后,我们指定了我们容器要运行的命令: python app.py.这样我们的 web 应用就启动了sudo docker run -d -P --name web --link db:db training/webapp python app.pydocker ps # db和web,我们还在名字列中可以看到web容器也显示db/web.这告诉我们web容器和db容器是父/子关系. Volume(持久化容器数据,以及容器之间共享数据)保留容器的数据当容器删除时,就是杀死进程,只要我们的数据在,当再启动时,数据又回来了,但我们想在容器中产生的数据保留起来 容器间的数据共享(root用户下,主机巻)123456789101112131415161718192021docker run -d -v /web_data:/tmp:ro --name data-container nginxcd /web_datamkdir filestouch test.filedocker exec -it data-container ls /tmp#第二个容器的数据来自 第一个容器的数据docker run -d --volumes-from data-container --name web-container nginx#第三个容器的数据来自 第一个容器的数据docker run -d --volumes-from data-container --name web-container-2 nginx# 查看容器 有没有第一个容器中的文件docker exec -it web-container ls /tmp# 验证只读docker exec -it web-container bashcd /tmptouch a.txtexit# 在宿主机添加一个新文件,相当于往三个容器分发信息.cd /web_datatouch a.txt Volume分为容器卷(在Dockerfile写了VOLUME)和主机卷容器卷的定义的目录,将会自动保存在宿主机的/var/lib/docker/volumes目录下1234567891011121314151617181920mkdir dockercd docker &amp;&amp; vim DockerfileFROM centos:7RUN yum -y install epel-release &amp;&amp; \\ yum -y install nginx &amp;&amp; \\ yum clean allEXPOSE 80 443VOLUME [\"/usr/share/nginx/html\"]CMD [\"nginx\",\"-g\", \"daemon off;\"]# 用Dockerfile 生成镜像appdocker build -t app .cd /var/lib/docker/volumesdocker rm -f web-container data-containerdocker run -d --name app appll #会有一个随机生成字符串的目录 VOLUME的东西,将会同步到这个目录下的_data目录下docker rm -f -v app # -v 主机卷(/web-data),这个不仅仅会在/var/lib/docker/volumes:/usr/share/nginx/html保留,双保险.1docker run -d -p 80:80 --name app -v /web-data:/tmp app 备份app容器中 /dbdata容器巻中的数据–&gt;打包在容器中的/backup/backup.tar–&gt;将此包copy到主机的当前目录1234567891011121314151617# 通过ubuntu这个镜像生成一个容器# --rm 这个容器退出 就把这个容器删掉# 使用 --volumes-from 标记来创建一个加载 dbdata 容器卷的容器:appdocker run --rm --volume-from app -v $&#123;pwd&#125;:/backup ubuntu \\ tar cvfz /backup/backup.tar /dbdata# 1.数据恢复docker run --rm --volume-from app -v $&#123;pwd&#125;:/backup busybox \\ bash -c \"cd /dbdata &amp;&amp; tar zxvf /backup/backup.tar --strip 1\"# 2# 如果要恢复数据到一个容器,首先创建一个带有空数据卷的容器 dbdata2sudo docker run -v /dbdata --name dbdata2 ubuntu /bin/bash# 然后创建另一个容器,挂载 dbdata2 容器卷中的数据卷# 并使用 untar 解压备份文件到挂载的容器卷中.sudo docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf/backup/backup.tar#为了查看/验证恢复的数据,可以再启动一个容器挂载同样的容器卷来查看sudo docker run --volumes-from dbdata2 busybox /bin/ls /dbdata Docker的网络模式:nat,host,container,none,overlay默认启动的是nat nat需要进行端口的管理,通过docker容器转发的功能,转发到宿主机的网卡上,每次启动容器的时候,它的IP会变:1234567891011docker run -d -p 80:80 --name app nginxps -aux |grep docker# 得到如下信息/usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 80 \\ -container-ip 172.17.0.3 -container-port 80# 但我试了两次 IP都没有变docker restart app/usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 80 \\ -container-ip 172.17.0.3 -container-port 80docker stop appdocker start app host:容器中的网卡直接与宿主机的网卡沟通:只能使用80端口,但可以固定容器的IP.攻击了容器也就相当于攻击了宿主机.1234docker run -d --name app2 --net=host nginxdocker ps -a # 查看端口是否已经冲突,如果冲突则这个容器会启动失败 状态为Exiteddocker start -a app2 # 端口也占用 container模式,用于容器之间经常通信的情况:12345678docker pull busyboxdocker run -it --name busybox1 busybox ship addrctrl+p+q # 不使用exit,让容器在后台运用docker run -it --name busybox2 --net=container:busybox1 busybox ship addr# 此两个的容器的IP是一模一样的,而且还可以相互通信ping busybox1 none模式:没有IP1docker run -it --name none --net=none busybox sh overlay模式,实现跨主机的通信,docker:1.10+,才有的模式. 约定的容器启动时 会被当作一个服务被consul发现,从而分发IP 1234567891011vim /lib/systemd/system/docker.service# 注意改自己的IP地址,和网卡的名称# 多台也是这个的一样的配置(不需要去改变IP地址和网卡名称)# 使用hostA做为consul的服务端 hostA的IP;192.168.1.116 网卡名称为:enp2s0# hostA hostB都要操作ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 \\ -H unix:///var/run/docker.sock --cluster-store=consul://192.168.1.116:8500 \\ --cluster-advertise=enp2s0:2376 --insecure-registry=0.0.0.0/0systemctl daemon-reloadsystemctl restart dockerps -aux |grep docket 在consul的主机执行就可以:hostA 1234567891011121314docker pull progrium/consul# -h 取名 -server服务端 并把ui打开docker run -d -p 8400:8400 -p 8500:8500 -p 8600:53/udp -h consul progrium/consul \\ -server -bootstrap -ui-dir /uidocker ps -a# 在浏览器中打开192.168.1.116:8500# 在KEY/VALUE中 会显示有多少台主机进行着通信 hostA,hostB# create overlay network 创建IP地址池 会用consul定义一个IP地址池(如10.0.9.0/24)docker network ls# -d overlay使用overlay驱动 --subnet 网段 edu_net为名称 # 会同步到多台主机上(hostA,hostB)docker network create -d overlay --subnet=10.0.9.0/24 edu-net 当约定好的主机启动容器时,consul服务就会从地址池中取得IP,给容器使用 1234567891011# hostAdocker run -d --name app1 --net=edu-net nginx# 登陆进出docker exec -it app1 baship addrping www.baidu.com# hostB 没有虚拟技术 所以没有实做docker run -d --name app2 --net=edu-net nginxdocker exec -it app2 bashping app1 官方文档 一个中文的docker文档 对docker的解释","categories":[{"name":"docker","slug":"docker","permalink":"https://www.femn.me/categories/docker/"}],"tags":[]},{"title":"supervisor","slug":"supervisor-server","date":"2017-08-04T15:24:48.000Z","updated":"2017-09-23T11:10:15.712Z","comments":true,"path":"2017/08/04/supervisor-server/","link":"","permalink":"https://www.femn.me/2017/08/04/supervisor-server/","excerpt":"","text":"Linux的后台进程运行有好几种方法,例如nohup,screen等,但是,如果是一个服务程序,要可靠地在后台运行,我们就需要把它做成daemon,最好还能监控进程状态,在意外结束时能自动重启. supervisor就是用Python开发的一套通用的进程管理程序,能将一个普通的命令行进程变为后台daemon,并监控进程状态,异常退出时能自动重启.另一个进程管理工具:S6 Debian / Ubuntu可以直接通过apt安装: 1sudo apt-get install supervisor 如果是通过pip安装的话,就需要echo_supervisord_conf程序生成supervisor的初始化配置文件: 123sudo pip install supervisormkdir /etc/supervisorecho_supervisord_conf &gt; /etc/supervisor/supervisord.conf supervisor安装完成后会生成三个执行程序:supervisortd 守护进程服务,用于接收进程管理命令.supervisorctl 客户端,用于和守护进程通信,发送管理进程的指令.echo_supervisord_conf 生成初始配置文件程序然后,给我们自己开发的应用程序编写一个配置文件,让supervisor来管理它.每个进程的配置文件都可以单独分拆,放在/etc/supervisor/conf.d/目录下,以.conf作为扩展名 vim server.conf123456789101112131415161718[program:python8010]command = /usr/bin/python3 HttpsRunner.pydirectory = /server/app1.6user = rootredirect_stderr = truestdout_logfile_maxbytes = 150MBstdout_logfile_backups = 20stdout_logfile = /server/app1.6/python8010.log[program:mongod];command = /mongo/mongodb-linux-x86_64-ubuntu1404-3.2.10/bin/mongod --dbpath /mnt/mongodb --authcommand = /mongo/mongodb-linux-x86_64-ubuntu1404-3.2.10/bin/mongod -f /server/app1.6/mongodb.confdirectory = /server/app1.6user = rootredirect_stderr = truestdout_logfile_maxbytes = 150MBstdout_logfile_backups = 20stdout_logfile = /server/app1.6/mongodb.log Supervisor只能管理非daemon的进程,也就是说Supervisor不能管理守护进程.否则提示Exited too quickly (process log may have details)异常.启动Supervisor服务: 1supervisord -c /etc/supervisor/supervisord.conf 管理进程: 12345678910111213supervisorctl statussupervisorctl stop mongodsupervisorctl start python8010supervisorctl restart python8001# 重启所有属于名为groupworker这个分组的进程(start,restart同理)supervisorctl stop groupworker# 停止全部进程,注:start、restart、stop都不会载入最新的配置文件supervisorctl stop all # 载入最新的配置文件,停止原有进程并按新的配置启动、管理所有进程supervisorctl reread/reload# 根据最新的配置文件,启动新配置或有改动的进程,配置没有改动的进程不会受影响而重启supervisorctl updatesupervisorctl tail &lt;APP_NAME&gt; 进入CLI管理台: 1supervisorctl Web管理界面 12345vim /etc/supervisor/supervisord.conf [inet_http_server] ; inet (TCP) server disabled by default port=0.0.0.0:9001 ; (ip_address:port specifier, *:port for all iface) username=root ; (default is no username (open server)) password=root ; (default is no password (open server)) 重启Supervisor服务,如果有Unlinking stale socket /var/run/supervisor.sock 执行unlink /var/run/supervisor.sock: 12ps aux |grep supervisordsupervisord -c /etc/supervisor/supervisord.conf 开机启动Supervisor:方法1: Linux 在启动的时候会执行 /etc/rc.local 里面的脚本,所以只要在这里添加执行命令就可以 以下内容需要添加在 exit 命令前,而且由于在执行 rc.local 脚本时,PATH 环境变量未全部初始化,因此命令需要使用绝对路径.1/usr/bin/supervisord -c /etc/supervisor/supervisord.conf 如果是 Ubuntu 16.04 以上,rc.local 被当成了服务,而且默认是不会启动,需要手动启用一下服务 启动rc.local服务:1sudo systemctl enable rc-local.service 方法二:Supervisord 默认情况下并没有被安装成服务,它本身也是一个进程.官方已经给出了脚本可以将 Supervisord 安装成服务,可以参考这里查看各种操作系统的安装脚本,但是我用官方这里给的 Ubuntu 脚本却无法运行.安装方法可以参考 serverfault这个脚本下载下来后,还需检查一下与我们的配置是否相符合,比如默认的配置文件路径,pid 文件路径等,如果存在不同则需要进行一些修改","categories":[{"name":"server","slug":"server","permalink":"https://www.femn.me/categories/server/"}],"tags":[]},{"title":"os模块","slug":"os","date":"2017-08-04T08:10:53.000Z","updated":"2017-09-23T11:10:15.700Z","comments":true,"path":"2017/08/04/os/","link":"","permalink":"https://www.femn.me/2017/08/04/os/","excerpt":"","text":"import os12345678910111213141516171819202122path = r\"aa/\"path1 = r'bb/'# 如果path路径不加'/'的话,默认是从运行路径再加aaos.getcwd() #'/home/python'# 运行ipython的路径,如果是python3 /home/python/app1.6/runner.py# 则是/home/python/app1.6os.path.abspath(path) # path规范化的绝对路径#'/home/python/aa'os.path.join(os.getcwd(),path,path1)#'/home/python/aa/bb/'os.path.normpath(os.path.join(os.getcwd(),path,path1)) # path规范化的绝对路径#'/home/python/aa/bb'将多个路径组合后返回,第一个绝对路径之前的参数将被忽略os.path.join('/home/python','/','aa','/home/')# '/home/' 判断12345678910111213os.path.exists(path)# 如果path存在,返回True;如果path不存在,返回False.os.path.isabs(os.getcwd()) # 如果只要path是绝对路径,不管是不是存在,返回Trueos.path.isfile(path) os.path.isdir(path)'1.jpg'.endswith('.jpng') # False# 计算此文件的大小 (os.path.getsize(abspath))/1024/1024 # byte/k/M#改变一个文件的文件名os.rename(os.path.join('abspath','filename'), \\ os.path.join('abspath','new_name'))# 如果没有则创建目录,有的话就没原来的,防止os.makedirs('/home/python/1/1/1',exist_ok=True) 分割12345678910111213os.path.splitext(r'/home/python/22.json')#('/home/python/22', '.json')os.path.split('/home/python/app1.6/1.txt')# 将path分割成目录和文件名二元组返回#('/home/python/app1.6', '1.txt')os.path.dirname('/home/python/app1.6/1.txt') # 相当于os.path.split(path)的第一元素#'/home/python/app1.6'os.path.basename('/home/python/app1.6/1.txt') # 相当于os.path.split(path)的第二元素#'1.txt' from urllib.parse import urljoin12urljoin('https://femnyy.com/','VPS/xx') # 第一个路径必须要有最后一个'/'","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"linux防火墙设置","slug":"linux_firewall","date":"2017-08-04T08:10:53.000Z","updated":"2017-09-23T11:10:15.696Z","comments":true,"path":"2017/08/04/linux_firewall/","link":"","permalink":"https://www.femn.me/2017/08/04/linux_firewall/","excerpt":"","text":"以在Ubuntu 16.04上为Docker Swarm配置Linux防火墙为例子介绍 DockerSwarm 是Docker的一项功能,可以很容易地大规模投放Docker窗主机和容器. Docker窗群,或码头集群,该功能是由一个或多个主机Dockerized作为经典的节点,任何数量的工作节点组成.设置这样的系统需要仔细操纵Linux防火墙. Docker Swarm正常工作所需的网络端口有: TCP端口2376进行安全Docker窗客户端通信.此端口是Docker Machine工作所必需的. Docker机器用于编排Docker主机.TCP端口2377 .此端口用于Docker Swarm或群集的节点之间的通信.它只需要在管理器节点上打开.TCP和UDP端口7946的节点之间的通信(容器网络发现).UDP端口4789的覆盖网络通信(容器入口联网).注意:除了这些端口,端口22 (SSH的流量),并在集群上运行需要提供特定服务的其他端口必须是开放. 预前准备 设置组成集群的主机,包括至少一个群集管理器和一个群组工作者.您可以按照教程如何提供和管理远程Docker在Ubuntu 16.04Docker主机设置这些.注意:您会注意到命令(在这篇文章中所有的命令)不能与前缀sudo .这是因为它假设您正在使用的登录到服务器docker-machine ssh使用Docker窗机设置后命令. 在本文中,您将学习如何使用所有Linux发行版上提供的不同防火墙管理应用程序在Ubuntu 16.04上配置Linux防火墙.这些防火墙管理应用程序是FirewallD,IPTables工具和UFW,简单的防火墙. .虽然本教程包含三种方法,每种方法都提供相同的结果,因此您可以选择最熟悉的方法. UFW UFW是Ubuntu发行版上的默认防火墙应用程序,包括Ubuntu 16.04如果你只是设置你的Docker主机,UFW已经安装.您只需要启用和配置它 在将用作Swarm管理器的节点上执行以下命令:123456ufw allow 22/tcpufw allow 2376/tcpufw allow 2377/tcpufw allow 7946/tcpufw allow 7946/udpufw allow 4789/udp 之后,重新加载并启用UFW: 12ufw reloadufw enable 这可能不是必需的,但是在任何时候更改并重新启动防火墙时,都不必重新启动Docker守护程序: 1systemctl restart docker 然后在将用作工作线程的每个节点上,执行以下命令: 12345678ufw allow 22/tcpufw allow 2376/tcpufw allow 7946/tcp ufw allow 7946/udp ufw allow 4789/udp ufw reloadufw enablesystemctl restart docker 关闭防火墙1ufw disable FirewallD FirewallD是Fedora,CentOS和基于它们的其他Linux发行版上的默认防火墙应用程序.但FirewallD也可用于其他Linux发行版,包括Ubuntu 16.04. 如果您选择使用FirewallD而不是UFW,请首先卸载UFW: 123456apt-get purge ufw# 然后安装FirewallD:apt-get install firewalldsystemctl status firewalldsystemctl start firewalldsystemctl enable firewalld # 开机启动 当开机启动时会生成如下文件:1234Created symlink from /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service to /usr/lib/systemd/system/firewalld.service.Created symlink from /etc/systemd/system/basic.target.wants/firewalld.service to /usr/lib/systemd/system/firewalld.service. 在将是Swarm管理器的节点上,使用以下命令打开必要的端口: 1234567firewall-cmd --add-port=22/tcp --permanentfirewall-cmd --add-port=2376/tcp --permanentfirewall-cmd --add-port=2377/tcp --permanentfirewall-cmd --add-port=7946/tcp --permanentfirewall-cmd --add-port=7946/udp --permanentfirewall-cmd --add-port=4789/udp --permanent# firewall-cmd --permanent --add-service=https 注意 :如果你犯了一个错误,需要删除的条目,输入1firewall-cmd --remove-port=port-number/tcp --permanent 重新加载防火墙:1234firewall-cmd --reload# 查看防火墙firewall-cmd --list-allvim /etc/firewalld/zones/public.xml 然后重新启动Docker.1systemctl restart docker 然后在将用作Swarm工作程序的每个节点上,执行以下命令:1234567firewall-cmd --add-port=22/tcp --permanentfirewall-cmd --add-port=2376/tcp --permanentfirewall-cmd --add-port=7946/tcp --permanentfirewall-cmd --add-port=7946/udp --permanentfirewall-cmd --add-port=4789/udp --permanentfirewall-cmd --reloadsystemctl restart docker 关闭防火墙1234systemctl stop firewalldsystemctl disable firewalld# 查看firewall-cmd --zone=public --query-service=ssh IPTables 要在任何Linux发行版上使用IPtables,您必须首先卸载任何其他防火墙实用程序.如果您从FirewallD或UFW切换,请先卸载它们. 12apt-get purge ufw firewalldapt-get install iptables-persistent 接下来,使用此命令清除所有现有规则: 1netfilter-persistent flush 现在,您可以添加使用规则, iptables实用程序.第一组命令应该在将用作Swarm管理器的节点上执行. 1234567891011iptables -A INPUT -p tcp --dport 22 -j ACCEPTiptables -A INPUT -p tcp --dport 2376 -j ACCEPTiptables -A INPUT -p tcp --dport 2377 -j ACCEPTiptables -A INPUT -p tcp --dport 7946 -j ACCEPTiptables -A INPUT -p udp --dport 7946 -j ACCEPTiptables -A INPUT -p udp --dport 4789 -j ACCEPT# 输入所有命令后,将规则保存到磁盘:netfilter-persistent save# 然后重新启动Docker.sudo systemctl restart docker 在将用作Swarm工作程序的节点上,执行以下命令:1234567iptables -A INPUT -p tcp --dport 22 -j ACCEPTiptables -A INPUT -p tcp --dport 2376 -j ACCEPTiptables -A INPUT -p tcp --dport 7946 -j ACCEPTiptables -A INPUT -p udp --dport 7946 -j ACCEPTiptables -A INPUT -p udp --dport 4789 -j ACCEPTnetfilter-persistent savesudo systemctl restart docker 如果您希望在使用此方法后切换到FirewallD或UFW,正确的方法是首先停止防火墙: 123456789sudo netfilter-persistent stop# 然后刷新规则:sudo netfilter-persistent flush# 最后,将现在的空表保存到磁盘:sudo netfilter-persistent save# 然后可以切换到UFW或FirewallD. 查看开启端口 123456# 查看本机的端口开启情况 sudo nmap -sTU localhost# 查看局域网的端口开启情况sudo nmap -PS 192.168.1.222# 查看远程服务器的端口开启情况nc -zv 45.76.0.178 22 22334","categories":[{"name":"linux","slug":"linux","permalink":"https://www.femn.me/categories/linux/"}],"tags":[]},{"title":"basic time","slug":"basic_time","date":"2017-08-04T08:10:53.000Z","updated":"2017-09-23T11:10:15.664Z","comments":true,"path":"2017/08/04/basic_time/","link":"","permalink":"https://www.femn.me/2017/08/04/basic_time/","excerpt":"","text":"from datetime import date,datetime,timedelta datetime类型12345d = datetime.now() datetime.datetime(2017, 6, 2, 17, 22, 5, 470694)datetime(2017,2,3) datetime.datetime(2017, 2, 3, 0, 0)str(d)[:19]d.year d.month (属性,都是int类型)current_day,month_days = calendar.monthrange(2017, 2) (获取某年某月的 当前天数 和 此月共有天) date类型datetime.datetime 会精确到 %H%M%S 而datetime.date 不需要12345678910date_today = date.today()start_date = date(2017,2,6).replace(day=1) # 对应月份第一天的日期 datetime.date(2017, 2, 1) 如果输入是一个 datetime 实例,那么你得到的就是一个 datetime 实例end_date = start_date + timedelta(days=month_days-1) # 第一种获得当月月底的日期 datetime.date(2017, 2, 28)date类型和datetime类型 都可以通过 timedelta 进行前/后几天的计算# 加月份时from dateutil.relativedelta import relativedeltasix_months = date.today() + relativedelta(months=+6) datetime.date(2017, 12, 27)six_months = datetime.now() + relativedelta(months=+6) datetime.datetime(2017, 12, 27, 16, 2, 5, 260990) 时间戳类型 timestamp1time.time() 1483756148.2785556 type:float time tuple类型1time.localtime() time.struct_time(tm_year=2017, tm_mon=1, tm_mday=7, tm_hour=11, tm_min=0, t_m_sec=54, tm_wday=5, tm_yday=7, tm_isdst=0) 转换关系datetime.datetime –&gt; str12s = d.strftime(&apos;%Y-%m-%d %H:%M:%S.%f&apos;) (2017-01-07 10:16:12.962917)s = date_today.strftime(&apos;%Y-%m-%d&apos;) (2017-01-07) datetime.datetime –&gt; time tuple1d.timetuple() str –&gt; datetime.datetime1datetime.strptime(&apos;20170107 10:21:28&apos;,&apos;%Y%m%d %H:%M:%S&apos;) timestamp –&gt; datetime1datetime.fromtimestamp(1483755372.0) str –&gt; time tuple1tuple = time.strptime(&apos;2017-01-07 10:16:12&apos;, &apos;%Y-%m-%d %H:%M:%S&apos;) time tuple –&gt;timestamp1time.mktime(tuple)","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"排序","slug":"basic_sort","date":"2017-08-04T08:10:53.000Z","updated":"2017-09-23T11:10:15.664Z","comments":true,"path":"2017/08/04/basic_sort/","link":"","permalink":"https://www.femn.me/2017/08/04/basic_sort/","excerpt":"","text":"items12d = &#123;'k':1,'x':1&#125;u.items() # ==dict_items([('x', 1), ('k', 1)]) sorted(iterable,key,reverse)sorted函数按key本身的值对字典排序123456789101112131415161718from operator import itemgetterd = &#123;'a':1,'c':3,'d':444,'b':2&#125;# 在签名时挺有用的for k, v in sorted(d.items(),key=lambda x:x[0]): print(k,v)sort_d = sorted(d.items(),key = itemgetter(0),reverse=False)a = &#123;'x': 1,'y': 2,'z': 3&#125;b = &#123;'w': 10,'x': 11,'y': 2&#125;sorted(zip(a.values(),a.keys()))# [(1, 'x'), (2, 'y'), (3, 'z')]max(zip(a.values(),a.keys()))# (3, 'z')min(zip(a.keys(),a.values()))# ('x',1) 对v值的排序 12345678910111213141516171819202122232425262728293031from operator import itemgetterrows = [ &#123;'address': '5412 N CLARK', 'date': '07/01/2012'&#125;, &#123;'address': '5412 NIKE SHIRT', 'date': '07/01/2012'&#125;, &#123;'address': '5148 N CLARK', 'date': '07/04/2012'&#125;, &#123;'address': '5800 E 58TH', 'date': '07/02/2012'&#125;, ]rows.sort(key=itemgetter('date'))rows = sorted(rows,key=itemgetter('date'))rows = sorted(rows, key=lambda x: x.get('date') \\ if x.get('date') else '4000', reverse=False)# 必須提供一個在排序过程中使用的函数,为每个元素创建一个key,然后按这个key来排序a = ['femn','femn2014','fe','femnyy']a.sort(key=len)from itertools import groupby# 按相同时间的值,进行分组for date, items in groupby(rows, key=itemgetter('date')): print(date) for i in items: print(' ', i)# 输出如下 # 07/01/2012# &#123;'address': '5412 N CLARK', 'date': '07/01/2012'&#125;# &#123;'address': '5412 NIKE SHIRT', 'date': '07/01/2012'&#125;# 07/04/2012# &#123;'address': '5148 N CLARK', 'date': '07/04/2012'&#125;# 07/02/2012# &#123;'address': '5800 E 58TH', 'date': '07/02/2012'&#125; join如果你想要合并的字符串是在一个序列或者 iterable 中,那么最快的方式就是使用 join() 方法 123data = ['ACME', 50, 91.1]','.join(str(d) for d in data) # 'ACME,50,91.1'(str(d) for d in data) #是一个 generator random1234567891011121314151617import random,stringv = [1, 2, 3, 4, 5, 6] # 一个序列或者 iterable # 随机选择一个,且只能是选一个random.choice(v)# 随机提取N个,保证不重复出现,并且N不能超过v的长度random.sample(v,3)# 只是想打乱序列中的顺序random.shuffle(v) # 此时v值的顺序已经被改变# 生成一个随机的整数random.randint(0,10)''.join(random.choice(string.ascii_letters + string.digits) for _ in range(32))''.join([random.choice(string.ascii_letters+string.digits) for _ in range(43)])''.join(random.sample(string.ascii_letters+string.digits, 15))","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"pip管理工具","slug":"pip管理","date":"2017-08-04T08:10:53.000Z","updated":"2017-09-23T11:10:15.700Z","comments":true,"path":"2017/08/04/pip管理/","link":"","permalink":"https://www.femn.me/2017/08/04/pip管理/","excerpt":"","text":"分别使用不同python版本 进行安装应用install pip 以及普通用户安装包的路径1234sudo apt install -y python-pipwhich pippython2.7 -m pip install tornado~/.local/lib/python2.7/site-packages/tornado install pip3 以及普通用户安装包的路径1234sudo apt install -y python3-pipwhich pip3python3.5 -m pip install bson~/.local/lib/python3.5/site-packages/bson root用户安装包之后的路径12sudo python3.5 -m pip install tornado/usr/local/lib/python3.5/dist-packages/tornado 更新pip123sudo python2.7 -m pip install -U pipsudo pip3 install -U pip# sudo pip install -U pip 更新的还是pip3 一键导出/安装所有安装包列表12sudo pip3 freeze &gt; requirements.txtsudo pip3 install -U -r requirements.txt","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"Shell基本","slug":"shell","date":"2017-08-04T08:10:53.000Z","updated":"2017-09-23T11:10:15.712Z","comments":true,"path":"2017/08/04/shell/","link":"","permalink":"https://www.femn.me/2017/08/04/shell/","excerpt":"","text":"shell:是一种命令解释器还是一种编程语言(shell脚本,shell编程),擅长处理文本类型的数据,所以Shell脚本在管理Linux系统中发挥了巨大作用备份文件、安装软件、下载数据之类的事情,学着使用sh,bash会是一个好主意. 123456#!/bin/bash# \"#!\"是一个约定的标记,它告诉系统这个脚本需要什么解释器来执行# shell脚本会被分解成一行一行的依次执行.# bash shell会将空格,制表符,换行符当作字段分隔符IFS=$'\\n' # 只识别换行符IFS=$'\\n:;\"' # 将换行,冒号,分号和双引号作为字段分隔符 脚本文件没有可执行权限时1sh test.sh 脚本有可执行权限123456789./test.sh# 注意,一定要写成./test.sh,而不是test.sh,运行其它二进制的程序也一样,# 直接写test.sh,linux系统会去PATH里寻找有没有叫test.sh的,# 而只有/bin, /sbin, /usr/bin,/usr/sbin等在PATH里,你的当前目录通常不在PATH里# 所以写成test.sh是会找不到命令的,要用./test.sh告诉系统说,就在当前目录找source 或. # 命令执行与上面执行不同,上面执行 shell 都会分配一个子进程来进行# source 或. 命令就在本进程执行,也就是说一些非环境变量也能读取到 重定向输入和输出:将某个命令的输出重定向到另一个位置(文件,或者命令)命令行的数据流定义:STDIN(0),STDOUT(1),STDERR(2),用来管理SHELL中的信息流的分流. 重定向输出:将命令的输出发到一个文件中12345STDOUT: &gt;(覆盖) &gt;&gt;(追加) 重定向到文件STDERR: 2&gt;STDOUT STDERR: 2&gt;&amp;1 ehco \"alias ll='ls -alF'\" &gt;&gt; test.txtdate &gt; test.txt 重定向输入:将文件的内容重定向到命令中123grep femn &lt; /etc/passwd grep femn &lt; /etc/passwdecho `grep femn &lt; /etc/passwd` 管道命令:将一个集合的输出做会一个命令的输入 STDOUT,STDERR | STDIN1rpm -qa | sort | more 生成已安装包的列表,经过管理排序,再经过管理传给More命令显示 Shell基本类型赋值与引用:脚本编程中的一个主要构件 反引号 ( `` ) 它允许你将shell命令的输出赋给变量12345testing=`date +%y%m%d` #你必须用把整个命令行命令圈起来 $HOME $&#123;HOME&#125;echo # -n 在同一行显示一个文本字符串作为命令输出.echo -e \"OK! \\n\" # -e 开启转义/$15 # 转义符 变量类型只能为Int,str,数组,而且等于两边不能有空格数字在将一个数学运算结果赋值给一个变量时,你可以用美元符和方括号将数字表达式圈起来12$[option]$(()) 注意只支持整数运算123var=1 var1=$[2 * 5]var1=$(($var*5)) 字符串12345678910111213141516171819202122232425262728var=femngreeting=\"hello, $&#123;var&#125; !\" var=\"my name\"echo $&#123;#var&#125; #获取字符串长度echo $&#123;var:1:4&#125; #字符串分片if [-z str 为0 ] # -z 字符串的长度为零则为真,退出状态为0.if [-n str 非0]# -n str 字符串的长度不为零则为真var=http://www.aaa.com/123.htm 1. # 号截取,删除左边字符,保留右边字符.echo $&#123;var#*//&#125; # www.aaa.com/123.htm 2. ## 号截取,删除左边字符,保留右边字符echo $&#123;var##*/&#125; # 123.htm 3. %号截取,删除右边字符,保留左边字符echo $&#123;var%/*&#125; # http://www.aaa.com4. %% 号截取,删除右边字符,保留左边字符echo $&#123;var%%/*&#125; # http:5. 从左边第几个字符开始,及字符的个数echo $&#123;var:0:5&#125; # http: 6. 从左边第几个字符开始,一直到结束echo $&#123;var:7&#125; # www.aaa.com/123.htm7. 从右边第几个字符开始,及字符的个数echo $&#123;var:0-7:3&#125; # 1238. 从右边第几个字符开始,一直到结束echo $&#123;var:0-7&#125; #123.htm 数组1234list=(1 2 3 4)echo $&#123;list[0]&#125; # echo $&#123;list[@]&#125; #获取数组中所有的元素echo $&#123;#list[@]&#125; # 计算数组个数 shell语法结构化命令允许你改变程序执行的顺序,在某些条件下执行一些命令而在其它条件下跳过另一些命令.if-then语句,只能测试跟命令的退出状态码有关的条件.1234567891011121314151617181920212223241.if command:then commands fi # 使用一行,多用于终端if [ $(ps -ef | grep -c \"ssh\") -gt 1 ]; then echo \"true\"; fi # 如果else分支没有语句执行,就不要写这个else.2.if command1then commandselse commandsfi# 使用一行,多用于终端if [ $(ps -ef | grep -c \"ssh\") -gt 1 ]; then echo \"true\"; \\ else echo 'false'; fi 3.if command1 then commands elif command2 then commands fi case命令,替代elif语句来不断检查相同变量值.case命令提供了一个更清晰的方法来为变量每个可以的值指定不同的选项.12345678case $USER infemn | pattern2 ) commands1;;parrent3) commands2;;*) commands;;esac test命令会将所有的标点和大小写也考虑在内在其它编程语言中,if语句之后的对象是一个等式来测试是 true or false .bash shell并不是这样工作的. 当command1命令退出状态码是0,位于then部分的命令就会被执行.如果是非0则执行else命令块.test命令提供了在if-then语句中测试不同条件的途径.test命令格式:test condition(要测试的一系列参数和值)1234567# test condition==[ condition ] # 你必须在左括号右侧和右括号左侧各加一个空格,否则会报错.if test $&#123;num1&#125; -eq $&#123;num2&#125;if [ $&#123;num1&#125; -eq $&#123;num2&#125; ]# 复合条件测试[ condition1 ] &amp;&amp; [ condition2 ] || test可以判断3类条件:1.数值比较,2.字符串比较,3.文件比较数值比较:123456-gt: 大于(-g)-lt: 小于(-l)-eq: 等于(-e)-ne: 不等于-ge: 大于等于 -le: 小于等于 bash shell能处理的数仅有整数.使用bash计算器时,你可以让shell将浮点值作为字符串值存储进一个变量,如果你只是要通过echo语句来显示这个结果,那它能很好地工作,便它无法在基于数字的函数中工作. 字符串比较:123456&lt;&gt;=!=-z-n 字符串顺序:要测试一个字符串要比另一个字符串大就开始变得烦琐了,大于小于符号必须转义,否则shell会把它们当做重写向符号而把字符串值当做文件名.而且大于小于顺序和sort命令所采用的不同.test命令中大写字母会被当成小于小写字母.if [Test \\&lt; test] 文件比较:1234567891011121314# 检查new.sh文件是否比old.sh新,在此之前要先确认文件是否存在.if [ ./new.sh -nt ./old.sh ] if [ ./old.sh -ot ./new.sh ] #if [ -e $HOME ] #检查文件是否存在 下面的所有检查都要满足这个前提条件if [ -d $HOME ] # 检查文件是否存在并是个目录if [ -f $HOME/.vimrc ] # 并是个文件if [ ! -f $HOME/.vimrc ] # 如果不是文件则执行if [ -r $HOME ] # 并是可读if [ -w $HOME/.vimrc ] # 并是可写if [ -x $HOME/.vimrc ] # 并是可执行if [ -O $HOME/.vimrc ] # 并是 属于当前用户所有if [ -s $HOME/.vimrc ] # 并是不为空,说明有数据,删除时就小心了. if-then的高级特征: 双圆括号命令允许你将高级数学表达式放入比较中1(( expression )) test命令只允许在比较中进行简单的算术操作.双圆括号命令提供了更多的为用过其它编程语言的程序员所熟悉的数学符号.你不需要将圆括号中表达式里的大于号转义,这是双圆括号命令提供的另一个高级特性. 用于高级字符串处理功能的双方括号. [[ expression ]]1234if (( $var1 ** 2 &gt; 90 )) || [[ $USER == f* ]]# 幂运算之后比较大小# 匹配$USER是否以f字母开头# 模式匹配中,你可以定义一个正则表达式来匹配字符串值. 循环中定义的test命令和if-then语句中定义的是一样的格式.你需要重复一组命令直到达到某个特定条件.for, while, untilfor循环假定每个值都是用空格分割的123456789for var in listdo commandsdonefor file in `ls /etc`for loop in 1 2 3 4 5for var in item1 item2 ... itemN; do command1; command2… done;for test in I don\\'t know if \"this'll \" work 用通配符读取目录:你可以你for命令来自动遍历满是文件的目录.进行操作时,你必须在文件名或路径名使用通配符.它会强制shell命令使用文件扩展匹配(file globbing):它是生成匹配指定的通配符的文件名或路径外的过程.12345678910111213for file in $HOME/*do if [-d \"$file\"] # 为了解决含有空格的目录名或文件名,将$file变量用双引号圈起来 then echo \"$file is a directory\" elif [-f \"$file\"] then echo \"$file is a file\" else echo \"$file is doesn't exist\" fidone C语言的for命令:通常会定义一个变量,然后这个变量会在每次迭代时自动改变.程序员会将这个变量当作计数器,并在每次迭代中让计数器增一或减一.这是bash中C语言风格的for循环的基本格式:for((variable assignment;condition;iteration process))1234567891011for (i=0;i&lt;10;i++)&#123; print(\"the next number is %d\\n\",i)&#125;for ((a=1,b=10;a&lt;10;a++,b--))do echo \"$a - $b\"done # 使用多个变量时,循环会单独处理每个变量,# 允许你为每个变量定义不同的迭代过程,但只能定义一种条件. whilewhile命令在某种意义上是if-then语句和for循环的混杂体.它会在每个迭代的一开始测试test命令.只有测试条件成立,while命令才会继续遍历执行定义好的命令.123456789101112while test command do other commanddone#!/bin/bashint=1while(( $int&lt;=5 ))do echo $int let \"int++\"done )) break终止执行后面的所有循环continue命令类似,只有一点差别,它不会跳出所有循环,仅仅跳出当前循环 until命令和while命令工作的方式完全相反测试条件中用到的变量必须被修改,否则会进入一个无限循环.嵌套循环nested loop:可以在循环内使用任何类型的命令,自然也包括其它循环命令.在使用nested loop时,你是在迭代中使用迭代,命令运行的次数是乘积关系.内部循环会有外部循环的每次迭代中遍历一遍它所有的值.以两个for命令写个nested loop shell变量bash shell提供了不同的方法从用户处获得数据,包括命令行参数,命令行选项以及直接从键盘读取输入的能力. 命令行参数(添加在命令后的数据值) $?专属变量来保存上个执行命令的退出状态码(0:命令成功结束,126:没有执行权限,1:无效参数等通用未知错误) $1-$9 第一到第九个命令行参数 ${10} # 第十个命令行参数的读取方式 当传给$0变量的真实字符串是整个脚本路径时,程序中就会使用整个路径,而不仅仅是程序名.12345678910111213141516171819202122vim tesh.sh #!/bin/bash name=`basename $0` # basename命令仅仅会返回程序名 echo the command entered is $name echo the command entered is $0sh ./test.sh # the command entered is test.sh# the command entered is ./test.shsh ~/test.sh # the command entered is test.sh# the command entered is /home/femn/test.sh# 检查命令行参数中是否有数据,有的话就执行then语句if [ -n \"$1\" ] # 所有命令行参数的个数 if [ $# -ne 2 ]# $*和$@变量提供了对所有参数的快速访问# $*变量将会把所有参数当成单个参数for param in \"$*\"# $@变量会单独处理每个参数for param in \"$@\" shell 命令bash shell工具链中另一个工具是shift命令.bash shell提供了shell命令来帮助操作命令行参数.默认情况下,shell命令会将参数变量减一,所以变量$2会移到$1,而变量$1的值会被删除并且无法恢复变量$0是程序名不会改变.这是遍历命令行参数的另一个绝妙方法,尤其是你不知道有多少参数时.1234567891011121314vim test1.sh #!/bin/bash # demonstration the shift command count=1 while [ -n \"$1\" ] do echo \"Parameter #$count = $1\" count=$(( $count+1 )) shift donesh ./test1.sh femn leipengkai yuyu# Parameter #1 = femn# Parameter #2 = leipengkai# Parameter #3 = yuyu 命令行选项(是跟在单破折线后面的单个字母,可以修改命令行为的单字母值)当脚本看到”–” ,脚本会安全地将剩下的命令行参数当做参数来处理而不是选项.你可以像处理命令行参数一样处理命令行选项你经常遇到想在脚本中同时使用选项和参数的情况.Linux处理这个问题的标准方式是用特殊的字符将二者分开,该字符(–双破折线)会告诉脚本选项何时结束,以及普通参数何时开始. getopt命令1234567891011121314151617181920212223242526272829303132333435363738394041getopt -q ab:cd -a -b test1 -cde test2 test3# 用getopt 命令生成的格式化后的版本来替换已有的命令行选项和参数# -a -b 'test1' -c -d -- 'test2' 'test3'vim test2.sh #!/bin/bash # extraction command line options and values. while [ -n \"$1\" ] do case \"$1\" in -a) echo \"Found the -a options\";; -b) param=\"$2\" echo \"Found the -b options,with parameter value $param\" shift;; -c) echo \"Found the -c options\";; --) shift break;; *) echo \"$1 is not an optionso\";; esac shift done count=1 for param in \"$@\" do echo \"Parameter #$count: $param\" count=$(( $count +1 )) donesh ./test2.sh -b test2 -a -d # Found the -b options,with parameter value test2# Found the -a options# -d is not an optionsosh ./test2.sh -b test2 -a -b # Found the -b options,with parameter value test2# Found the -a options# Found the -b options,with parameter value # ./test2.sh: 18: shift: can't shift that many 你可以在脚本中使用getopt命令来格式化输入脚本的任何命令行选项和参数,但用起来略微复杂. 1set -- `getopt -q ab:cd \"$@\" ` options parameters用\"$@\" 该方法将原本的脚本的命令行参数传给getopt命令,之后再将getopt的输出传给set命令,用getopt命令格式化后的命令行参数来替换原始命令行参数. set 命令的选项之一是双破折线,它会将命令行参数替换成set命令的命令行的值. 12345678910111213sh ./test2.sh -ac # 合并选项 增加下面这句 set -- `getopt -q ab:c \"$@\"` while [ -n \"$1\" ]# Found the -a options# Found the -c optionssh ./test2.sh -a -b test1 -cd test2 test3# Found the -a options# Found the -b options,with parameter value 'test1'# Found the -c options# Parameter #1: 'test2'# Parameter #2: 'test3' 但getopt命令并不擅长处理带空格的参数值,它会将空格当做参数分隔符,而不是根据双引号将二者当作一个参数. getopts命令扩展了getopt命令的功能:getopts optstring variable 与getopt命令将命令行上找到的选项和参数处理后只生成一个输出不同,getopts命令能够和已有的shell参数变量对应地顺序工作. getopts命令将当前参数保存在命令行中定义的variable中.它会用到两个环境变量,如果选项需要参数值,OPTARG环境变量就会保存这个值.OPTIND环境变量保存了参数列表中getopts正在处理的参数位置. 获得用户输入你想在运行脚本时,问一个问题,并等运行脚本的人来回答.bash shell为此提供了read命令.read命令接受从标准输入(键盘)或另一个文件描述符的输入.echo -n -n会移除字符串末尾的换行符,允许脚本用户紧跟其后输入数据,而不是下一行read -n1 -t 5 -p 接受单个字符后退出而不必回车,超时,直接在read命令行提示符read -s隐藏方式读取,实际上数据会被显示,只是read命令会将文本颜色设成跟背景色一样. 123456vim test.sh #!/bin/bash# echo -n \"ENter your name:\"# read name read -p \"ENter your name:\" nameecho \"Hello $name, Welcome\" 从文件中读取.每次调用read命令会从文件中读取一行文本,当文件没能内容时,read命令会退出并返回一个非零的状态码.最常见的方法是将文件通过cat命令后的输出通过管道直接传给含有read命令的while命令.cat test |while read line","categories":[{"name":"shell","slug":"shell","permalink":"https://www.femn.me/categories/shell/"}],"tags":[]},{"title":"套接字(SOCKET)","slug":"basic_socket","date":"2017-08-04T08:10:53.000Z","updated":"2017-09-23T11:10:15.660Z","comments":true,"path":"2017/08/04/basic_socket/","link":"","permalink":"https://www.femn.me/2017/08/04/basic_socket/","excerpt":"","text":"socket套接字.是一种通信机制,用于描述IP地址和端口,是一个通信链的句柄.操作socket就像操作Unix一样,一切皆是文件,. 0.0.0.0有多少个网卡,都可以连接到本机.程序之间进行内存数据交换(通信)比较麻烦:每个程序的内存空间都是被保护的,不能被别的程序直接访问,所以要通过某种介质,管道或第三方工具,去通信.nosql(第三方):将内存的数据缓存进来,供其它的程序调用,所有的程序都可以往里存数据,所有的程序都可以取数据.相当于实现了一个共享的内存空间.socket.AF_UNIX;只能够用于单一的Unix系统进程间通信socket.AF_INET:服务器之间网络通信socket.AF_INET6 IPv6 socket 4层 ICMP 3层socket通信的数据格式socket.SOCK_STREAM :PCP三次握手socket.SOCKDGRAM:UDPsocket.SOCK_RAW 原始套接字 可以处理普通套接字不能处理的ICMP,IGMP等网络报文 可以可以伪造IP server123456789101112131415161718192021222324252627282930313233from socket import *#IP协议(socket type) TCP协议(数据包格式)socketobj = socket(AF_INET,SOCK_STREAM)# 生成对象socketobj.bind(('localhost',8080)) #绑定IP和端口socketobj.listen(128)# 监听连接数量# 1#客户端实例,客户端地址# connection,address=socketobj.accept()# 每个客户端一连接就会返回的结果# 但只能连接一个客户端,只有当前客户端下线,下个客户端才能连上# A,B客户端都运行 但A先连接 B后连接 B处于阻塞状态,没有生成connection # A断开之后,因为只有一个connection,所以执行了 socketobj.close(),# 服务也跟着断了 B不会自动连上while True: # 2 connection,address=socketobj.accept() # 多用户连接时 生成了对应的多个connection # 只是当A断开之后,B自动连上,但每个客户端只能访问一次之后 # 访问一次后 重新循环 重新一次新的连接 # 而上次的connection就被 服务器给挂起了 print('connect by ', address) # 3 # while True: # 当多用户连接时 生成了对应的多个connection # 只是当A断开之后,B自动连上,B可以随便聊 data = connection.recv(1024) #服务器只接收1024个字节 print('server端收到client端的信息:'+ str(data,encoding = \"utf-8\")) connection.sendall(bytes(\"hello client\",\"utf-8\")) #服务器返回给客户的信息socketobj.close() client123456789101112from socket import *socketobj = socket(AF_INET,SOCK_STREAM)# socketobj.connect(('localhost',8080)) #绑定 阻塞的socketobj.connect(('localhost',20000)) #asywhile True: user_input =input(\"msg to server:\").strip() socketobj.send(bytes(user_input,'utf-8'))#socketobj.sendall(bytes(\"hello server\", 'utf-8')) data = socketobj.recv(1024) print(\"client端收到server端的信息 :\"+str(data,encoding = \"utf-8\"))socketobj.close() asy_server参考123456789101112131415161718192021from socketserver import BaseRequestHandler, TCPServer, ThreadingTCPServerimport os# socketserver 可以让我们很容易的创建简单的TCP服务器,# 巨大部分Python的高层网络模块(比如HTTP,XML-RPC等)都是建立在socketserver功能之上class EchoHandler(BaseRequestHandler): def handle(self):#每个连接就会 调用此方法 print('Got connection from', self.client_address) while True: # 循环去监听用户的连接,否则只能像单进程的阻塞一样,只能连接一个用户 msg = self.request.recv(8192) if not msg:#如果用户退出,没有这句的话 就变成死循环 print('connection close by', self.client_address) break print(msg) # self.request.send(str(msg,encoding = \"utf-8\")) self.request.send(msg)if __name__ == '__main__': # serv = TCPServer(('', 20000), EchoHandler)#单个线程 serv = ThreadingTCPServer(('0.0.0.0', 20000), EchoHandler) serv.serve_forever()","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"推导式(Derivation)","slug":"basic_derivation","date":"2017-08-04T08:10:53.000Z","updated":"2017-09-23T11:10:15.660Z","comments":true,"path":"2017/08/04/basic_derivation/","link":"","permalink":"https://www.femn.me/2017/08/04/basic_derivation/","excerpt":"","text":"list derivation(列表推导式)1234567891011121314151617181920212223242526272829303132l = [x*x for x in range(5)]# [0, 1, 4, 9, 16] 直接返回列表而不是生成器[i+1 if i&gt;0 else 1 for i in l]# [1, 2, 5, 10, 17][i+1 if i&gt;0 else 2 for i in l]# [2, 2, 5, 10, 17] # 说明 如果是取else的话,就不再去做更新的操作[i for i in l if i &gt;4 and i &lt;=16] # [9,16]vec = [[1,2,3], [4,5,6], [7,8,9]][num for elem in vec for num in elem]# [1, 2, 3, 4, 5, 6, 7, 8, 9][(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]# [(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]``` 改变字典的值```python l_d = [&#123;'name':'femn','age':25&#125;,&#123;'name':'femnyy','age':35&#125;][i if i.get('age')&gt; 25 else i for i in l_d]# 虽然此时不能得到自己想要的改变 不能用i['name']='femnhh'去做改变[i.update(&#123;'name':'femnhh'&#125;) if i.get('age')&gt; 25 else i for i in l_d]# [&#123;'age': 25, 'name': 'femn'&#125;, None] # 相当于是匹配没有匹配成功则返回None# 但此时l_d却已经是改变成想要的了l_d# [&#123;'age': 25, 'name': 'femn'&#125;, &#123;'age': 35, 'name': 'femnhh'&#125;] generator derivation(生成器推导式)12g = (x*x for x in range(5)) # 'generator' objectnext(g) # dict derivation (字典推导式)1234prices = &#123;'ACME': 45.23,'AAPL': 612.78,'IBM': 205.55,\\ 'HPQ': 37.20,'FB': 10.75&#125;p1 = &#123;key: value for key, value in prices.items() if value &gt; 20&#125;# &#123;'ACME': 45.23, 'IBM': 205.55, 'HPQ': 37.2, 'AAPL': 612.78&#125;","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"WebSocket","slug":"WebSocket","date":"2017-08-04T08:10:53.000Z","updated":"2017-09-23T11:10:15.716Z","comments":true,"path":"2017/08/04/WebSocket/","link":"","permalink":"https://www.femn.me/2017/08/04/WebSocket/","excerpt":"","text":"网页的消息推送一般常见的实现方法有轮询,长连接,WebSocket. 为什么要用 WebSockets？一个 WebSocket 连接允许在客户端和服务端之间进行全双工通讯,从而每一端都可以通过建立的连接向另一端推送数据. WebSocket,以及与其相关的 服务端发送事件 (SSE) 及 WebRTC 数据通路 等技术之所以重要的原因是:HTTP不能打开并一直保持连接,不能在服务端和 Web 浏览器之间进行频繁的数据推送.在这之前,大多数的 Web 应用会通过频繁的异步 JavaScript 和 XML (AJAX) 请求来实现长轮循 WebSocket并不限于以Ajax(或XHR)方式通信,因为Ajax技术需要客户端发起请求,而WebSocket服务器和客户端可以彼此相互推送信息;XHR受到域的限制,而WebSocket允许跨域通信. 实现 WebSocketWeb 浏览器和服务端都必须要实现 WebSocket 协议,以便建立和维护连接.因为 WebSocket 的连接是持续连通的,不像经典的 HTTP 连接,因此服务器需要做更多工作. 基于多线程或多进程的服务器不能很好地提供 WebSockets 服务,因为它们的设计是:打开一个连接,尽快处理完请求,然后关闭连接.因此,采用 Tornado 或 打包了 gevent 的 Green Unicorn 等异步服务器,对于实现一个实用的服务端 WebSockets 都是必要的 而在客户端,使用 WebSocket 并不要求有某个 JavaScript 库.实现了 WebSocket 的 Web 浏览器都会通过 WebSockets 对象 导出所有必要的客户端功能. github中的例子 对这个例子的的解释 Websocket资源","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"字符","slug":"character_and_encode","date":"2017-08-04T08:10:52.000Z","updated":"2017-09-23T11:10:15.664Z","comments":true,"path":"2017/08/04/character_and_encode/","link":"","permalink":"https://www.femn.me/2017/08/04/character_and_encode/","excerpt":"","text":"信息的存储单位:位(bit)–&gt;字节(Byte=8bit,已经可以表示所有的英语符号)–&gt;字符(char=2Byte) 1K =1024byte 1M = 1024K G T P 字节是电脑最小的处理单元 一个字节:0x01 字符:也是一个信息单位,它是各种文字和符号的总称.比如人类 各国看得懂的文字,符号,图形符号,数字. 字符编码:是指对于字符集中的字符,将其编码为特定的二进制数,以便计算机处理. 解码:将计算机处理后的二进制信息,转换成人类看得懂的字符. 字符集和字符编码往往被认为是同文义的概念.ASCII字符编码既表示了字符集也表示了的对应的字符编码. ASCII字符集:共有128个字符(美国,本身只需要一个字节),包含显示字符(英文大小写,阿拉伯数字)和控制字符(回车,空格键) GB2312字符集:中国标准的简体中文字符集,其中还有一个中国的GBK字符集 Unicode字符集:世界各国语言中使用到的所有字符.用了4个字节,2个字符.汉字’严’的Unicode编码是十六进制数4E25,转化成二进制有15位 UTF-8:是一种针对Unicode的可变长度字符编码,它使用一到四个字节来表示字符.ASCII字符继续用一个字节表示.中文可能用到4个字节. 先来一个关于简单的ASCII字符集,解码和编码的例子12345678910111213a = 12b = oct(a)print(b) #0o14 # 为了将整数转换为二进制,八进制或十六进制的文本串,可以分别使用bin(),oct()或hex()# 如果你不想输出0b,0o或者0x的前缀的话# 可以使用format()函数.比如:format(x, 'b') 'o' 'x'# 编码 虽然没有用encode()方法print([n for n in b'ahello'])#[97, 104, 101, 108, 108, 111]# 索引和迭代动作返回的是字节的值而不是字节字符串# 编码与解码 print([int(n).to_bytes(1,'big').decode('utf-8') for n in b'ahello'])# 成功 所以说再次证明 电脑最小的操作单位是字节 ,而不是字节的值这是人看得懂的# ['a', 'h', 'e', 'l', 'l', 'o'] 中文字符集的例子 1234567891011121314151617181920212223242526272829print(sys.getdefaultencoding())#utf-8c ='严'.encode('utf-8')#b'\\xe4\\xb8\\xa5'print(b'\\xe4\\xb8\\xa5'[0])#228print(len(c))# 3个字节print(c.decode())# 严# 字节的低位高位排列方式 big从低到高 little从高到低from idna import unicodeunicode(b'\\xe4\\xb8\\xa5','utf-8')# 解码# 多个字节的解码转换出来的 数字不太理解 虽然也是十进制的print(int().from_bytes(c, 'little')) #10860772# 将字节byte转换为整数 并指定字节顺序print(int().from_bytes(c, 'big')) # 14989477print('--------------------') # 14989477# 编码print(int(10860772).to_bytes(3, 'little'))# b'\\xe4\\xb8\\xa5'print(int(14989477).to_bytes(3, 'big').decode('utf-8'))# b'\\xe4\\xb8\\xa5'# 为了将一个大整数转换为一个字节字符串,使用 int.to_bytes() 方法# 并像下面这样指定字节数和字节顺序print(int(14989477).to_bytes(3, 'big'))# b'\\xe4\\xb8\\xa5'print(int(14989477).to_bytes(8, 'big'))# b'\\x00\\x00\\x00\\x00\\x00\\xe4\\xb8\\xa5' u’’ –&gt; str12s = '\\u6211's = s.encode('utf-8').strip().decode()","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"序列(sequence)","slug":"basic_sequence","date":"2017-08-04T08:10:51.000Z","updated":"2017-09-23T11:10:15.660Z","comments":true,"path":"2017/08/04/basic_sequence/","link":"","permalink":"https://www.femn.me/2017/08/04/basic_sequence/","excerpt":"","text":"在Python中,最基本的数据结构就是序列(sequence).序列中的每个元素都会分配一个序号即元素的位置也称为索引.序列的第一索引是0,最后一个是-1. 序列有6种内建的序列.最常用的是元组(不可以改),列表(可以修改)和字符串,还有Unicode字符串,buffer对象,xrange对象.内建函数会返回元组,它与Python内部的动作方式有关,几乎在所有的情况下都可以用列表替代元组.例外的情况是:使用元组作为字典的键. 通用的序列操作所有序列类型都可以进行某些特定的操作:索引(indexing),分片(slicing),加(adding两种相同的类型的序列才能进行连接操作),乘(multiplying),以及检查某个元素是否属于序列成员(成员资格) in,除此之处,Python还有计算序列长度len(),找出最大元素max()和最小元素min()的内建函数以及迭代(iterator) l = list(‘hello’) [‘h’,’e’,’l’,’l’,’o’]list函数适用于所有类型的序列,而不仅仅是字符串.list()为内建函数. x=[31,5,7,8]y=sorted(x),这个函数实际上可以用于任何序列,任何可迭代对象,却总是返回一个列表. sorted(‘Python’)12345678910111213# 分片操作第二个索引不包含在分片内numbers = [1,2,3,4,5,6,7,8,9,10]number[-3: ] # 8-10number[:3] # 1-3number[:] # 取所有# 步长numbers[0:10:2]numbers[::4] # 步长不能为 0,但是可以为负数,如numbers[8:3:-1] # 得到[9, 8, 7, 6, 5]numbers[10:0:-2] # 得到[10, 8, 6, 4, 2]number[::-2] # 得到[10, 8, 6, 4, 2]number[5::-2] # 得到[6, 4, 2]number[:5:-2] # 得到 [10, 8] 基本的列表操作(list)元素赋值(不能超过索引进行赋值):是替换而不是累加 1l[4]= 1 删除元素 1234567891011del l[4]remove('h')# 用于移除列表中某个值的第一个匹配元素.pop()# 会移除列表中的一个元素(默认是最后 一个)并返回该元素的值.# 后进先出(LIFO)唯一个修改了列表以返回元素值的列表方法.(出栈)l[1:5] = []['h', 'e', 'l', 'l'] 追加元素 123456789101112insert(索引位置,要插入的对象) # 将对象插入到列表中,(累加)l.insert(4,'four')l.append(5)# 在列表末尾追加新的对象,它不是简单的返回一个修改过的新列表,# 而是直接修改的原来的列表.(入栈)l.extend()# 可用新的列表来扩展原有的列表,只是修改(扩展)了原有的列表.# 而原始的连接操作(+),则会返回一个新的列表.l.extend(list('o femn')) 分片赋值12l[1:1] = list('femn')['h', 'f', 'e', 'm', 'n', 'e', 'l', 'l'] l.count(‘h’):统计某元素在列表中出现的次数. l.index(‘h’):用于列表中找出某个元素在列表中第一个匹配的索引位置. l.reverse():将列表元素反向存放,它返回的是一个迭代器(iterator)对象. sort():在原位置对列表进行排序.在”原位置排序”意味着改变原来的列表,从而让其中的元素按一定的顺序排列,而不是简单地返回一个已经排序的列表副本. 12y=x[:] # y=x 错误,这样会让x,y都指向同一个列表.y.sort() 元组:不可变序列(字符串也是不能修改)元组通过圆括号 括起来的.如果你用逗号分隔了一些值,那么你就自动创建的元组.tuple([1,2,3]):以一个序列作为参数并把它转换为元组.tuple并不是真正的函数,而是一种类型. 字典dict()像list,tuple,str一样,不是真正的函数,都只是类型.这些方法如果都不带参数,返回的都是对应的空字典,列表,元组,字符串. 创建字典 12345678910d = dict(host='1',name = 'femn')d = dict([('name','femn'),('age',18)])u = dict(&#123;'love':'sport'&#125;,**d) for l in d.items() # 将字典中所有项以列表的方式返回,但返回时并没有特定的次序(dict_items)for k,v in d.items()d.iteritmes() # 返回的是一个迭代器对象,而不是列表.d.keys()# 将字典中所有的K(dict_keys),以列表形式返回d.values() (dict_values)d.iterkeys() # 返回针对键的迭代器 d.itervalues() 典的基本操作 1len(d) # 键值对的数量 到V 12d['name'] # 返回k对应的vd.get('name','femn') 修改V 1d['name'] = 'femnyy' 删除 K-V 123del d['name'] # 删除K为name的那一个项d.pop('name') # 用来取得给定K的V,并将K-V移除.d.clear() # 清除字典中所有的项 更新 1234567d[x] = y # 若键x存在,则修改x对应的值为y,若键x不存在,则在字典d中增加键值对x:y# 利用一个字典项更新另一个字典d1.update(d) # 将字典x所有键值对添加到字典d中(不重复,重复的键值对用字典x中的键值对替代字典d中)# update可以使用与调用dict函数(或者类型构造函数)同样的方式进行调用# 这意味着update可以和映射,拥有键值对的队列(或者其它可迭代对象)以及关键字参数一起调用. K in d # 检查d中是否含有键为K的项. v in l:# 查找列表的值,而不索引1d.has_key('name') # 返回True 或 False 键视图的一个很少被了解的特性就是它们也支持集合操作,比如集合并、交、差运算123456a = &#123;'x': 1,'y': 2,'z': 3&#125;b = &#123;'w': 10,'x': 11,'y': 2&#125;a.keys() &amp; b.keys() # &#123;'x', 'y'&#125;a.keys() - b.keys() # &#123;'z'&#125;a.items() &amp; b.items() # &#123;('y', 2)&#125;&#123;key: a[key] for key in a.keys() - ['z', 'w']&#125; # &#123;'y': 2, 'x': 1&#125; dict copycopy 拷贝返回一个相同的字典,此处是 Java 中的浅拷贝共用对象的引用,独立的基本类型的引用1234567x = &#123;'username':'admin', 'machines':['foo', 'bar', 'baz']&#125;y = x.copy()y['username'] = 'mlh'y # &#123;'machines': ['foo', 'bar', 'baz'], 'username': 'mlh'&#125;y['machines'].remove('bar')y # &#123;'machines': ['foo', 'baz'], 'username': 'mlh'&#125;x # &#123;'machines': ['foo', 'baz'], 'username': 'admin'&#125; deepcopy 是深拷贝,有自己独立的存储空间12345678from copy import deepcopyd=&#123;&#125;d['names'] = ['Alfred', 'Bertrand']c = d.copy()dc = deepcopy(d)d['names'].append('Clive')c # &#123;'names': ['Alfred', 'Bertrand', 'Clive']&#125;dc # &#123;'names': ['Alfred', 'Bertrand']&#125; 迭代工具zip():并行迭代,返回一个元组的列表,zip可以处理不等长的序列,当最短的序列用完的时候就会停止.123name = ['femn','femnyy','femnhh']age = [18,25]zip(name,age) # [('femn', 18), ('femnyy', 25)]","categories":[{"name":"python3","slug":"python3","permalink":"https://www.femn.me/categories/python3/"}],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2017-08-01T11:16:14.000Z","updated":"2017-09-23T11:10:15.692Z","comments":true,"path":"2017/08/01/hello-world/","link":"","permalink":"https://www.femn.me/2017/08/01/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}